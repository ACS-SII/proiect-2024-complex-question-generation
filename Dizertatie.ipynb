{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db6ac2625e114b33aebf6c33471fe39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03217c4451ba4ae189d8f73e667a406b",
              "IPY_MODEL_2c4009d3bfe643199cb6478001ff6b61",
              "IPY_MODEL_2c53157380134e44adb02ac78541f9e9"
            ],
            "layout": "IPY_MODEL_f9b51eed7d1548ea812582b76fd9e656"
          }
        },
        "03217c4451ba4ae189d8f73e667a406b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da425a495a3454494e31b446e674c14",
            "placeholder": "​",
            "style": "IPY_MODEL_41dee8ca6ebe45b3b5a7264fd8be1af8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2c4009d3bfe643199cb6478001ff6b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1debf07b5744a2b21c8f62d2f6eafb",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38324cc1375d4390b31541a116396d2e",
            "value": 48
          }
        },
        "2c53157380134e44adb02ac78541f9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac1a3f2dad5b48afaba6ef474d049ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_49030677b56245aa9140a782b97b589c",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.60kB/s]"
          }
        },
        "f9b51eed7d1548ea812582b76fd9e656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da425a495a3454494e31b446e674c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41dee8ca6ebe45b3b5a7264fd8be1af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1debf07b5744a2b21c8f62d2f6eafb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38324cc1375d4390b31541a116396d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac1a3f2dad5b48afaba6ef474d049ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49030677b56245aa9140a782b97b589c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a26ae8cdb42e47688a110d5197edd9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6de416b2af7f4df6ad176e0343b03006",
              "IPY_MODEL_45ee34d6d00542f1a7becf9ffcdcd571",
              "IPY_MODEL_d53bffbc195649398d26e05ae2a61ce7"
            ],
            "layout": "IPY_MODEL_4a82c88a41184c778424b99e4560a24f"
          }
        },
        "6de416b2af7f4df6ad176e0343b03006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b6ea7b2afc4b7c96d8f87b33586c14",
            "placeholder": "​",
            "style": "IPY_MODEL_822e17bfd4d94c6da36ed07b9eb7070f",
            "value": "vocab.txt: 100%"
          }
        },
        "45ee34d6d00542f1a7becf9ffcdcd571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380a0362cff448b7a85956bd9462b16b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70d180c0399e45559456739d145cecfb",
            "value": 231508
          }
        },
        "d53bffbc195649398d26e05ae2a61ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553e8f8efbe94193942f31eb9a944f90",
            "placeholder": "​",
            "style": "IPY_MODEL_be226222fd594a31b26e85d328a20e8f",
            "value": " 232k/232k [00:00&lt;00:00, 2.74MB/s]"
          }
        },
        "4a82c88a41184c778424b99e4560a24f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b6ea7b2afc4b7c96d8f87b33586c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822e17bfd4d94c6da36ed07b9eb7070f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "380a0362cff448b7a85956bd9462b16b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d180c0399e45559456739d145cecfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "553e8f8efbe94193942f31eb9a944f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be226222fd594a31b26e85d328a20e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f7fe48f4cce4c4ea2815155099bcf31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42a17a84524747aeb326748e0561ec0b",
              "IPY_MODEL_fe0a069f1c4d4d8e965f258d2e2f0fa0",
              "IPY_MODEL_7f760bd67a9e4851a955f478f2e2deff"
            ],
            "layout": "IPY_MODEL_64e187a029224ef0b4ec5dd1ea0a2422"
          }
        },
        "42a17a84524747aeb326748e0561ec0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1f9355bd2c1419cab2488514fc3926d",
            "placeholder": "​",
            "style": "IPY_MODEL_122d5850bfd143faa53b6956f7eb7b04",
            "value": "tokenizer.json: 100%"
          }
        },
        "fe0a069f1c4d4d8e965f258d2e2f0fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08b41e1d4407489e800b49f8d46b7805",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21d3e554267845b9b9ef5dcc41ae2a5d",
            "value": 466062
          }
        },
        "7f760bd67a9e4851a955f478f2e2deff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a702b4346e4ec387c399165c78d7f9",
            "placeholder": "​",
            "style": "IPY_MODEL_afcd0d5d36fb4ab9bdfb14aa6ee6f2e6",
            "value": " 466k/466k [00:00&lt;00:00, 6.51MB/s]"
          }
        },
        "64e187a029224ef0b4ec5dd1ea0a2422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f9355bd2c1419cab2488514fc3926d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122d5850bfd143faa53b6956f7eb7b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08b41e1d4407489e800b49f8d46b7805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d3e554267845b9b9ef5dcc41ae2a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13a702b4346e4ec387c399165c78d7f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcd0d5d36fb4ab9bdfb14aa6ee6f2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "076fc3ab131944e68a814c6e22f1237c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5350b9617aa4b2dbd8ebaa50083dd89",
              "IPY_MODEL_0870aab1d9f5431a8658765a2f754c0d",
              "IPY_MODEL_1288727b8f8a4e40af3d032e3f14325e"
            ],
            "layout": "IPY_MODEL_6a9e9ec383564f24a1ee690e261cd806"
          }
        },
        "e5350b9617aa4b2dbd8ebaa50083dd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba720121f904cc0aaa00ce67b13e11d",
            "placeholder": "​",
            "style": "IPY_MODEL_99f52d3074c24011a78ab53b19f4e534",
            "value": "config.json: 100%"
          }
        },
        "0870aab1d9f5431a8658765a2f754c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a556b1a61bf49ad80361778376d1a5f",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb071c0c7b6f476aa54384d347d4dbe2",
            "value": 571
          }
        },
        "1288727b8f8a4e40af3d032e3f14325e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f16a18a763f6486899280237b16ad104",
            "placeholder": "​",
            "style": "IPY_MODEL_35c08878c0a443c78e69fa772a24b002",
            "value": " 571/571 [00:00&lt;00:00, 30.6kB/s]"
          }
        },
        "6a9e9ec383564f24a1ee690e261cd806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ba720121f904cc0aaa00ce67b13e11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f52d3074c24011a78ab53b19f4e534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a556b1a61bf49ad80361778376d1a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb071c0c7b6f476aa54384d347d4dbe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f16a18a763f6486899280237b16ad104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c08878c0a443c78e69fa772a24b002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9fd795048b24488a9deebffaaa30809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d773106671cd41198cd7da560b770fbf",
              "IPY_MODEL_8ea41b5883bc4cadb3a03b4708490736",
              "IPY_MODEL_da6744741d114786b32f618dda3231f9"
            ],
            "layout": "IPY_MODEL_5d2c8bc912de441fb8902e711024e919"
          }
        },
        "d773106671cd41198cd7da560b770fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a8e5faf8a64aa29061dee1cf044b4a",
            "placeholder": "​",
            "style": "IPY_MODEL_bc5c2758865546618053e18f2fe9526a",
            "value": "model.safetensors: 100%"
          }
        },
        "8ea41b5883bc4cadb3a03b4708490736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ebbb0e3b1284384a8cca9dc172b6714",
            "max": 1344951957,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1d67394cef544ffb275321dc092ba76",
            "value": 1344951957
          }
        },
        "da6744741d114786b32f618dda3231f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae7458858604f679a19d1ea3cfb2b32",
            "placeholder": "​",
            "style": "IPY_MODEL_3be6cbd1bca94ee89e9b7f041e9a9ba0",
            "value": " 1.34G/1.34G [00:06&lt;00:00, 231MB/s]"
          }
        },
        "5d2c8bc912de441fb8902e711024e919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a8e5faf8a64aa29061dee1cf044b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5c2758865546618053e18f2fe9526a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ebbb0e3b1284384a8cca9dc172b6714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1d67394cef544ffb275321dc092ba76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ae7458858604f679a19d1ea3cfb2b32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be6cbd1bca94ee89e9b7f041e9a9ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c10885480ff440419467273c3da65aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af8a0fee8d324b82b25dc8ab94c42484",
              "IPY_MODEL_2d6e49ff87ed49e98ee939e2eec6decf",
              "IPY_MODEL_53c75440ef9847c981afc6087d9d4548"
            ],
            "layout": "IPY_MODEL_cb2310dae8be4300904296a22a26534c"
          }
        },
        "af8a0fee8d324b82b25dc8ab94c42484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a693318cba714e3a81366d946ce2559c",
            "placeholder": "​",
            "style": "IPY_MODEL_0da9da07e78948828a5d4a4b6ae30191",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2d6e49ff87ed49e98ee939e2eec6decf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f38bba2d314e24add3f6badbf119dd",
            "max": 2161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01f4ac9e24dc40e0a432e4db46c52bb6",
            "value": 2161
          }
        },
        "53c75440ef9847c981afc6087d9d4548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42ff4c8a75b4d3bacea5004c30aa5a0",
            "placeholder": "​",
            "style": "IPY_MODEL_b955de0e35c94a45988c8a7814a288eb",
            "value": " 2.16k/2.16k [00:00&lt;00:00, 167kB/s]"
          }
        },
        "cb2310dae8be4300904296a22a26534c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a693318cba714e3a81366d946ce2559c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da9da07e78948828a5d4a4b6ae30191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75f38bba2d314e24add3f6badbf119dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f4ac9e24dc40e0a432e4db46c52bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b42ff4c8a75b4d3bacea5004c30aa5a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b955de0e35c94a45988c8a7814a288eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ace5934806f04e7d863c35a723fae42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a781d27ff3494a4b986b9256db1fdd53",
              "IPY_MODEL_46d8d7409cf14b49b8881df6f6a7ab90",
              "IPY_MODEL_855465c83a7943de8a2e49e6b0c75880"
            ],
            "layout": "IPY_MODEL_d37cce8a6e6b4b7f820a026cfd77ed96"
          }
        },
        "a781d27ff3494a4b986b9256db1fdd53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d01a7efee34a94847bc03beb4c1217",
            "placeholder": "​",
            "style": "IPY_MODEL_ba6804b175e442fba58b8b6c267a0f82",
            "value": "spiece.model: 100%"
          }
        },
        "46d8d7409cf14b49b8881df6f6a7ab90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa75db4dfcbc46e99f6c4937e577625e",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1ef8a99e32241928078149fb6d97697",
            "value": 791656
          }
        },
        "855465c83a7943de8a2e49e6b0c75880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abea2eb154e4b7ba319f7e151f8838d",
            "placeholder": "​",
            "style": "IPY_MODEL_14ee12cddf354608b119749a7a783235",
            "value": " 792k/792k [00:00&lt;00:00, 25.8MB/s]"
          }
        },
        "d37cce8a6e6b4b7f820a026cfd77ed96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d01a7efee34a94847bc03beb4c1217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6804b175e442fba58b8b6c267a0f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa75db4dfcbc46e99f6c4937e577625e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1ef8a99e32241928078149fb6d97697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5abea2eb154e4b7ba319f7e151f8838d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ee12cddf354608b119749a7a783235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acf24738150d4b6da2736682282d1993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abaded4287534593a02b3a35d08eeed4",
              "IPY_MODEL_0100494a83954083998d05b21c9735c2",
              "IPY_MODEL_7b3b1aab90d24a1ca4909ea19faf4639"
            ],
            "layout": "IPY_MODEL_17290c82bec44501a336f64dc005cc87"
          }
        },
        "abaded4287534593a02b3a35d08eeed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12477627341c4cb6be190ec471d7412b",
            "placeholder": "​",
            "style": "IPY_MODEL_84ff8358fdae4592840ef55f777e1baa",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "0100494a83954083998d05b21c9735c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d42b421f14b94ee8bfaf45b2f90e3c53",
            "max": 1786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac375078c89f49579c356904226f3fed",
            "value": 1786
          }
        },
        "7b3b1aab90d24a1ca4909ea19faf4639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddce072fd14743949b72cf03189ca362",
            "placeholder": "​",
            "style": "IPY_MODEL_79a99f94a87549068ecbff99fdc2e6ef",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 117kB/s]"
          }
        },
        "17290c82bec44501a336f64dc005cc87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12477627341c4cb6be190ec471d7412b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ff8358fdae4592840ef55f777e1baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d42b421f14b94ee8bfaf45b2f90e3c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac375078c89f49579c356904226f3fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddce072fd14743949b72cf03189ca362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a99f94a87549068ecbff99fdc2e6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d45c0389f2d41f0a60d859993280e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0aface83a7d44a5ab2a382becc024d2a",
              "IPY_MODEL_5302e496cd25400f9275e25167accff0",
              "IPY_MODEL_362042346322402b9bc0dd0c198b0367"
            ],
            "layout": "IPY_MODEL_4b6313414e5849c3a74aa9f448186ad4"
          }
        },
        "0aface83a7d44a5ab2a382becc024d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cffdbc7e937e4fe8a4b194dfa25a7d84",
            "placeholder": "​",
            "style": "IPY_MODEL_8dbe506e97424679b3d25484bd27ea5d",
            "value": "config.json: 100%"
          }
        },
        "5302e496cd25400f9275e25167accff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_578b3a3f755249ec8697a355706134d5",
            "max": 1465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_771ee5b2254d48d18ffc26bf7d20a96a",
            "value": 1465
          }
        },
        "362042346322402b9bc0dd0c198b0367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d92c50ec8d4bf3bae715ccf2cc607b",
            "placeholder": "​",
            "style": "IPY_MODEL_3e2fefa152644b969a08ffa9cd5eb414",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 123kB/s]"
          }
        },
        "4b6313414e5849c3a74aa9f448186ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cffdbc7e937e4fe8a4b194dfa25a7d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbe506e97424679b3d25484bd27ea5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "578b3a3f755249ec8697a355706134d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "771ee5b2254d48d18ffc26bf7d20a96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20d92c50ec8d4bf3bae715ccf2cc607b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2fefa152644b969a08ffa9cd5eb414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e31964e1cf4440d9ab3d065b08530e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c28c886c94624f86ab186103d001d597",
              "IPY_MODEL_39614a5c3df144399da286442b398b78",
              "IPY_MODEL_25096f0bd8f044cfa6cd6c773c22759c"
            ],
            "layout": "IPY_MODEL_262069b7871d44268b9a11473894ea96"
          }
        },
        "c28c886c94624f86ab186103d001d597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05cb5e5769cc46fab0805d73818af259",
            "placeholder": "​",
            "style": "IPY_MODEL_0894a301f8e5491abaab5e8eb0b432df",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "39614a5c3df144399da286442b398b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baf0d23f55ed47f99974239844480792",
            "max": 891707320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e04ac2c0ee844bc9adf3d3979ff717a",
            "value": 891707320
          }
        },
        "25096f0bd8f044cfa6cd6c773c22759c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7fff661031a4897a897872a516b7585",
            "placeholder": "​",
            "style": "IPY_MODEL_5c64cbe5a74b45ab9886ba4b7bbae475",
            "value": " 892M/892M [00:38&lt;00:00, 21.4MB/s]"
          }
        },
        "262069b7871d44268b9a11473894ea96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05cb5e5769cc46fab0805d73818af259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0894a301f8e5491abaab5e8eb0b432df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baf0d23f55ed47f99974239844480792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e04ac2c0ee844bc9adf3d3979ff717a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7fff661031a4897a897872a516b7585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c64cbe5a74b45ab9886ba4b7bbae475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "894267102e8f4243b65dbc0583d62611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5751225df62441a08fc370b950092671",
              "IPY_MODEL_a817bd0ac92748a29b4a1948cec740a1",
              "IPY_MODEL_6efbfe9fddeb46ffb066e432137e99c1"
            ],
            "layout": "IPY_MODEL_4b910bb64bf04cde9bd1ccf5eb52af4b"
          }
        },
        "5751225df62441a08fc370b950092671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb9c01f805341fab7d0970b33f5e570",
            "placeholder": "​",
            "style": "IPY_MODEL_45b64ebe6b0446c6a086248215b1931a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a817bd0ac92748a29b4a1948cec740a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ce31a208594bad9c069a90fdf4b191",
            "max": 2161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9a5b711401947bb9ce5b93aa86c717f",
            "value": 2161
          }
        },
        "6efbfe9fddeb46ffb066e432137e99c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e250721e42c412d98430d8d423857eb",
            "placeholder": "​",
            "style": "IPY_MODEL_d880c1517b2841949c398eae913648f8",
            "value": " 2.16k/2.16k [00:00&lt;00:00, 192kB/s]"
          }
        },
        "4b910bb64bf04cde9bd1ccf5eb52af4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb9c01f805341fab7d0970b33f5e570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b64ebe6b0446c6a086248215b1931a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ce31a208594bad9c069a90fdf4b191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a5b711401947bb9ce5b93aa86c717f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e250721e42c412d98430d8d423857eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d880c1517b2841949c398eae913648f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "704b6e773bf545d999b7417345dbeaf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a7c3478bffa4f0a9df5a2b8ce70121e",
              "IPY_MODEL_155fe95412f043fe87164cbfe49862f3",
              "IPY_MODEL_e40a4e42ab6a4b809c000edbbe8d1936"
            ],
            "layout": "IPY_MODEL_b550b6b447e4451c831edbce7b21f91e"
          }
        },
        "4a7c3478bffa4f0a9df5a2b8ce70121e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f90eb6379849d18b7e4e72c9af9d6f",
            "placeholder": "​",
            "style": "IPY_MODEL_05dac3e8606d42389900d4867e0288ef",
            "value": "spiece.model: 100%"
          }
        },
        "155fe95412f043fe87164cbfe49862f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_990147c76bb548c08e32c5f159f269ef",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1f7da4545534ecda80b80040a6514ea",
            "value": 791656
          }
        },
        "e40a4e42ab6a4b809c000edbbe8d1936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5df2d68113a4483387f066d518b3be41",
            "placeholder": "​",
            "style": "IPY_MODEL_210619543e3f4e13b4c596d9a21addee",
            "value": " 792k/792k [00:00&lt;00:00, 12.9MB/s]"
          }
        },
        "b550b6b447e4451c831edbce7b21f91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f90eb6379849d18b7e4e72c9af9d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05dac3e8606d42389900d4867e0288ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "990147c76bb548c08e32c5f159f269ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f7da4545534ecda80b80040a6514ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5df2d68113a4483387f066d518b3be41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210619543e3f4e13b4c596d9a21addee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "239eb31abe76488c9ac2eafa930c850b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1514cd5e998f4f21bb20227f01b333d1",
              "IPY_MODEL_8cd645d191a641e9a23b8837a4307bc5",
              "IPY_MODEL_73bcb3d5f7f24f7b9bb11422dde71e0c"
            ],
            "layout": "IPY_MODEL_dd6d6a2207214663aac5f0b7bd8ffbc1"
          }
        },
        "1514cd5e998f4f21bb20227f01b333d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4369126c2cb3486eba443cc6311569be",
            "placeholder": "​",
            "style": "IPY_MODEL_3a02c818ea394fee963e1813ac415e25",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8cd645d191a641e9a23b8837a4307bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48585431185d418596d4511058589d6d",
            "max": 1786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e09874935db042739872fd45455e2eb6",
            "value": 1786
          }
        },
        "73bcb3d5f7f24f7b9bb11422dde71e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89de029e56354184b7963ce229753443",
            "placeholder": "​",
            "style": "IPY_MODEL_335d0a36a640485fb2e38f2444f3e91b",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 122kB/s]"
          }
        },
        "dd6d6a2207214663aac5f0b7bd8ffbc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4369126c2cb3486eba443cc6311569be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a02c818ea394fee963e1813ac415e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48585431185d418596d4511058589d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09874935db042739872fd45455e2eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89de029e56354184b7963ce229753443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "335d0a36a640485fb2e38f2444f3e91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ce9ab6ef88e474a9a03345dcb615d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6bef581122d4b609fea9952eedd51a8",
              "IPY_MODEL_00f97abf5f8a4967aa8f29e83df18e20",
              "IPY_MODEL_e994af944c704ec18e094522f34c9f4d"
            ],
            "layout": "IPY_MODEL_38d57ec427534741a115de19af675789"
          }
        },
        "b6bef581122d4b609fea9952eedd51a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a808b0b9a09423583648b36eed533de",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9d169064474c3abc22624fb25c6d1d",
            "value": "config.json: 100%"
          }
        },
        "00f97abf5f8a4967aa8f29e83df18e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf89ec75db4848b2b95da4ae09290a50",
            "max": 1465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5215f717786a4c54bc20bccf9f49022c",
            "value": 1465
          }
        },
        "e994af944c704ec18e094522f34c9f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d736f73c96e4c8698f3f716c853402f",
            "placeholder": "​",
            "style": "IPY_MODEL_0ceef8ed173a48149f00ee343a39376c",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 124kB/s]"
          }
        },
        "38d57ec427534741a115de19af675789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a808b0b9a09423583648b36eed533de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9d169064474c3abc22624fb25c6d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf89ec75db4848b2b95da4ae09290a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5215f717786a4c54bc20bccf9f49022c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d736f73c96e4c8698f3f716c853402f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ceef8ed173a48149f00ee343a39376c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "270ef1552fa14f6bb670452e4298c6b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0923ce9bc32143ffb469d7a2a1813592",
              "IPY_MODEL_51b4f502ba5348539faae8824721c789",
              "IPY_MODEL_38dfeee810d7429ca8404754be5caa2d"
            ],
            "layout": "IPY_MODEL_237911ed13ea4c899c7771d5a1941398"
          }
        },
        "0923ce9bc32143ffb469d7a2a1813592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce5057408fcc4dc7a7f3520411b20746",
            "placeholder": "​",
            "style": "IPY_MODEL_d99bd1d2091348b79357ecdbe3965fc3",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "51b4f502ba5348539faae8824721c789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_291b934832b5464587d2354eaae6ca85",
            "max": 891707320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f8e78822e2d4290b3972329827ef101",
            "value": 891707320
          }
        },
        "38dfeee810d7429ca8404754be5caa2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfb961b0699b4f4dabcc92f59ab0eb96",
            "placeholder": "​",
            "style": "IPY_MODEL_337c4a6234ca458ba5623db8ba8987a5",
            "value": " 892M/892M [00:12&lt;00:00, 33.1MB/s]"
          }
        },
        "237911ed13ea4c899c7771d5a1941398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5057408fcc4dc7a7f3520411b20746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99bd1d2091348b79357ecdbe3965fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "291b934832b5464587d2354eaae6ca85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8e78822e2d4290b3972329827ef101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfb961b0699b4f4dabcc92f59ab0eb96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337c4a6234ca458ba5623db8ba8987a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87fd5e6c75cc40cb810f02fd7f7a8836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2df88c3f3ee14247a33ce4444146377c",
              "IPY_MODEL_8f965adaaca44a77a13af082de68937b",
              "IPY_MODEL_eb7fd24f16e04a9ab88c0367a2ac1493"
            ],
            "layout": "IPY_MODEL_353a528e4dd04603b77043cb19410b2d"
          }
        },
        "2df88c3f3ee14247a33ce4444146377c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_333b375ebd6946aeb49fe8deeacc6e14",
            "placeholder": "​",
            "style": "IPY_MODEL_63595d9c2f8b429cadb831ae44b8ca33",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8f965adaaca44a77a13af082de68937b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_722b78a37cff43b2bd50d97813f70ca2",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18278ae02e274cdaacd60552f5b813f3",
            "value": 49
          }
        },
        "eb7fd24f16e04a9ab88c0367a2ac1493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7398e79ba56d449f9bf000891e83e17a",
            "placeholder": "​",
            "style": "IPY_MODEL_8a9deff3af3f41fcb762a3fc0a169fc4",
            "value": " 49.0/49.0 [00:00&lt;00:00, 4.14kB/s]"
          }
        },
        "353a528e4dd04603b77043cb19410b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "333b375ebd6946aeb49fe8deeacc6e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63595d9c2f8b429cadb831ae44b8ca33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "722b78a37cff43b2bd50d97813f70ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18278ae02e274cdaacd60552f5b813f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7398e79ba56d449f9bf000891e83e17a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a9deff3af3f41fcb762a3fc0a169fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83917399c9274ece9e496ce1926148d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_781719a35bdf4b868842cc0bb915c49c",
              "IPY_MODEL_7d5ae24635a943aca44bb5a5c90a2573",
              "IPY_MODEL_259e5131eb6f4907abe0914b1159762f"
            ],
            "layout": "IPY_MODEL_8123bd1a0824406c975727c4c33eb4ed"
          }
        },
        "781719a35bdf4b868842cc0bb915c49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca4b8f82691f41378ecd1c0e5be53d3c",
            "placeholder": "​",
            "style": "IPY_MODEL_bfbb33a3d5f1411fba9e0601e4593a14",
            "value": "vocab.txt: 100%"
          }
        },
        "7d5ae24635a943aca44bb5a5c90a2573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c23e8d9e4ea64fbe840c64b506629daa",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05223b7f8b20442aad7dd75de8d33b09",
            "value": 213450
          }
        },
        "259e5131eb6f4907abe0914b1159762f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1742c66bf4f145d4aaad1580eef3c08b",
            "placeholder": "​",
            "style": "IPY_MODEL_31ab12f181354b048895b0edc15362d0",
            "value": " 213k/213k [00:00&lt;00:00, 498kB/s]"
          }
        },
        "8123bd1a0824406c975727c4c33eb4ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca4b8f82691f41378ecd1c0e5be53d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbb33a3d5f1411fba9e0601e4593a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c23e8d9e4ea64fbe840c64b506629daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05223b7f8b20442aad7dd75de8d33b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1742c66bf4f145d4aaad1580eef3c08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ab12f181354b048895b0edc15362d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a2ead438cd4f1fa37b1951ff6dd55e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b67c7a708a94082aed81eeca52d1887",
              "IPY_MODEL_f2835d9626ba4d4eb5b3e07edf0e4c8b",
              "IPY_MODEL_5c2edef8783a4c5ba3bc8827e84f7ef0"
            ],
            "layout": "IPY_MODEL_ccc5687e8eb545958f37a89b20f7a61e"
          }
        },
        "9b67c7a708a94082aed81eeca52d1887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ef3251ec5af4d228cf9e3db43fb86b6",
            "placeholder": "​",
            "style": "IPY_MODEL_478ae864af2347e1a001347b3c134d2d",
            "value": "tokenizer.json: 100%"
          }
        },
        "f2835d9626ba4d4eb5b3e07edf0e4c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057c6589f8b14857a91b37ecb7c33484",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2353526ea2944912b8144e60855f9256",
            "value": 435797
          }
        },
        "5c2edef8783a4c5ba3bc8827e84f7ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8126654d79c94073bd4365d4c36e59bf",
            "placeholder": "​",
            "style": "IPY_MODEL_89b85af8781d4f3c8601d53ef6f9eb02",
            "value": " 436k/436k [00:00&lt;00:00, 2.06MB/s]"
          }
        },
        "ccc5687e8eb545958f37a89b20f7a61e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ef3251ec5af4d228cf9e3db43fb86b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "478ae864af2347e1a001347b3c134d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "057c6589f8b14857a91b37ecb7c33484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2353526ea2944912b8144e60855f9256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8126654d79c94073bd4365d4c36e59bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b85af8781d4f3c8601d53ef6f9eb02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51c2004178b04b27a261d35035689add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30b958c41bf343f8b292374fe18f6225",
              "IPY_MODEL_638d5018504a4a1b86f4fbdbd92980e2",
              "IPY_MODEL_46d99e399de140898a53089a588a1de1"
            ],
            "layout": "IPY_MODEL_b72d9a8aa1ae4e8abecfe74335fce9d9"
          }
        },
        "30b958c41bf343f8b292374fe18f6225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521de082b0b44bcdbb9701780887ca64",
            "placeholder": "​",
            "style": "IPY_MODEL_f76c2dd6330f4297ad1974f46d206764",
            "value": "config.json: 100%"
          }
        },
        "638d5018504a4a1b86f4fbdbd92980e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edd043fe13d4586afd586fa42a4971e",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_778e3a3e89bf4898a4e15c9591930a9a",
            "value": 570
          }
        },
        "46d99e399de140898a53089a588a1de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908a2187f8e5417bb6564a27f29f7b0e",
            "placeholder": "​",
            "style": "IPY_MODEL_86bd5009a60644c2a1bd67dd859a6057",
            "value": " 570/570 [00:00&lt;00:00, 47.6kB/s]"
          }
        },
        "b72d9a8aa1ae4e8abecfe74335fce9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "521de082b0b44bcdbb9701780887ca64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f76c2dd6330f4297ad1974f46d206764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4edd043fe13d4586afd586fa42a4971e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "778e3a3e89bf4898a4e15c9591930a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "908a2187f8e5417bb6564a27f29f7b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bd5009a60644c2a1bd67dd859a6057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "t8ft7mQM337L",
        "outputId": "96d088bf-20af-4777-f424-a94bf31b2cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [132/132 03:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.160100</td>\n",
              "      <td>1.091795</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.890084</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.753600</td>\n",
              "      <td>0.834912</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.8349121809005737, 'eval_f1': 0.8282828282828283, 'eval_accuracy': 0.7068965517241379, 'eval_runtime': 5.2768, 'eval_samples_per_second': 32.974, 'eval_steps_per_second': 0.569, 'epoch': 3.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "\n",
        "# Dezactivarea W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "texts = []\n",
        "labels = []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding='max_length', truncation=True)\n",
        "\n",
        "train_encodings = tokenize_function(X_train)\n",
        "test_encodings = tokenize_function(X_test)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Load the pre-trained BERT model for classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(bloom_categories))\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory for model checkpoints\n",
        "    num_train_epochs=3,              # number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size for training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"      # evaluate after each epoch\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to be trained\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids)  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"qg_agno_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "texts = []\n",
        "labels = []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"hadifar/openstax_qg_agno\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"hadifar/openstax_qg_agno\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    # Returning tensors directly for the required input format\n",
        "    return tokenizer(examples, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "train_encodings = tokenize_function(X_train)\n",
        "test_encodings = tokenize_function(X_test)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory for model checkpoints\n",
        "    num_train_epochs=3,              # number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size for training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"      # evaluate after each epoch\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to be trained\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids)  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions_output = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions_output.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n",
        "\n",
        "# Generate a confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=bloom_categories, yticklabels=bloom_categories)\n",
        "plt.title(\"Confusion Matrix Heatmap\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"confusion_matrix_heatmap.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744,
          "referenced_widgets": [
            "c10885480ff440419467273c3da65aed",
            "af8a0fee8d324b82b25dc8ab94c42484",
            "2d6e49ff87ed49e98ee939e2eec6decf",
            "53c75440ef9847c981afc6087d9d4548",
            "cb2310dae8be4300904296a22a26534c",
            "a693318cba714e3a81366d946ce2559c",
            "0da9da07e78948828a5d4a4b6ae30191",
            "75f38bba2d314e24add3f6badbf119dd",
            "01f4ac9e24dc40e0a432e4db46c52bb6",
            "b42ff4c8a75b4d3bacea5004c30aa5a0",
            "b955de0e35c94a45988c8a7814a288eb",
            "ace5934806f04e7d863c35a723fae42d",
            "a781d27ff3494a4b986b9256db1fdd53",
            "46d8d7409cf14b49b8881df6f6a7ab90",
            "855465c83a7943de8a2e49e6b0c75880",
            "d37cce8a6e6b4b7f820a026cfd77ed96",
            "32d01a7efee34a94847bc03beb4c1217",
            "ba6804b175e442fba58b8b6c267a0f82",
            "fa75db4dfcbc46e99f6c4937e577625e",
            "c1ef8a99e32241928078149fb6d97697",
            "5abea2eb154e4b7ba319f7e151f8838d",
            "14ee12cddf354608b119749a7a783235",
            "acf24738150d4b6da2736682282d1993",
            "abaded4287534593a02b3a35d08eeed4",
            "0100494a83954083998d05b21c9735c2",
            "7b3b1aab90d24a1ca4909ea19faf4639",
            "17290c82bec44501a336f64dc005cc87",
            "12477627341c4cb6be190ec471d7412b",
            "84ff8358fdae4592840ef55f777e1baa",
            "d42b421f14b94ee8bfaf45b2f90e3c53",
            "ac375078c89f49579c356904226f3fed",
            "ddce072fd14743949b72cf03189ca362",
            "79a99f94a87549068ecbff99fdc2e6ef",
            "9d45c0389f2d41f0a60d859993280e74",
            "0aface83a7d44a5ab2a382becc024d2a",
            "5302e496cd25400f9275e25167accff0",
            "362042346322402b9bc0dd0c198b0367",
            "4b6313414e5849c3a74aa9f448186ad4",
            "cffdbc7e937e4fe8a4b194dfa25a7d84",
            "8dbe506e97424679b3d25484bd27ea5d",
            "578b3a3f755249ec8697a355706134d5",
            "771ee5b2254d48d18ffc26bf7d20a96a",
            "20d92c50ec8d4bf3bae715ccf2cc607b",
            "3e2fefa152644b969a08ffa9cd5eb414",
            "e31964e1cf4440d9ab3d065b08530e83",
            "c28c886c94624f86ab186103d001d597",
            "39614a5c3df144399da286442b398b78",
            "25096f0bd8f044cfa6cd6c773c22759c",
            "262069b7871d44268b9a11473894ea96",
            "05cb5e5769cc46fab0805d73818af259",
            "0894a301f8e5491abaab5e8eb0b432df",
            "baf0d23f55ed47f99974239844480792",
            "3e04ac2c0ee844bc9adf3d3979ff717a",
            "f7fff661031a4897a897872a516b7585",
            "5c64cbe5a74b45ab9886ba4b7bbae475"
          ]
        },
        "id": "0W7tN6w_NrlW",
        "outputId": "74feac4b-e86b-49db-b675-ab87454dc739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c10885480ff440419467273c3da65aed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ace5934806f04e7d863c35a723fae42d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acf24738150d4b6da2736682282d1993"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d45c0389f2d41f0a60d859993280e74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e31964e1cf4440d9ab3d065b08530e83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b572edc11386>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2522\u001b[0m                     )\n\u001b[1;32m   2523\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3653\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3654\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3706\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3707\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3708\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3709\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1892\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"qg_agno_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "texts = []\n",
        "labels = []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"hadifar/openstax_qg_agno\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"hadifar/openstax_qg_agno\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    encodings = tokenizer(examples, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_function(X_train)\n",
        "test_encodings = tokenize_function(X_test)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory for model checkpoints\n",
        "    num_train_epochs=3,              # number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size for training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"      # evaluate after each epoch\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to be trained\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids)  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n",
        "\n",
        "# Generate a confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=bloom_categories, yticklabels=bloom_categories)\n",
        "plt.title(\"Confusion Matrix Heatmap\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"confusion_matrix_heatmap.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640,
          "referenced_widgets": [
            "894267102e8f4243b65dbc0583d62611",
            "5751225df62441a08fc370b950092671",
            "a817bd0ac92748a29b4a1948cec740a1",
            "6efbfe9fddeb46ffb066e432137e99c1",
            "4b910bb64bf04cde9bd1ccf5eb52af4b",
            "2fb9c01f805341fab7d0970b33f5e570",
            "45b64ebe6b0446c6a086248215b1931a",
            "f8ce31a208594bad9c069a90fdf4b191",
            "b9a5b711401947bb9ce5b93aa86c717f",
            "5e250721e42c412d98430d8d423857eb",
            "d880c1517b2841949c398eae913648f8",
            "704b6e773bf545d999b7417345dbeaf1",
            "4a7c3478bffa4f0a9df5a2b8ce70121e",
            "155fe95412f043fe87164cbfe49862f3",
            "e40a4e42ab6a4b809c000edbbe8d1936",
            "b550b6b447e4451c831edbce7b21f91e",
            "98f90eb6379849d18b7e4e72c9af9d6f",
            "05dac3e8606d42389900d4867e0288ef",
            "990147c76bb548c08e32c5f159f269ef",
            "a1f7da4545534ecda80b80040a6514ea",
            "5df2d68113a4483387f066d518b3be41",
            "210619543e3f4e13b4c596d9a21addee",
            "239eb31abe76488c9ac2eafa930c850b",
            "1514cd5e998f4f21bb20227f01b333d1",
            "8cd645d191a641e9a23b8837a4307bc5",
            "73bcb3d5f7f24f7b9bb11422dde71e0c",
            "dd6d6a2207214663aac5f0b7bd8ffbc1",
            "4369126c2cb3486eba443cc6311569be",
            "3a02c818ea394fee963e1813ac415e25",
            "48585431185d418596d4511058589d6d",
            "e09874935db042739872fd45455e2eb6",
            "89de029e56354184b7963ce229753443",
            "335d0a36a640485fb2e38f2444f3e91b",
            "0ce9ab6ef88e474a9a03345dcb615d09",
            "b6bef581122d4b609fea9952eedd51a8",
            "00f97abf5f8a4967aa8f29e83df18e20",
            "e994af944c704ec18e094522f34c9f4d",
            "38d57ec427534741a115de19af675789",
            "9a808b0b9a09423583648b36eed533de",
            "fe9d169064474c3abc22624fb25c6d1d",
            "bf89ec75db4848b2b95da4ae09290a50",
            "5215f717786a4c54bc20bccf9f49022c",
            "7d736f73c96e4c8698f3f716c853402f",
            "0ceef8ed173a48149f00ee343a39376c",
            "270ef1552fa14f6bb670452e4298c6b5",
            "0923ce9bc32143ffb469d7a2a1813592",
            "51b4f502ba5348539faae8824721c789",
            "38dfeee810d7429ca8404754be5caa2d",
            "237911ed13ea4c899c7771d5a1941398",
            "ce5057408fcc4dc7a7f3520411b20746",
            "d99bd1d2091348b79357ecdbe3965fc3",
            "291b934832b5464587d2354eaae6ca85",
            "5f8e78822e2d4290b3972329827ef101",
            "dfb961b0699b4f4dabcc92f59ab0eb96",
            "337c4a6234ca458ba5623db8ba8987a5"
          ]
        },
        "id": "kTTnjxCMNaAL",
        "outputId": "d7425151-bd8e-4fe2-dd30-c548f27967a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "894267102e8f4243b65dbc0583d62611"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "704b6e773bf545d999b7417345dbeaf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "239eb31abe76488c9ac2eafa930c850b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ce9ab6ef88e474a9a03345dcb615d09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "270ef1552fa14f6bb670452e4298c6b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-91f1a5e506f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2522\u001b[0m                     )\n\u001b[1;32m   2523\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3653\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3654\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3706\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3707\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3708\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3709\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1892\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Disable W&B (Weights and Biases)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your datasets\n",
        "dataset_paths = [r\"eduqg_evaluation_bloom_cleaned.json\", r\"eduqg_few_shot_bloom_cleaned.json\"]\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load and combine datasets\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for dataset_path in dataset_paths:\n",
        "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "        dataset = json.load(f)\n",
        "        for chapter in dataset:\n",
        "            for question_item in chapter.get('questions', []):\n",
        "                question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "                actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "                if question and actual_bloom:\n",
        "                    texts.append(question)\n",
        "                    labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Split the combined dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "train_encodings = tokenize_function(X_train)\n",
        "test_encodings = tokenize_function(X_test)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Load the pre-trained BERT model for classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(bloom_categories))\n",
        "\n",
        "# Metrics for evaluation\n",
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(axis=-1)\n",
        "    f1 = f1_score(p.label_ids, preds, average='weighted')\n",
        "    accuracy = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',               # output directory for model checkpoints\n",
        "    num_train_epochs=5,                   # increased number of training epochs\n",
        "    per_device_train_batch_size=8,        # smaller batch size for finer gradients\n",
        "    per_device_eval_batch_size=16,        # batch size for evaluation\n",
        "    warmup_steps=200,                     # number of warmup steps for LR scheduler\n",
        "    weight_decay=0.01,                    # strength of weight decay\n",
        "    logging_dir='./logs',                 # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",          # evaluate after each epoch\n",
        "    save_strategy=\"epoch\",                # save model after each epoch\n",
        "    save_total_limit=3,                   # limit the number of saved models\n",
        "    learning_rate=5e-6,                   # reduced learning rate for finer tuning\n",
        "    load_best_model_at_end=True,          # load the best model at the end of training\n",
        "    gradient_accumulation_steps=2,        # simulate a larger effective batch size\n",
        "    lr_scheduler_type=\"cosine\",           # cosine annealing for learning rate\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to be trained\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # custom metrics\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Early stopping for optimization\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n",
        "\n",
        "# Generate a confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=bloom_categories, yticklabels=bloom_categories)\n",
        "plt.title(\"Confusion Matrix Heatmap\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"confusion_matrix_heatmap.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "oB8me8EvBz-M",
        "outputId": "f02fcbfa-d64a-4c09-c4d2-355af41d42c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 00:59, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.042000</td>\n",
              "      <td>1.433742</td>\n",
              "      <td>0.082873</td>\n",
              "      <td>0.031361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.379800</td>\n",
              "      <td>1.131478</td>\n",
              "      <td>0.723757</td>\n",
              "      <td>0.607770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.888800</td>\n",
              "      <td>0.896567</td>\n",
              "      <td>0.723757</td>\n",
              "      <td>0.607770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.570600</td>\n",
              "      <td>0.831505</td>\n",
              "      <td>0.723757</td>\n",
              "      <td>0.607770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.8315049409866333, 'eval_accuracy': 0.7237569060773481, 'eval_f1': 0.6077702224111065, 'eval_runtime': 0.5779, 'eval_samples_per_second': 313.195, 'eval_steps_per_second': 20.764, 'epoch': 4.9010989010989015}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "import os\n",
        "\n",
        "# Disable W&B (Weights and Biases)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Define the paths for your dataset\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "texts = []\n",
        "labels = []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "train_encodings = tokenize_function(X_train)\n",
        "test_encodings = tokenize_function(X_test)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Load the pre-trained BERT model for classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(bloom_categories))\n",
        "\n",
        "# Metrics for evaluation\n",
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(axis=-1)\n",
        "    f1 = f1_score(p.label_ids, preds, average='weighted')\n",
        "    accuracy = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',              # output directory for model checkpoints\n",
        "    num_train_epochs=10,                 # increased number of training epochs\n",
        "    per_device_train_batch_size=8,       # smaller batch size for finer gradients\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=200,                    # number of warmup steps for LR scheduler\n",
        "    weight_decay=0.01,                   # strength of weight decay\n",
        "    logging_dir='./logs',                # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",         # evaluate after each epoch\n",
        "    save_strategy=\"epoch\",               # save model after each epoch\n",
        "    save_total_limit=3,                  # limit the number of saved models\n",
        "    learning_rate=5e-6,                  # reduced learning rate for finer tuning\n",
        "    load_best_model_at_end=True,         # load the best model at the end of training\n",
        "    gradient_accumulation_steps=2,       # simulate a larger effective batch size\n",
        "    lr_scheduler_type=\"cosine\",          # cosine annealing for learning rate\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to be trained\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # custom metrics\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Early stopping for optimization\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "dJp7DwLm_QQC",
        "outputId": "04ece18f-dc05-4f42-dc99-4c3bb85b8d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='430' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [430/430 01:54, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.778200</td>\n",
              "      <td>1.303225</td>\n",
              "      <td>0.643678</td>\n",
              "      <td>0.565832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.174700</td>\n",
              "      <td>1.070416</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.585510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.886200</td>\n",
              "      <td>0.953254</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.585510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.557900</td>\n",
              "      <td>0.881337</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.585510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.519100</td>\n",
              "      <td>0.852489</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.585510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.564500</td>\n",
              "      <td>0.811017</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.585510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.483800</td>\n",
              "      <td>0.795640</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.585510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.398500</td>\n",
              "      <td>0.788455</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.587488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.111300</td>\n",
              "      <td>0.782936</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.589480</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.7823790907859802, 'eval_accuracy': 0.7126436781609196, 'eval_f1': 0.6017900620414635, 'eval_runtime': 0.5447, 'eval_samples_per_second': 319.417, 'eval_steps_per_second': 20.193, 'epoch': 9.781609195402298}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJtpJYAa7Vb_",
        "outputId": "ed5eca47-7a60-493c-e4f9-62e18ddab7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Dezactivarea W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "texts = []\n",
        "labels = []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding='max_length', truncation=True)\n",
        "\n",
        "train_encodings = tokenize_function(X_train)\n",
        "test_encodings = tokenize_function(X_test)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Load the pre-trained BERT model for classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(bloom_categories))\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # output directory for model checkpoints\n",
        "    num_train_epochs=5,               # number of training epochs\n",
        "    per_device_train_batch_size=8,    # reduced batch size for better memory handling\n",
        "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
        "    warmup_steps=1000,                # increased number of warmup steps\n",
        "    weight_decay=0.01,                # strength of weight decay\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",      # evaluate after each epoch\n",
        "    save_strategy=\"epoch\",            # save checkpoint after each epoch\n",
        "    load_best_model_at_end=True,      # load best model after training\n",
        "    learning_rate=2e-5,               # reduced learning rate for finer tuning\n",
        "    gradient_accumulation_steps=2,    # accumulate gradients to simulate a larger batch size\n",
        "    max_grad_norm=1.0,                # gradient clipping to avoid exploding gradients\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to be trained\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids)  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "TLHY7oLt7RZY",
        "outputId": "b3520631-0be9-4afd-d1b9-d13fc81849b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/215 05:38 < 00:49, 0.55 it/s, Epoch 4.25/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.821800</td>\n",
              "      <td>1.365903</td>\n",
              "      <td>0.055950</td>\n",
              "      <td>0.034483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.508400</td>\n",
              "      <td>1.167700</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.760900</td>\n",
              "      <td>0.895831</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.484000</td>\n",
              "      <td>0.874715</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-41404d47cda3>\u001b[0m in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2527\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2529\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2530\u001b[0m                     ):\n\u001b[1;32m   2531\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "texts = []\n",
        "labels = []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding='max_length', truncation=True)\n",
        "\n",
        "train_encodings = tokenize_function(X_train)\n",
        "test_encodings = tokenize_function(X_test)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Load the pre-trained BERT model for classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(bloom_categories))\n",
        "\n",
        "# Set up training arguments with adjustments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # output directory for model checkpoints\n",
        "    num_train_epochs=5,               # number of training epochs\n",
        "    per_device_train_batch_size=16,    # increased batch size for better training\n",
        "    per_device_eval_batch_size=32,    # increased batch size for evaluation\n",
        "    warmup_steps=1000,                # number of warmup steps\n",
        "    weight_decay=0.01,                # strength of weight decay\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",      # evaluate after each epoch\n",
        "    save_strategy=\"epoch\",            # save checkpoint after each epoch\n",
        "    load_best_model_at_end=True,      # load best model after training\n",
        "    learning_rate=3e-5,               # adjusted learning rate for finer tuning\n",
        "    gradient_accumulation_steps=4,    # accumulate gradients to simulate a larger batch size\n",
        "    max_grad_norm=1.0,                # gradient clipping to avoid exploding gradients\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to be trained\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids)  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ADyviMTnQbIr",
        "outputId": "3d03e67b-9650-4f35-8559-e8656139828d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 02:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.164200</td>\n",
              "      <td>1.553513</td>\n",
              "      <td>0.195760</td>\n",
              "      <td>0.109195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.932800</td>\n",
              "      <td>1.460768</td>\n",
              "      <td>0.195826</td>\n",
              "      <td>0.114943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.589000</td>\n",
              "      <td>1.305753</td>\n",
              "      <td>0.210021</td>\n",
              "      <td>0.235632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.169200</td>\n",
              "      <td>1.179394</td>\n",
              "      <td>0.723948</td>\n",
              "      <td>0.649425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.732900</td>\n",
              "      <td>1.089345</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 1.0893452167510986, 'eval_f1': 0.8282828282828283, 'eval_accuracy': 0.7068965517241379, 'eval_runtime': 2.35, 'eval_samples_per_second': 74.043, 'eval_steps_per_second': 2.553, 'epoch': 5.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "\n",
        "# Dezactivarea W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_large_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "texts = []\n",
        "labels = []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the pre-trained BERT tokenizer (for bert-large-uncased)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding='max_length', truncation=True)\n",
        "\n",
        "train_encodings = tokenize_function(X_train)\n",
        "test_encodings = tokenize_function(X_test)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Load the pre-trained BERT large model for classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=len(bloom_categories))\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',           # output directory for model checkpoints\n",
        "    num_train_epochs=5,               # number of training epochs\n",
        "    per_device_train_batch_size=8,    # reduced batch size for better memory handling\n",
        "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
        "    warmup_steps=1000,                # increased number of warmup steps\n",
        "    weight_decay=0.01,                # strength of weight decay\n",
        "    logging_dir='./logs',             # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",      # evaluate after each epoch\n",
        "    save_strategy=\"epoch\",            # save checkpoint after each epoch\n",
        "    load_best_model_at_end=True,      # load best model after training\n",
        "    learning_rate=2e-5,               # reduced learning rate for finer tuning\n",
        "    gradient_accumulation_steps=2,    # accumulate gradients to simulate a larger batch size\n",
        "    max_grad_norm=1.0,                # gradient clipping to avoid exploding gradients\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to be trained\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids)  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(X_test, y_test)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502,
          "referenced_widgets": [
            "db6ac2625e114b33aebf6c33471fe39c",
            "03217c4451ba4ae189d8f73e667a406b",
            "2c4009d3bfe643199cb6478001ff6b61",
            "2c53157380134e44adb02ac78541f9e9",
            "f9b51eed7d1548ea812582b76fd9e656",
            "4da425a495a3454494e31b446e674c14",
            "41dee8ca6ebe45b3b5a7264fd8be1af8",
            "9e1debf07b5744a2b21c8f62d2f6eafb",
            "38324cc1375d4390b31541a116396d2e",
            "ac1a3f2dad5b48afaba6ef474d049ab2",
            "49030677b56245aa9140a782b97b589c",
            "a26ae8cdb42e47688a110d5197edd9e1",
            "6de416b2af7f4df6ad176e0343b03006",
            "45ee34d6d00542f1a7becf9ffcdcd571",
            "d53bffbc195649398d26e05ae2a61ce7",
            "4a82c88a41184c778424b99e4560a24f",
            "69b6ea7b2afc4b7c96d8f87b33586c14",
            "822e17bfd4d94c6da36ed07b9eb7070f",
            "380a0362cff448b7a85956bd9462b16b",
            "70d180c0399e45559456739d145cecfb",
            "553e8f8efbe94193942f31eb9a944f90",
            "be226222fd594a31b26e85d328a20e8f",
            "2f7fe48f4cce4c4ea2815155099bcf31",
            "42a17a84524747aeb326748e0561ec0b",
            "fe0a069f1c4d4d8e965f258d2e2f0fa0",
            "7f760bd67a9e4851a955f478f2e2deff",
            "64e187a029224ef0b4ec5dd1ea0a2422",
            "c1f9355bd2c1419cab2488514fc3926d",
            "122d5850bfd143faa53b6956f7eb7b04",
            "08b41e1d4407489e800b49f8d46b7805",
            "21d3e554267845b9b9ef5dcc41ae2a5d",
            "13a702b4346e4ec387c399165c78d7f9",
            "afcd0d5d36fb4ab9bdfb14aa6ee6f2e6",
            "076fc3ab131944e68a814c6e22f1237c",
            "e5350b9617aa4b2dbd8ebaa50083dd89",
            "0870aab1d9f5431a8658765a2f754c0d",
            "1288727b8f8a4e40af3d032e3f14325e",
            "6a9e9ec383564f24a1ee690e261cd806",
            "6ba720121f904cc0aaa00ce67b13e11d",
            "99f52d3074c24011a78ab53b19f4e534",
            "1a556b1a61bf49ad80361778376d1a5f",
            "cb071c0c7b6f476aa54384d347d4dbe2",
            "f16a18a763f6486899280237b16ad104",
            "35c08878c0a443c78e69fa772a24b002",
            "f9fd795048b24488a9deebffaaa30809",
            "d773106671cd41198cd7da560b770fbf",
            "8ea41b5883bc4cadb3a03b4708490736",
            "da6744741d114786b32f618dda3231f9",
            "5d2c8bc912de441fb8902e711024e919",
            "43a8e5faf8a64aa29061dee1cf044b4a",
            "bc5c2758865546618053e18f2fe9526a",
            "2ebbb0e3b1284384a8cca9dc172b6714",
            "b1d67394cef544ffb275321dc092ba76",
            "3ae7458858604f679a19d1ea3cfb2b32",
            "3be6cbd1bca94ee89e9b7f041e9a9ba0"
          ]
        },
        "id": "B2n9v_OB9Cqv",
        "outputId": "542fa90c-ea2a-471a-921e-7d6766c33772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db6ac2625e114b33aebf6c33471fe39c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a26ae8cdb42e47688a110d5197edd9e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f7fe48f4cce4c4ea2815155099bcf31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "076fc3ab131944e68a814c6e22f1237c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9fd795048b24488a9deebffaaa30809"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [215/215 21:51, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.316600</td>\n",
              "      <td>1.113009</td>\n",
              "      <td>0.819587</td>\n",
              "      <td>0.701149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.800400</td>\n",
              "      <td>0.896971</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.494300</td>\n",
              "      <td>0.861812</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.342600</td>\n",
              "      <td>0.818265</td>\n",
              "      <td>0.815536</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.8182653784751892, 'eval_f1': 0.815536202319773, 'eval_accuracy': 0.7068965517241379, 'eval_runtime': 17.6837, 'eval_samples_per_second': 9.84, 'eval_steps_per_second': 0.622, 'epoch': 4.896551724137931}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "\n",
        "# Paths and categories\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "output_model_path = r\"bloom_lstm_model\"\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare dataset\n",
        "texts, labels = [], []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization with BERT tokenizer for word embeddings\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "# Dataset Class\n",
        "class BloomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, y_train)\n",
        "test_dataset = BloomDataset(test_encodings, y_test)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# LSTM Model Definition\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, embedding_dim=768, dropout=0.5):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')  # Use BERT for embeddings\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Pass input through BERT to get embeddings\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        embedding_output = outputs.last_hidden_state  # Shape: (batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "        # LSTM layer\n",
        "        lstm_out, _ = self.lstm(embedding_output)\n",
        "        hidden_state = lstm_out[:, -1, :]  # Get the output from the last time step\n",
        "        output = self.fc(self.dropout(hidden_state))  # Fully connected layer\n",
        "        return output\n",
        "\n",
        "# Initialize Model\n",
        "model = LSTMModel(input_dim=768, hidden_dim=128, output_dim=len(bloom_categories))  # embedding_dim = 768 for BERT\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "epochs = 4\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)  # BERT input\n",
        "        attention_mask = batch['attention_mask'].to(device)  # Attention mask\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} | Average Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)  # BERT input\n",
        "            attention_mask = batch['attention_mask'].to(device)  # Attention mask\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    print(f\"Validation F1 Score: {f1:.4f} | Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Save Model\n",
        "model.save_pretrained(output_model_path)\n",
        "\n",
        "# Final Evaluation\n",
        "print(\"Training Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "dhg8ImVwMx1q",
        "outputId": "9792e47a-77ab-4d4f-99a0-2a416f4c0785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Average Training Loss: 0.9522\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n",
            "Epoch 2 | Average Training Loss: 0.8044\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n",
            "Epoch 3 | Average Training Loss: 0.7948\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n",
            "Epoch 4 | Average Training Loss: 0.7984\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LSTMModel' object has no attribute 'save_pretrained'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-17541093fd26>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m# Save Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;31m# Final Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LSTMModel' object has no attribute 'save_pretrained'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "\n",
        "# Paths and categories\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "output_model_path = r\"bloom_gru_model\"\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare dataset\n",
        "texts, labels = [], []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization with BERT tokenizer for word embeddings\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "# Dataset Class\n",
        "class BloomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, y_train)\n",
        "test_dataset = BloomDataset(test_encodings, y_test)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# GRU Model Definition\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, embedding_dim=768, dropout=0.5):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')  # Use BERT for embeddings\n",
        "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Pass input through BERT to get embeddings\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        embedding_output = outputs.last_hidden_state  # Shape: (batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "        # GRU layer\n",
        "        gru_out, _ = self.gru(embedding_output)\n",
        "        hidden_state = gru_out[:, -1, :]  # Get the output from the last time step\n",
        "        output = self.fc(self.dropout(hidden_state))  # Fully connected layer\n",
        "        return output\n",
        "\n",
        "# Initialize Model\n",
        "model = GRUModel(input_dim=768, hidden_dim=128, output_dim=len(bloom_categories))  # embedding_dim = 768 for BERT\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "epochs = 4\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)  # BERT input\n",
        "        attention_mask = batch['attention_mask'].to(device)  # Attention mask\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} | Average Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)  # BERT input\n",
        "            attention_mask = batch['attention_mask'].to(device)  # Attention mask\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    print(f\"Validation F1 Score: {f1:.4f} | Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Save Model\n",
        "model.save_pretrained(output_model_path)\n",
        "\n",
        "# Final Evaluation\n",
        "print(\"Training Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "QGkPq95jOEh6",
        "outputId": "e0986968-70c9-40f6-eb38-65927b3abc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Average Training Loss: 0.8685\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n",
            "Epoch 2 | Average Training Loss: 0.8332\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n",
            "Epoch 3 | Average Training Loss: 0.8296\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6036e7ce0c1c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "\n",
        "# Paths and categories\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare dataset\n",
        "texts, labels = [], []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization with BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "# Dataset Class\n",
        "class BloomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, y_train)\n",
        "test_dataset = BloomDataset(test_encodings, y_test)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# BERT Model Definition\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(bloom_categories))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "epochs = 4\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} | Average Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    print(f\"Validation F1 Score: {f1:.4f} | Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Save Model\n",
        "model.save_pretrained(output_model_path)\n",
        "\n",
        "# Final Evaluation\n",
        "print(\"Training Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHUnoLRfOeq5",
        "outputId": "59598294-1e63-4cf5-d8d6-5bb69f6d58c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Average Training Loss: 0.9682\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n",
            "Epoch 2 | Average Training Loss: 0.7933\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n",
            "Epoch 3 | Average Training Loss: 0.7265\n",
            "Validation F1 Score: 0.5855 | Accuracy: 0.7069\n",
            "Epoch 4 | Average Training Loss: 0.6210\n",
            "Validation F1 Score: 0.6502 | Accuracy: 0.7126\n",
            "Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "\n",
        "# Paths and categories\n",
        "dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "output_model_path = r\"bloom_bert_augmentation_model\"\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Prepare dataset with data augmentation\n",
        "def synonym_augmentation(sentence):\n",
        "    words = sentence.split()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        syns = wordnet.synsets(word)\n",
        "        if syns:\n",
        "            new_word = random.choice(syns).lemmas()[0].name()\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return \" \".join(new_words)\n",
        "\n",
        "texts, labels = [], []\n",
        "for chapter in dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "        if question and actual_bloom:\n",
        "            texts.append(question)\n",
        "            labels.append(bloom_categories.index(actual_bloom))\n",
        "            # Augmenting the data by adding a synonym replacement version\n",
        "            augmented_text = synonym_augmentation(question)\n",
        "            texts.append(augmented_text)\n",
        "            labels.append(bloom_categories.index(actual_bloom))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization with BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "# Dataset Class\n",
        "class BloomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, y_train)\n",
        "test_dataset = BloomDataset(test_encodings, y_test)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# BERT Model Definition\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(bloom_categories))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "epochs = 4\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1} | Average Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    print(f\"Validation F1 Score: {f1:.4f} | Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Save Model\n",
        "model.save_pretrained(output_model_path)\n",
        "\n",
        "# Final Evaluation\n",
        "print(\"Training Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hxNuJllBOsR0",
        "outputId": "a539b18c-a90e-47ff-afa7-eefc2752b719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9a2926ffdd3f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloom_categories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_bloom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# Augmenting the data by adding a synonym replacement version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0maugmented_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynonym_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloom_categories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_bloom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-9a2926ffdd3f>\u001b[0m in \u001b[0;36msynonym_augmentation\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnew_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msyns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msyns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mnew_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yepyRa2k_sJ",
        "outputId": "7b1463f8-8ce7-4aba-f9d4-183537aade3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute class weights to handle the imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),  # Ensure all categories are considered\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        # Removed num_labels from CrossEntropyLoss initialization\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights) # This line was modified\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Remove num_items_in_batch from kwargs if present to avoid the error\n",
        "        kwargs.pop('num_items_in_batch', None)\n",
        "\n",
        "        # remove labels from super().forward() call as it's already handled in loss_fct\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        # Modify the output to match the expected format by Trainer\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the weighted model\n",
        "# Pass num_labels explicitly during model initialization\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))  # Move class_weights to device\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',              # output directory for model checkpoints\n",
        "    num_train_epochs=3,                  # number of training epochs\n",
        "    per_device_train_batch_size=16,      # batch size for training\n",
        "    per_device_eval_batch_size=64,       # batch size for evaluation\n",
        "    warmup_steps=500,                    # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,                   # strength of weight decay\n",
        "    logging_dir='./logs',                # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",         # evaluate after each epoch\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                          # the model to be trained\n",
        "    args=training_args,                   # training arguments\n",
        "    train_dataset=train_dataset,          # training dataset\n",
        "    eval_dataset=test_dataset,            # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608,
          "referenced_widgets": [
            "87fd5e6c75cc40cb810f02fd7f7a8836",
            "2df88c3f3ee14247a33ce4444146377c",
            "8f965adaaca44a77a13af082de68937b",
            "eb7fd24f16e04a9ab88c0367a2ac1493",
            "353a528e4dd04603b77043cb19410b2d",
            "333b375ebd6946aeb49fe8deeacc6e14",
            "63595d9c2f8b429cadb831ae44b8ca33",
            "722b78a37cff43b2bd50d97813f70ca2",
            "18278ae02e274cdaacd60552f5b813f3",
            "7398e79ba56d449f9bf000891e83e17a",
            "8a9deff3af3f41fcb762a3fc0a169fc4",
            "83917399c9274ece9e496ce1926148d8",
            "781719a35bdf4b868842cc0bb915c49c",
            "7d5ae24635a943aca44bb5a5c90a2573",
            "259e5131eb6f4907abe0914b1159762f",
            "8123bd1a0824406c975727c4c33eb4ed",
            "ca4b8f82691f41378ecd1c0e5be53d3c",
            "bfbb33a3d5f1411fba9e0601e4593a14",
            "c23e8d9e4ea64fbe840c64b506629daa",
            "05223b7f8b20442aad7dd75de8d33b09",
            "1742c66bf4f145d4aaad1580eef3c08b",
            "31ab12f181354b048895b0edc15362d0",
            "13a2ead438cd4f1fa37b1951ff6dd55e",
            "9b67c7a708a94082aed81eeca52d1887",
            "f2835d9626ba4d4eb5b3e07edf0e4c8b",
            "5c2edef8783a4c5ba3bc8827e84f7ef0",
            "ccc5687e8eb545958f37a89b20f7a61e",
            "1ef3251ec5af4d228cf9e3db43fb86b6",
            "478ae864af2347e1a001347b3c134d2d",
            "057c6589f8b14857a91b37ecb7c33484",
            "2353526ea2944912b8144e60855f9256",
            "8126654d79c94073bd4365d4c36e59bf",
            "89b85af8781d4f3c8601d53ef6f9eb02",
            "51c2004178b04b27a261d35035689add",
            "30b958c41bf343f8b292374fe18f6225",
            "638d5018504a4a1b86f4fbdbd92980e2",
            "46d99e399de140898a53089a588a1de1",
            "b72d9a8aa1ae4e8abecfe74335fce9d9",
            "521de082b0b44bcdbb9701780887ca64",
            "f76c2dd6330f4297ad1974f46d206764",
            "4edd043fe13d4586afd586fa42a4971e",
            "778e3a3e89bf4898a4e15c9591930a9a",
            "908a2187f8e5417bb6564a27f29f7b0e",
            "86bd5009a60644c2a1bd67dd859a6057"
          ]
        },
        "id": "Cpu8p4tsOzBs",
        "outputId": "5b9cd088-e09e-4608-ac92-cd7aa4bc2be7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87fd5e6c75cc40cb810f02fd7f7a8836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83917399c9274ece9e496ce1926148d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13a2ead438cd4f1fa37b1951ff6dd55e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51c2004178b04b27a261d35035689add"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4289a2f2ee8>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Load the pre-trained tokenizer and model (BERT-base-cased)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-cased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-cased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloom_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Modify the model's loss function to account for class weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3540\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_adapter_model_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3541\u001b[0;31m                 _adapter_model_path = find_adapter_config_file(\n\u001b[0m\u001b[1;32m   3542\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3543\u001b[0m                     \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/peft_utils.py\u001b[0m in \u001b[0;36mfind_adapter_config_file\u001b[0;34m(model_id, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, _commit_hash)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0madapter_cached_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mADAPTER_CONFIG_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         adapter_cached_filename = cached_file(\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mADAPTER_CONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         )\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;31m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;31m# If we can't, a HEAD request error is returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m     (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# Recursively follow relative redirects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;34m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_AMZN_TRACE_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the results are: Epoch\tTraining Loss\tValidation Loss\tF1\tAccuracy\n",
        "1\t1.311800\t1.654000\t0.237986\t0.171429\n",
        "2\t1.409800\t1.960426\t0.521739\t0.428571\n",
        "3\t1.241400\t2.085874\t0.501192\t0.457143\n",
        "Evaluation Results: {'eval_loss': 2.085873603820801, 'eval_f1': 0.5011918751049186, 'eval_accuracy': 0.45714285714285713, 'eval_runtime': 0.1088, 'eval_samples_per_second': 321.798, 'eval_steps_per_second': 9.194, 'epoch': 3.0}"
      ],
      "metadata": {
        "id": "iXTsGDyiuTdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
        "\n",
        "# Plot heatmap of confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=bloom_categories, yticklabels=bloom_categories)\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "vj_Y9-hGmgWi",
        "outputId": "bda39e57-60e0-489a-ad74-5f985106e5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute class weights to handle the imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),  # Ensure all categories are considered\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        # Removed num_labels from CrossEntropyLoss initialization\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights) # This line was modified\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Remove num_items_in_batch from kwargs if present to avoid the error\n",
        "        kwargs.pop('num_items_in_batch', None)\n",
        "\n",
        "        # remove labels from super().forward() call as it's already handled in loss_fct\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        # Modify the output to match the expected format by Trainer\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the weighted model\n",
        "# Pass num_labels explicitly during model initialization\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))  # Move class_weights to device\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,  # Experiment with a lower learning rate\n",
        "    lr_scheduler_type=\"linear\",  # Linear decay schedule\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                          # the model to be trained\n",
        "    args=training_args,                   # training arguments\n",
        "    train_dataset=train_dataset,          # training dataset\n",
        "    eval_dataset=test_dataset,            # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "DW-9JlLVuzvr",
        "outputId": "5030d49b-7024-492f-8ae9-ab7b77dcfeee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 00:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.297300</td>\n",
              "      <td>1.816185</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.472300</td>\n",
              "      <td>1.859916</td>\n",
              "      <td>0.346958</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.230200</td>\n",
              "      <td>2.023634</td>\n",
              "      <td>0.523498</td>\n",
              "      <td>0.457143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 2.023634195327759, 'eval_f1': 0.5234982882041705, 'eval_accuracy': 0.45714285714285713, 'eval_runtime': 0.1084, 'eval_samples_per_second': 322.992, 'eval_steps_per_second': 9.228, 'epoch': 3.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute class weights to handle the imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),  # Ensure all categories are considered\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        # Removed num_labels from CrossEntropyLoss initialization\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights) # This line was modified\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Remove num_items_in_batch from kwargs if present to avoid the error\n",
        "        kwargs.pop('num_items_in_batch', None)\n",
        "\n",
        "        # remove labels from super().forward() call as it's already handled in loss_fct\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        # Modify the output to match the expected format by Trainer\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the weighted model\n",
        "# Pass num_labels explicitly during model initialization\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))  # Move class_weights to device\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,  # Experiment with a lower learning rate\n",
        "    lr_scheduler_type=\"linear\",  # Linear decay schedule\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                          # the model to be trained\n",
        "    args=training_args,                   # training arguments\n",
        "    train_dataset=train_dataset,          # training dataset\n",
        "    eval_dataset=test_dataset,            # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "EcNmAgtivFES",
        "outputId": "ba4cc595-b210-4d3b-fcda-0b30ce6e689a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='550' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [550/550 01:26, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.684800</td>\n",
              "      <td>1.180004</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.432900</td>\n",
              "      <td>2.079523</td>\n",
              "      <td>0.323810</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.238100</td>\n",
              "      <td>2.267164</td>\n",
              "      <td>0.374026</td>\n",
              "      <td>0.342857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.142600</td>\n",
              "      <td>2.243222</td>\n",
              "      <td>0.317302</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.741100</td>\n",
              "      <td>2.065095</td>\n",
              "      <td>0.376284</td>\n",
              "      <td>0.371429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.618900</td>\n",
              "      <td>2.262473</td>\n",
              "      <td>0.187590</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.208800</td>\n",
              "      <td>4.205311</td>\n",
              "      <td>0.310476</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.573300</td>\n",
              "      <td>4.369220</td>\n",
              "      <td>0.347368</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.126700</td>\n",
              "      <td>5.430581</td>\n",
              "      <td>0.335847</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>6.398314</td>\n",
              "      <td>0.416105</td>\n",
              "      <td>0.371429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 6.398313522338867, 'eval_f1': 0.416105303910182, 'eval_accuracy': 0.37142857142857144, 'eval_runtime': 0.1043, 'eval_samples_per_second': 335.731, 'eval_steps_per_second': 9.592, 'epoch': 10.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute class weights to handle the imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),  # Ensure all categories are considered\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        # Removed num_labels from CrossEntropyLoss initialization\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights) # This line was modified\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Remove num_items_in_batch from kwargs if present to avoid the error\n",
        "        kwargs.pop('num_items_in_batch', None)\n",
        "\n",
        "        # remove labels from super().forward() call as it's already handled in loss_fct\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        # Modify the output to match the expected format by Trainer\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the weighted model\n",
        "# Pass num_labels explicitly during model initialization\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))  # Move class_weights to device\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,  # Experiment with a lower learning rate\n",
        "    lr_scheduler_type=\"linear\",  # Linear decay schedule\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                          # the model to be trained\n",
        "    args=training_args,                   # training arguments\n",
        "    train_dataset=train_dataset,          # training dataset\n",
        "    eval_dataset=test_dataset,            # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "knVmSbWmxfO8",
        "outputId": "448279fc-1657-41c0-e103-9558bfdc8776"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 00:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.297300</td>\n",
              "      <td>1.816185</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.472300</td>\n",
              "      <td>1.859916</td>\n",
              "      <td>0.346958</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.230200</td>\n",
              "      <td>2.023634</td>\n",
              "      <td>0.523498</td>\n",
              "      <td>0.457143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 2.023634195327759, 'eval_f1': 0.5234982882041705, 'eval_accuracy': 0.45714285714285713, 'eval_runtime': 0.1081, 'eval_samples_per_second': 323.892, 'eval_steps_per_second': 9.254, 'epoch': 3.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute the class weights using class frequencies in the dataset\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        # Removed num_labels from CrossEntropyLoss initialization\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights) # This line was modified\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Remove num_items_in_batch from kwargs if present to avoid the error\n",
        "        kwargs.pop('num_items_in_batch', None)\n",
        "\n",
        "        # remove labels from super().forward() call as it's already handled in loss_fct\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        # Modify the output to match the expected format by Trainer\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the weighted model\n",
        "# Pass num_labels explicitly during model initialization\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))  # Move class_weights to device\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,  # Experiment with a lower learning rate\n",
        "    lr_scheduler_type=\"linear\",  # Linear decay schedule\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                          # the model to be trained\n",
        "    args=training_args,                   # training arguments\n",
        "    train_dataset=train_dataset,          # training dataset\n",
        "    eval_dataset=test_dataset,            # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "PMKx4Gor0Ac-",
        "outputId": "db35657c-8581-4503-afc7-30bf67fdce5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 00:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.297300</td>\n",
              "      <td>1.816185</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.472300</td>\n",
              "      <td>1.859916</td>\n",
              "      <td>0.346958</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.230200</td>\n",
              "      <td>2.023634</td>\n",
              "      <td>0.523498</td>\n",
              "      <td>0.457143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 2.023634195327759, 'eval_f1': 0.5234982882041705, 'eval_accuracy': 0.45714285714285713, 'eval_runtime': 0.1081, 'eval_samples_per_second': 323.901, 'eval_steps_per_second': 9.254, 'epoch': 3.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XyS5XuI3PME",
        "outputId": "3a9189cd-a172-46d9-e986-2dca9740663d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import optuna  # This is an optional library for hyperparameter tuning\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute the class weights using class frequencies in the dataset\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Modify the training_step method in the Trainer class\n",
        "class CustomTrainer(Trainer):\n",
        "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
        "        \"\"\"\n",
        "        Perform a training step on a batch of inputs.\n",
        "\n",
        "        Subclass and override to inject custom behavior.\n",
        "        \"\"\"\n",
        "        model.train()\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "        # Remove num_items_in_batch from inputs if present\n",
        "        if num_items_in_batch is not None and \"num_items_in_batch\" in inputs:\n",
        "            del inputs[\"num_items_in_batch\"]\n",
        "\n",
        "        with self.compute_loss_context_manager():\n",
        "            loss = self.compute_loss(model, inputs)\n",
        "\n",
        "        if self.args.gradient_accumulation_steps > 1:\n",
        "            loss = loss / self.args.gradient_accumulation_steps\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        return loss.detach()\n",
        "\n",
        "# Define hyperparameters for training (you can tune these)\n",
        "def objective(trial):\n",
        "    # Hyperparameters\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
        "    num_epochs = trial.suggest_int('num_train_epochs', 3, 5)\n",
        "\n",
        "    # Set up training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        num_train_epochs=num_epochs,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        learning_rate=learning_rate,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "    )\n",
        "\n",
        "    # Initialize the weighted model\n",
        "    model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights)\n",
        "\n",
        "    # Initialize the Trainer using the CustomTrainer class\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=lambda p: {\n",
        "            'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "            'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model\n",
        "    results = trainer.evaluate()\n",
        "    return results['eval_f1']  # Return the F1 score as the objective for Optuna optimization\n",
        "\n",
        "# Use Optuna to optimize hyperparameters\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=10)  # Adjust the number of trials\n",
        "\n",
        "print(f\"Best trial: {study.best_trial.params}\")\n",
        "\n",
        "# Use best parameters from optimization to retrain the model\n",
        "best_params = study.best_trial.params\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=best_params['num_train_epochs'],\n",
        "    per_device_train_batch_size=best_params['batch_size'],\n",
        "    per_device_eval_batch_size=best_params['batch_size'],\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    lr_scheduler_type=\"linear\",\n",
        ")\n",
        "\n",
        "# Initialize the best model\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights)\n",
        "\n",
        "# Initialize the Trainer with the best hyperparameters using the CustomTrainer class\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W1ZxGAxi3Gb8",
        "outputId": "87095d16-d1d0-4ae9-a313-dae93b2f7f35"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-01-18 19:24:53,709] A new study created in memory with name: no-name-09a81f7b-dd7a-47b8-bfd4-75029f26273e\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='436' max='436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [436/436 00:48, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.228400</td>\n",
              "      <td>1.951617</td>\n",
              "      <td>0.635165</td>\n",
              "      <td>0.485714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.241000</td>\n",
              "      <td>2.176317</td>\n",
              "      <td>0.591597</td>\n",
              "      <td>0.457143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.128700</td>\n",
              "      <td>2.065114</td>\n",
              "      <td>0.431897</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.868100</td>\n",
              "      <td>2.139396</td>\n",
              "      <td>0.245530</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:25:43,608] Trial 0 finished with value: 0.2455299539170507 and parameters: {'learning_rate': 3.238290999182408e-05, 'batch_size': 8, 'num_train_epochs': 4}. Best is trial 0 with value: 0.2455299539170507.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [112/112 00:29, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.378100</td>\n",
              "      <td>1.456800</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.383300</td>\n",
              "      <td>1.461173</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.396600</td>\n",
              "      <td>1.459915</td>\n",
              "      <td>0.246154</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.409800</td>\n",
              "      <td>1.443561</td>\n",
              "      <td>0.155844</td>\n",
              "      <td>0.171429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:26:14,580] Trial 1 finished with value: 0.15584415584415587 and parameters: {'learning_rate': 3.25227371270369e-06, 'batch_size': 32, 'num_train_epochs': 4}. Best is trial 0 with value: 0.2455299539170507.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='436' max='436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [436/436 00:45, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.381000</td>\n",
              "      <td>1.511761</td>\n",
              "      <td>0.591597</td>\n",
              "      <td>0.457143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.290600</td>\n",
              "      <td>1.604418</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.206300</td>\n",
              "      <td>1.863833</td>\n",
              "      <td>0.401088</td>\n",
              "      <td>0.342857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.154100</td>\n",
              "      <td>2.102841</td>\n",
              "      <td>0.485618</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:27:01,763] Trial 2 finished with value: 0.4856177414316949 and parameters: {'learning_rate': 3.889408227085584e-06, 'batch_size': 8, 'num_train_epochs': 4}. Best is trial 2 with value: 0.4856177414316949.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 00:36, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.378100</td>\n",
              "      <td>1.456197</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.383500</td>\n",
              "      <td>1.458849</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.397800</td>\n",
              "      <td>1.458205</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.413300</td>\n",
              "      <td>1.448921</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.360600</td>\n",
              "      <td>1.453850</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:27:39,263] Trial 3 finished with value: 0.2 and parameters: {'learning_rate': 1.9036195313760302e-06, 'batch_size': 32, 'num_train_epochs': 5}. Best is trial 2 with value: 0.4856177414316949.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [220/220 00:35, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.441000</td>\n",
              "      <td>1.296497</td>\n",
              "      <td>0.247273</td>\n",
              "      <td>0.171429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.444600</td>\n",
              "      <td>1.885324</td>\n",
              "      <td>0.213550</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.298500</td>\n",
              "      <td>1.914132</td>\n",
              "      <td>0.218776</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.232000</td>\n",
              "      <td>1.890755</td>\n",
              "      <td>0.291899</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:28:15,725] Trial 4 finished with value: 0.2918985776128633 and parameters: {'learning_rate': 1.326749277086846e-05, 'batch_size': 16, 'num_train_epochs': 4}. Best is trial 2 with value: 0.4856177414316949.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [327/327 00:34, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.252400</td>\n",
              "      <td>1.907570</td>\n",
              "      <td>0.679245</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.189600</td>\n",
              "      <td>1.649156</td>\n",
              "      <td>0.370068</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.942300</td>\n",
              "      <td>2.190430</td>\n",
              "      <td>0.475161</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:28:51,609] Trial 5 finished with value: 0.47516087516087513 and parameters: {'learning_rate': 6.107372199014388e-05, 'batch_size': 8, 'num_train_epochs': 3}. Best is trial 2 with value: 0.4856177414316949.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 00:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.354000</td>\n",
              "      <td>1.716452</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.489400</td>\n",
              "      <td>1.937109</td>\n",
              "      <td>0.390204</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.211700</td>\n",
              "      <td>1.926618</td>\n",
              "      <td>0.336996</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:29:20,370] Trial 6 finished with value: 0.33699633699633696 and parameters: {'learning_rate': 7.735738836233528e-05, 'batch_size': 16, 'num_train_epochs': 3}. Best is trial 2 with value: 0.4856177414316949.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 00:36, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.418800</td>\n",
              "      <td>1.633629</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.503900</td>\n",
              "      <td>1.624418</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.451000</td>\n",
              "      <td>1.607424</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.431400</td>\n",
              "      <td>1.577338</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.435200</td>\n",
              "      <td>1.555402</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:29:58,418] Trial 7 finished with value: 0.20512820512820512 and parameters: {'learning_rate': 2.4077633968676275e-06, 'batch_size': 32, 'num_train_epochs': 5}. Best is trial 2 with value: 0.4856177414316949.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [112/112 00:29, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.446300</td>\n",
              "      <td>1.294529</td>\n",
              "      <td>0.278571</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.391500</td>\n",
              "      <td>1.666681</td>\n",
              "      <td>0.163265</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.327400</td>\n",
              "      <td>1.905491</td>\n",
              "      <td>0.234413</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.304800</td>\n",
              "      <td>1.757256</td>\n",
              "      <td>0.035966</td>\n",
              "      <td>0.057143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:30:29,597] Trial 8 finished with value: 0.035966386554621844 and parameters: {'learning_rate': 4.108212195481191e-05, 'batch_size': 32, 'num_train_epochs': 4}. Best is trial 2 with value: 0.4856177414316949.\n",
            "<ipython-input-19-c253acef35a2>:144: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='275' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [275/275 00:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.398700</td>\n",
              "      <td>1.525687</td>\n",
              "      <td>0.548571</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.406600</td>\n",
              "      <td>1.655118</td>\n",
              "      <td>0.290598</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.299200</td>\n",
              "      <td>1.903520</td>\n",
              "      <td>0.295549</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.160700</td>\n",
              "      <td>1.863903</td>\n",
              "      <td>0.296847</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.159900</td>\n",
              "      <td>2.269075</td>\n",
              "      <td>0.586494</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:31:14,884] Trial 9 finished with value: 0.5864935064935065 and parameters: {'learning_rate': 2.1177779662998504e-05, 'batch_size': 16, 'num_train_epochs': 5}. Best is trial 9 with value: 0.5864935064935065.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: {'learning_rate': 2.1177779662998504e-05, 'batch_size': 16, 'num_train_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='275' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [275/275 00:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.424800</td>\n",
              "      <td>1.360089</td>\n",
              "      <td>0.162837</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.489500</td>\n",
              "      <td>1.928713</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.293500</td>\n",
              "      <td>1.809232</td>\n",
              "      <td>0.593407</td>\n",
              "      <td>0.485714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.199600</td>\n",
              "      <td>1.724819</td>\n",
              "      <td>0.672527</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.308500</td>\n",
              "      <td>1.569131</td>\n",
              "      <td>0.349129</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 1.5691314935684204, 'eval_f1': 0.34912891986062716, 'eval_accuracy': 0.3142857142857143, 'eval_runtime': 0.0933, 'eval_samples_per_second': 375.039, 'eval_steps_per_second': 32.146, 'epoch': 5.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import optuna  # This is an optional library for hyperparameter tuning\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute the class weights using class frequencies in the dataset\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Modify the training_step method in the Trainer class\n",
        "class CustomTrainer(Trainer):\n",
        "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
        "        model.train()\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "        if num_items_in_batch is not None and \"num_items_in_batch\" in inputs:\n",
        "            del inputs[\"num_items_in_batch\"]\n",
        "\n",
        "        with self.compute_loss_context_manager():\n",
        "            loss = self.compute_loss(model, inputs)\n",
        "\n",
        "        if self.args.gradient_accumulation_steps > 1:\n",
        "            loss = loss / self.args.gradient_accumulation_steps\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        return loss.detach()\n",
        "\n",
        "# Hyperparameter optimization with Optuna\n",
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
        "    num_epochs = trial.suggest_int('num_train_epochs', 3, 5)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        num_train_epochs=num_epochs,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        learning_rate=learning_rate,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "    )\n",
        "\n",
        "    model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights)\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=lambda p: {\n",
        "            'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "            'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    results = trainer.evaluate()\n",
        "    return results['eval_f1']\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "best_params = study.best_trial.params\n",
        "print(f\"Best trial: {study.best_trial.params}\")\n",
        "\n",
        "# Using best hyperparameters to retrain the model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=best_params['num_train_epochs'],\n",
        "    per_device_train_batch_size=best_params['batch_size'],\n",
        "    per_device_eval_batch_size=best_params['batch_size'],\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    lr_scheduler_type=\"linear\",\n",
        ")\n",
        "\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights)\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),\n",
        "    }\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_labels, predicted_labels)\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=bloom_categories, yticklabels=bloom_categories)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Save faulty predictions\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9-5GTFde6FWn",
        "outputId": "fa1e1b9f-ab71-40f0-ad8c-d43629ec1e7e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-01-18 19:34:00,833] A new study created in memory with name: no-name-37eb0e52-e795-4a85-8579-775f33303bd7\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='436' max='436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [436/436 00:45, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.311200</td>\n",
              "      <td>1.893057</td>\n",
              "      <td>0.373076</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.280500</td>\n",
              "      <td>2.032562</td>\n",
              "      <td>0.294678</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.956500</td>\n",
              "      <td>2.128058</td>\n",
              "      <td>0.293307</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.933800</td>\n",
              "      <td>2.678944</td>\n",
              "      <td>0.254222</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:34:48,103] Trial 0 finished with value: 0.2542222222222223 and parameters: {'learning_rate': 3.8869219786494705e-05, 'batch_size': 8, 'num_train_epochs': 4}. Best is trial 0 with value: 0.2542222222222223.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [220/220 00:35, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.413400</td>\n",
              "      <td>1.468024</td>\n",
              "      <td>0.288502</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.402500</td>\n",
              "      <td>1.483370</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.373800</td>\n",
              "      <td>1.507512</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.345000</td>\n",
              "      <td>1.531772</td>\n",
              "      <td>0.359184</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:35:25,314] Trial 1 finished with value: 0.3591836734693878 and parameters: {'learning_rate': 2.4405965058658277e-06, 'batch_size': 16, 'num_train_epochs': 4}. Best is trial 1 with value: 0.3591836734693878.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [112/112 00:29, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.378100</td>\n",
              "      <td>1.456886</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.383300</td>\n",
              "      <td>1.461497</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.396400</td>\n",
              "      <td>1.460144</td>\n",
              "      <td>0.246154</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.409300</td>\n",
              "      <td>1.442733</td>\n",
              "      <td>0.155844</td>\n",
              "      <td>0.171429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:35:56,458] Trial 2 finished with value: 0.15584415584415587 and parameters: {'learning_rate': 3.4466599797495684e-06, 'batch_size': 32, 'num_train_epochs': 4}. Best is trial 1 with value: 0.3591836734693878.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 00:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.413700</td>\n",
              "      <td>1.466300</td>\n",
              "      <td>0.288502</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.402500</td>\n",
              "      <td>1.479826</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.375800</td>\n",
              "      <td>1.500734</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:36:25,381] Trial 3 finished with value: 0.37142857142857144 and parameters: {'learning_rate': 2.093612813620588e-06, 'batch_size': 16, 'num_train_epochs': 3}. Best is trial 3 with value: 0.37142857142857144.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [220/220 00:35, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.548300</td>\n",
              "      <td>1.631870</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.477300</td>\n",
              "      <td>1.622399</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.445300</td>\n",
              "      <td>1.605884</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.370000</td>\n",
              "      <td>1.583001</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:37:02,430] Trial 4 finished with value: 0.20512820512820512 and parameters: {'learning_rate': 1.385820528433939e-06, 'batch_size': 16, 'num_train_epochs': 4}. Best is trial 3 with value: 0.37142857142857144.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 00:36, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.377700</td>\n",
              "      <td>1.463583</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.381300</td>\n",
              "      <td>1.481492</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.385300</td>\n",
              "      <td>1.471916</td>\n",
              "      <td>0.236296</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.368700</td>\n",
              "      <td>1.362737</td>\n",
              "      <td>0.115964</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.286800</td>\n",
              "      <td>1.513667</td>\n",
              "      <td>0.189648</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:37:40,451] Trial 5 finished with value: 0.189648033126294 and parameters: {'learning_rate': 1.8797485342549577e-05, 'batch_size': 32, 'num_train_epochs': 5}. Best is trial 3 with value: 0.37142857142857144.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='436' max='436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [436/436 00:46, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.268500</td>\n",
              "      <td>1.892135</td>\n",
              "      <td>0.133687</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.291600</td>\n",
              "      <td>1.989555</td>\n",
              "      <td>0.621714</td>\n",
              "      <td>0.485714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.140200</td>\n",
              "      <td>2.064756</td>\n",
              "      <td>0.637299</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.023500</td>\n",
              "      <td>2.155448</td>\n",
              "      <td>0.672527</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:38:27,817] Trial 6 finished with value: 0.6725274725274725 and parameters: {'learning_rate': 1.365083723480555e-05, 'batch_size': 8, 'num_train_epochs': 4}. Best is trial 6 with value: 0.6725274725274725.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [327/327 00:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.362600</td>\n",
              "      <td>1.557821</td>\n",
              "      <td>0.679245</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.259400</td>\n",
              "      <td>1.733681</td>\n",
              "      <td>0.352137</td>\n",
              "      <td>0.314286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.084700</td>\n",
              "      <td>2.207338</td>\n",
              "      <td>0.513623</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:39:04,171] Trial 7 finished with value: 0.5136231884057971 and parameters: {'learning_rate': 8.826880675023355e-06, 'batch_size': 8, 'num_train_epochs': 3}. Best is trial 6 with value: 0.6725274725274725.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='436' max='436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [436/436 00:46, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.413700</td>\n",
              "      <td>1.607571</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.256500</td>\n",
              "      <td>1.823038</td>\n",
              "      <td>0.415782</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.113000</td>\n",
              "      <td>2.070593</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.342857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.982100</td>\n",
              "      <td>2.116323</td>\n",
              "      <td>0.485618</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:39:51,502] Trial 8 finished with value: 0.4856177414316949 and parameters: {'learning_rate': 9.103868534318688e-06, 'batch_size': 8, 'num_train_epochs': 4}. Best is trial 6 with value: 0.6725274725274725.\n",
            "<ipython-input-20-82e883ff9092>:139: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='545' max='545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [545/545 00:58, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.393000</td>\n",
              "      <td>1.480325</td>\n",
              "      <td>0.411429</td>\n",
              "      <td>0.342857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.309200</td>\n",
              "      <td>1.521046</td>\n",
              "      <td>0.542274</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.287500</td>\n",
              "      <td>1.593006</td>\n",
              "      <td>0.548571</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.309900</td>\n",
              "      <td>1.686940</td>\n",
              "      <td>0.635165</td>\n",
              "      <td>0.485714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.201200</td>\n",
              "      <td>1.804353</td>\n",
              "      <td>0.453755</td>\n",
              "      <td>0.371429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-18 19:40:51,575] Trial 9 finished with value: 0.45375494071146244 and parameters: {'learning_rate': 1.3315540753894772e-06, 'batch_size': 8, 'num_train_epochs': 5}. Best is trial 6 with value: 0.6725274725274725.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: {'learning_rate': 1.365083723480555e-05, 'batch_size': 8, 'num_train_epochs': 4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='436' max='436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [436/436 00:46, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.268500</td>\n",
              "      <td>1.892135</td>\n",
              "      <td>0.133687</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.291600</td>\n",
              "      <td>1.989555</td>\n",
              "      <td>0.621714</td>\n",
              "      <td>0.485714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.140200</td>\n",
              "      <td>2.064756</td>\n",
              "      <td>0.637299</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.023500</td>\n",
              "      <td>2.155448</td>\n",
              "      <td>0.672527</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 2.1554479598999023, 'eval_f1': 0.6725274725274725, 'eval_accuracy': 0.5142857142857142, 'eval_runtime': 0.1141, 'eval_samples_per_second': 306.781, 'eval_steps_per_second': 43.826, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from torch import nn\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_t5_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert labels to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute the class weights using class frequencies in the dataset\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "train_encodings = tokenize_function(train_texts)\n",
        "test_encodings = tokenize_function(test_texts)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Modify the T5 model for classification\n",
        "class WeightedLossModel(T5ForConditionalGeneration):\n",
        "    def __init__(self, config, class_weights, num_labels):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "        # Add a classification head\n",
        "        self.classification_head = nn.Linear(config.d_model, num_labels)\n",
        "\n",
        "        # Use weighted cross-entropy loss\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Forward pass through the T5 encoder\n",
        "        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "\n",
        "        # Average the encoder's output to create a pooled representation\n",
        "        pooled_output = encoder_outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "        # Pass through the classification head\n",
        "        logits = self.classification_head(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, logits)\n",
        "\n",
        "# Load the modified model\n",
        "model = WeightedLossModel.from_pretrained(\n",
        "    \"t5-base\",\n",
        "    config=T5ForConditionalGeneration.from_pretrained(\"t5-base\").config,\n",
        "    class_weights=class_weights,\n",
        "    num_labels=len(bloom_categories),\n",
        ")\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.label_ids, p.predictions.argmax(axis=-1), average='weighted'),\n",
        "        'accuracy': accuracy_score(p.label_ids, p.predictions.argmax(axis=-1)),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "H9IF36LP_Yrh",
        "outputId": "2de5ed8b-6298-4865-d816-9a55a135d257"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at t5-base and are newly initialized: ['classification_head.bias', 'classification_head.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 00:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2722494075204927098162083583229952.000000</td>\n",
              "      <td>3590955806897106117793909491892224.000000</td>\n",
              "      <td>0.361757</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2813583188823592175369039640526848.000000</td>\n",
              "      <td>3590877197704611496146453397504000.000000</td>\n",
              "      <td>0.361757</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2846341805731169995863776166936576.000000</td>\n",
              "      <td>3590760212370899027710475430264832.000000</td>\n",
              "      <td>0.361757</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 3.590760212370899e+33, 'eval_f1': 0.3617571059431524, 'eval_accuracy': 0.42857142857142855, 'eval_runtime': 0.1489, 'eval_samples_per_second': 235.113, 'eval_steps_per_second': 20.153, 'epoch': 3.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute the class weights using class frequencies in the dataset\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        # Removed num_labels from CrossEntropyLoss initialization\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights) # This line was modified\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Remove num_items_in_batch from kwargs if present to avoid the error\n",
        "        kwargs.pop('num_items_in_batch', None)\n",
        "\n",
        "        # remove labels from super().forward() call as it's already handled in loss_fct\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        # Modify the output to match the expected format by Trainer\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the weighted model\n",
        "# Pass num_labels explicitly during model initialization\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))  # Move class_weights to device\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,  # Experiment with a lower learning rate\n",
        "    lr_scheduler_type=\"linear\",  # Linear decay schedule\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                          # the model to be trained\n",
        "    args=training_args,                   # training arguments\n",
        "    train_dataset=train_dataset,          # training dataset\n",
        "    eval_dataset=test_dataset,            # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "id": "jzdBK4bU0XbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_distilbert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute class weights to handle the imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (DistilBERT)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(DistilBertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Accept and ignore num_items_in_batch argument\n",
        "        num_items_in_batch = kwargs.pop(\"num_items_in_batch\", None)  # Remove it from kwargs\n",
        "\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = WeightedLossModel.from_pretrained(\"distilbert-base-uncased\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "G_A9oze-1Jl7",
        "outputId": "9d9dd2fb-9afb-48e9-e616-00b97d5c774f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'loss_fct.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 00:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.328100</td>\n",
              "      <td>1.594073</td>\n",
              "      <td>0.456774</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.451400</td>\n",
              "      <td>1.946248</td>\n",
              "      <td>0.399398</td>\n",
              "      <td>0.371429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.217500</td>\n",
              "      <td>2.062242</td>\n",
              "      <td>0.370952</td>\n",
              "      <td>0.257143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 2.062241554260254, 'eval_f1': 0.37095176966807264, 'eval_accuracy': 0.2571428571428571, 'eval_runtime': 0.0563, 'eval_samples_per_second': 622.002, 'eval_steps_per_second': 17.771, 'epoch': 3.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_roberta_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute class weights to handle the imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (RoBERTa)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(RobertaForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Accept and ignore num_items_in_batch argument\n",
        "        num_items_in_batch = kwargs.pop(\"num_items_in_batch\", None)  # Remove it from kwargs if present\n",
        "\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = WeightedLossModel.from_pretrained(\"roberta-base\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "M8YqrIvn1oNm",
        "outputId": "1fab9d7a-c184-4ab8-93cb-f8bf78f8b8b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of WeightedLossModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'loss_fct.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 00:29, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.383100</td>\n",
              "      <td>1.466212</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.559000</td>\n",
              "      <td>2.014393</td>\n",
              "      <td>0.158095</td>\n",
              "      <td>0.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.299200</td>\n",
              "      <td>2.146624</td>\n",
              "      <td>0.370068</td>\n",
              "      <td>0.228571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 2.1466238498687744, 'eval_f1': 0.37006802721088433, 'eval_accuracy': 0.22857142857142856, 'eval_runtime': 0.0869, 'eval_samples_per_second': 402.554, 'eval_steps_per_second': 11.502, 'epoch': 3.0}\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"qg_train_v0.json\"\n",
        "test_dataset_path = r\"qg_valid_v0.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "output_model_path = r\"bloom_bert_model\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset (eduqg_evaluation_bloom_cleaned)\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset (eduqg_few_shot_bloom_cleaned)\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))  # Map Bloom taxonomy category to index\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute class weights to handle the imbalance\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),  # Ensure all categories are considered\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load the pre-trained tokenizer and model (BERT-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories))\n",
        "\n",
        "# Modify the model's loss function to account for class weights\n",
        "class WeightedLossModel(BertForSequenceClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        # Removed num_labels from CrossEntropyLoss initialization\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=self.class_weights) # This line was modified\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        # Remove num_items_in_batch from kwargs if present to avoid the error\n",
        "        kwargs.pop('num_items_in_batch', None)\n",
        "\n",
        "        # remove labels from super().forward() call as it's already handled in loss_fct\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        # Modify the output to match the expected format by Trainer\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the weighted model\n",
        "# Pass num_labels explicitly during model initialization\n",
        "model = WeightedLossModel.from_pretrained(\"bert-base-cased\", num_labels=len(bloom_categories), class_weights=class_weights.to(device))  # Move class_weights to device\n",
        "\n",
        "# Tokenize the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, train_labels)\n",
        "test_dataset = BloomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,  # Experiment with a lower learning rate\n",
        "    lr_scheduler_type=\"linear\",  # Linear decay schedule\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                          # the model to be trained\n",
        "    args=training_args,                   # training arguments\n",
        "    train_dataset=train_dataset,          # training dataset\n",
        "    eval_dataset=test_dataset,            # evaluation dataset\n",
        "    compute_metrics=lambda p: {\n",
        "        'f1': f1_score(p.predictions.argmax(axis=-1), p.label_ids, average='weighted'),\n",
        "        'accuracy': accuracy_score(p.predictions.argmax(axis=-1), p.label_ids),  # Accuracy calculation\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(output_model_path)\n",
        "tokenizer.save_pretrained(output_model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predicted_labels[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "# Save faulty predictions to a file\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "PQnifo6RqNoU",
        "outputId": "301fe580-0945-48c2-9baa-6462601c305e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "classes should have valid labels that are in y",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3df292f6b880>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Compute class weights to handle the imbalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m class_weights = compute_class_weight(\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloom_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Ensure all categories are considered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/class_weight.py\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[0;34m(class_weight, classes, y)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0my_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classes should have valid labels that are in y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mrecip_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: classes should have valid labels that are in y"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torch torchvision torchaudio\n",
        "!pip install --force-reinstall torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DF_xmcHmITuv",
        "outputId": "932d0c4b-6173-4d32-ff17-42349dd2019f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Downloading numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.5\n",
            "    Uninstalling Jinja2-3.1.5:\n",
            "      Successfully uninstalled Jinja2-3.1.5\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.2 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.2 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.2.2 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "langchain 0.3.14 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.12.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-11.1.0 sympy-1.13.1 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1 triton-3.1.0 typing-extensions-4.12.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "torch",
                  "torchgen"
                ]
              },
              "id": "7fea051f73d043c7b724cabbfcd5d858"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Using cached torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting tqdm (from torchtext)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from torchtext)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting torch>=2.3.0 (from torchtext)\n",
            "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting numpy (from torchtext)\n",
            "  Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting filelock (from torch>=2.3.0->torchtext)\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch>=2.3.0->torchtext)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch>=2.3.0->torchtext)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=2.3.0->torchtext)\n",
            "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch>=2.3.0->torchtext)\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch>=2.3.0->torchtext)\n",
            "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting sympy==1.13.1 (from torch>=2.3.0->torchtext)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2.3.0->torchtext)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torchtext)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchtext)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torchtext)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchtext)\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.3.0->torchtext)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Using cached torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m20.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchtext\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.2\n",
            "    Uninstalling numpy-2.2.2:\n",
            "      Successfully uninstalled numpy-2.2.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.12.0\n",
            "    Uninstalling fsspec-2024.12.0:\n",
            "      Successfully uninstalled fsspec-2024.12.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.12.14\n",
            "    Uninstalling certifi-2024.12.14:\n",
            "      Successfully uninstalled certifi-2024.12.14\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.5\n",
            "    Uninstalling Jinja2-3.1.5:\n",
            "      Successfully uninstalled Jinja2-3.1.5\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1\n",
            "    Uninstalling torch-2.5.1:\n",
            "      Successfully uninstalled torch-2.5.1\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y310LQbXJxxs",
        "outputId": "1f69fcbe-901b-4ec5-f990-31d637fb6ba5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp311-cp311-linux_x86_64.whl (838.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.4/838.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy==1.13.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy (from torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.2\n",
            "    Uninstalling numpy-2.2.2:\n",
            "      Successfully uninstalled numpy-2.2.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.12.0\n",
            "    Uninstalling fsspec-2024.12.0:\n",
            "      Successfully uninstalled fsspec-2024.12.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.5\n",
            "    Uninstalling Jinja2-3.1.5:\n",
            "      Successfully uninstalled Jinja2-3.1.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1\n",
            "    Uninstalling torch-2.5.1:\n",
            "      Successfully uninstalled torch-2.5.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1\n",
            "    Uninstalling torchvision-0.20.1:\n",
            "      Successfully uninstalled torchvision-0.20.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1\n",
            "    Uninstalling torchaudio-2.5.1:\n",
            "      Successfully uninstalled torchaudio-2.5.1\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\n",
            "openai 1.59.6 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.9.0 which is incompatible.\n",
            "pydantic 2.10.5 requires typing-extensions>=4.12.2, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pillow-10.2.0 sympy-1.13.1 torch torchaudio-2.5.1+cu118 torchvision-0.20.1+cu118 triton-3.1.0 typing-extensions-4.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "8bbed7695f264442b36b2d162abc83d6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QnN4374kJx1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, optim\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define dataset paths\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the datasets\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the datasets\n",
        "def extract_texts_and_labels(dataset, categories):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for chapter in dataset:\n",
        "        for question_item in chapter.get('questions', []):\n",
        "            question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "            actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "            if question and actual_bloom:\n",
        "                texts.append(question)\n",
        "                labels.append(categories.index(actual_bloom))\n",
        "    return texts, np.array(labels)\n",
        "\n",
        "train_texts, train_labels = extract_texts_and_labels(train_dataset, bloom_categories)\n",
        "test_texts, test_labels = extract_texts_and_labels(test_dataset, bloom_categories)\n",
        "\n",
        "# Build vocabulary and tokenize\n",
        "def build_vocab_and_tokenize(texts):\n",
        "    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
        "    tokenizer = lambda text: text.lower().split()\n",
        "    for text in texts:\n",
        "        for token in tokenizer(text):\n",
        "            if token not in vocab:\n",
        "                vocab[token] = len(vocab)\n",
        "    return vocab, tokenizer\n",
        "\n",
        "vocab, tokenizer = build_vocab_and_tokenize(train_texts)\n",
        "\n",
        "# Encode and pad sequences\n",
        "def encode_and_pad(texts, vocab, tokenizer, max_len):\n",
        "    sequences = []\n",
        "    for text in texts:\n",
        "        tokens = tokenizer(text)\n",
        "        encoded = [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
        "        padded = encoded[:max_len] + [vocab[\"<pad>\"]] * max(0, max_len - len(encoded))\n",
        "        sequences.append(padded)\n",
        "    return torch.tensor(sequences, dtype=torch.long)\n",
        "\n",
        "max_len = 50\n",
        "train_encodings = encode_and_pad(train_texts, vocab, tokenizer, max_len)\n",
        "test_encodings = encode_and_pad(test_texts, vocab, tokenizer, max_len)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced', classes=np.arange(len(bloom_categories)), y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encodings[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, torch.tensor(train_labels, dtype=torch.long))\n",
        "test_dataset = BloomDataset(test_encodings, torch.tensor(test_labels, dtype=torch.long))\n",
        "# Data loaders\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, class_weights):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    def forward(self, x, labels=None):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_out = lstm_out[:, -1, :]  # Use the last hidden state\n",
        "        logits = self.fc(lstm_out)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fct(logits, labels)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "# Model setup\n",
        "embed_size = 128\n",
        "hidden_size = 256\n",
        "output_size = len(bloom_categories)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model = LSTMClassifier(vocab_size, embed_size, hidden_size, output_size, class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "\n",
        "def train_epoch(model, data_loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        inputs, labels = [x.to(device) for x in batch]\n",
        "        optimizer.zero_grad()\n",
        "        logits, loss = model(inputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            inputs, labels = [x.to(device) for x in batch]\n",
        "            logits, _ = model(inputs)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "# Evaluate and save results\n",
        "predictions, true_labels = evaluate(model, test_loader)\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "print(f\"Test Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predictions[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ghdRGwbtIEk5",
        "outputId": "968877c1-cd48-4c0b-f754-b629fd6379b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.4157\n",
            "Epoch 2/5, Loss: 1.3566\n",
            "Epoch 3/5, Loss: 1.3620\n",
            "Epoch 4/5, Loss: 1.3466\n",
            "Epoch 5/5, Loss: 1.3662\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6d3b5abaa3a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;31m# Evaluate and save results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6d3b5abaa3a1>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, optim\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            inputs, labels = [x.to(device) for x in batch]\n",
        "            logits, _ = model(inputs)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().tolist())\n",
        "            all_labels.extend(labels.cpu().tolist())\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "# Evaluate and save results\n",
        "predictions, true_labels = evaluate(model, test_loader)\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "print(f\"Test Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Save faulty predictions\n",
        "faulty_predictions = [\n",
        "    {\n",
        "        \"question\": text,\n",
        "        \"actual_bloom\": bloom_categories[true_label],\n",
        "        \"predicted_bloom\": bloom_categories[predicted]\n",
        "    }\n",
        "    for text, true_label, predicted in zip(test_texts, test_labels, predictions)\n",
        "    if true_label != predicted\n",
        "]\n",
        "\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wHKdfwTSGSf",
        "outputId": "69550302-e213-4aa5-a651-4ca5588eee1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.3453\n",
            "Epoch 2/5, Loss: 1.3467\n",
            "Epoch 3/5, Loss: 1.3731\n",
            "Epoch 4/5, Loss: 1.3606\n",
            "Epoch 5/5, Loss: 1.3527\n",
            "Test Accuracy: 0.5143, F1 Score: 0.3493\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.0.1+cu118 torchtext==2.0.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3N_daqNLCpN",
        "outputId": "c223008f-756a-4151-8c98-e9ca9daecfcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext==2.0.1+cu118 (from versions: 0.1.1, 0.2.0, 0.2.1, 0.2.3, 0.3.1, 0.4.0, 0.5.0, 0.6.0, 0.15.0+cpu, 0.15.1, 0.15.1+cpu, 0.15.2, 0.15.2+cpu, 0.16.0, 0.16.0+cpu, 0.16.1, 0.16.1+cpu, 0.16.2, 0.16.2+cpu, 0.17.0, 0.17.0+cpu, 0.17.1, 0.17.1+cpu, 0.17.2, 0.17.2+cpu, 0.18.0, 0.18.0+cpu)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext==2.0.1+cu118\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchtext --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XylF_aSZKhMK",
        "outputId": "c65c5f43-7508-4f91-f6f4-3840fd9ce2ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torchtext\n",
            "  Using cached torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting tqdm (from torchtext)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting requests (from torchtext)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting torch>=2.3.0 (from torchtext)\n",
            "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting numpy (from torchtext)\n",
            "  Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting filelock (from torch>=2.3.0->torchtext)\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch>=2.3.0->torchtext)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch>=2.3.0->torchtext)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=2.3.0->torchtext)\n",
            "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch>=2.3.0->torchtext)\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch>=2.3.0->torchtext)\n",
            "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting sympy==1.13.1 (from torch>=2.3.0->torchtext)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2.3.0->torchtext)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torchtext)\n",
            "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchtext)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torchtext)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchtext)\n",
            "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.3.0->torchtext)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Using cached torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchtext\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Attempting uninstall: tqdm\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.3\n",
            "    Uninstalling numpy-1.26.3:\n",
            "      Successfully uninstalled numpy-1.26.3\n",
            "  Attempting uninstall: networkx\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: idna\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.2.0\n",
            "    Uninstalling fsspec-2024.2.0:\n",
            "      Successfully uninstalled fsspec-2024.2.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.13.1\n",
            "    Uninstalling filelock-3.13.1:\n",
            "      Successfully uninstalled filelock-3.13.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: certifi 2024.12.14\n",
            "    Uninstalling certifi-2024.12.14:\n",
            "      Successfully uninstalled certifi-2024.12.14\n",
            "  Attempting uninstall: triton\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.2 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.2 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.2.2 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "langchain 0.3.14 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 certifi-2024.12.14 charset-normalizer-3.4.1 filelock-3.16.1 fsspec-2024.12.0 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 requests-2.32.3 sympy-1.13.1 torch-2.5.1 torchtext-0.18.0 tqdm-4.67.1 triton-3.1.0 typing-extensions-4.12.2 urllib3-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "torch",
                  "torchgen",
                  "tqdm"
                ]
              },
              "id": "2e4116cb406d4fa18e6569231b6ae502"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import os\n",
        "\n",
        "# Disable W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Define the paths for your dataset\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "faulty_predictions_path = r\"faulty_predictions.json\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load the training dataset\n",
        "with open(train_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    train_dataset = json.load(f)\n",
        "\n",
        "# Load the test dataset\n",
        "with open(test_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "# Prepare the dataset\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "for chapter in train_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            train_texts.append(question)\n",
        "            train_labels.append(bloom_categories.index(actual_bloom))\n",
        "\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for chapter in test_dataset:\n",
        "    for question_item in chapter.get('questions', []):\n",
        "        question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "        actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "\n",
        "        if question and actual_bloom:\n",
        "            test_texts.append(question)\n",
        "            test_labels.append(bloom_categories.index(actual_bloom))\n",
        "\n",
        "# Convert labels to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Compute the class weights\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.arange(len(bloom_categories)),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Tokenization and Vocabulary\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "\n",
        "def yield_tokens(texts):\n",
        "    for text in texts:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_texts), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "# Encode texts\n",
        "def encode_texts(texts):\n",
        "    return [torch.tensor(vocab(tokenizer(text)), dtype=torch.long) for text in texts]\n",
        "\n",
        "\n",
        "train_encodings = encode_texts(train_texts)\n",
        "test_encodings = encode_texts(test_texts)\n",
        "\n",
        "# Pad sequences\n",
        "def pad_sequences(sequences, max_len):\n",
        "    padded_sequences = torch.zeros((len(sequences), max_len), dtype=torch.long)\n",
        "    for i, seq in enumerate(sequences):\n",
        "        length = min(len(seq), max_len)\n",
        "        padded_sequences[i, :length] = seq[:length]\n",
        "    return padded_sequences\n",
        "\n",
        "\n",
        "max_len = 50  # Maximum sequence length\n",
        "train_encodings = pad_sequences(train_encodings, max_len)\n",
        "test_encodings = pad_sequences(test_encodings, max_len)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BloomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encodings[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_dataset = BloomDataset(train_encodings, torch.tensor(train_labels, dtype=torch.long))\n",
        "test_dataset = BloomDataset(test_encodings, torch.tensor(test_labels, dtype=torch.long))\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define the GRU model\n",
        "class GRUClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, class_weights):\n",
        "        super(GRUClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    def forward(self, x, labels=None):\n",
        "        x = self.embedding(x)\n",
        "        gru_out, _ = self.gru(x)\n",
        "        gru_out = gru_out[:, -1, :]  # Use the last hidden state\n",
        "        logits = self.fc(gru_out)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fct(logits, labels)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "embed_size = 128\n",
        "hidden_size = 256\n",
        "output_size = len(bloom_categories)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model = GRUClassifier(vocab_size, embed_size, hidden_size, output_size, class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "\n",
        "\n",
        "def train_epoch(model, data_loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        inputs, labels = [x.to(device) for x in batch]\n",
        "        optimizer.zero_grad()\n",
        "        logits, loss = model(inputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_labels in data_loader:\n",
        "            outputs = model(batch_data)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.tolist())  # Use .tolist() instead of .numpy()\n",
        "            all_labels.extend(batch_labels.tolist())  # Use .tolist() instead of .numpy()\n",
        "    return all_preds, all_labels\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions, true_labels = evaluate(model, test_loader)\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "print(f\"Test Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Save faulty predictions\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predictions[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "fdeEilCYI89C",
        "outputId": "f8d994bc-f0e2-4639-b621-99b2c8ec3fb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.4796\n",
            "Epoch 2/5, Loss: 1.3798\n",
            "Epoch 3/5, Loss: 1.3248\n",
            "Epoch 4/5, Loss: 1.2190\n",
            "Epoch 5/5, Loss: 0.9648\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5cd0492f155a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;31m# Evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-5cd0492f155a>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True,  # Annotate cells with the counts\n",
        "    fmt='d',  # Integer format\n",
        "    cmap='Blues',  # Color map\n",
        "    xticklabels=bloom_categories,  # Predicted labels\n",
        "    yticklabels=bloom_categories  # Actual labels\n",
        ")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "jxmOQx52SsnQ",
        "outputId": "2bb273bc-3528-424f-af44-c332bd99af0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAJOCAYAAABrxbsfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAds1JREFUeJzt3XlcVOX7//H3oGyKoOAGqWBiiPuaa4ppmblbuWSJa1auqWVWplhJmpprWmaiZuqnXDJtcdfMJTdcyj3MTMgVFRdUOL8/+jnfRlBBZjgDvJ49zuPh3OfMua+ZubVrrrnPfSyGYRgCAAAA4DAuZgcAAAAAZHck3QAAAICDkXQDAAAADkbSDQAAADgYSTcAAADgYCTdAAAAgIORdAMAAAAORtINAAAAOBhJNwAAAOBgJN0A0uTIkSN68skn5ePjI4vFoqVLl9r1/MePH5fFYlFUVJRdz5uVhYWFKSwszOwwAAB2QNINZCHHjh1Tr1699PDDD8vDw0Pe3t6qW7euJk6cqGvXrjm07/DwcO3bt08ffPCB5s6dq+rVqzu0v8zUpUsXWSwWeXt7p/o+HjlyRBaLRRaLRWPHjk33+U+dOqURI0YoOjraDtE+OIvFoj59+qS6LyoqShaLRTt27HBY/87yPgCAGXKbHQCAtFmxYoWee+45ubu7q3Pnzipfvrxu3LihTZs26fXXX9dvv/2mzz77zCF9X7t2TVu2bNHbb79916QtowIDA3Xt2jW5uro65Pz3kzt3bl29elXfffed2rVrZ7Nv3rx58vDw0PXr1x/o3KdOnVJERISCgoJUuXLlND9v5cqVD9Sfs3rQ9wEAsgOSbiALiImJUYcOHRQYGKi1a9fK39/fuq937946evSoVqxY4bD+z5w5I0nKnz+/w/qwWCzy8PBw2Pnvx93dXXXr1tX8+fNTJN1fffWVmjVrpkWLFmVKLFevXlWePHnk5uaWKf0BAByP6SVAFjBmzBglJCRo5syZNgn3bcHBwerfv7/18a1bt/Tee++pVKlScnd3V1BQkN566y0lJibaPC8oKEjNmzfXpk2b9Oijj8rDw0MPP/yw5syZYz1mxIgRCgwMlCS9/vrrslgsCgoKkvTvtIzbf/6vESNGyGKx2LStWrVK9erVU/78+eXl5aWQkBC99dZb1v13m9O9du1aPfbYY8qbN6/y58+vVq1a6cCBA6n2d/ToUXXp0kX58+eXj4+PunbtqqtXr979jb3D888/rx9++EHx8fHWtu3bt+vIkSN6/vnnUxx//vx5DR48WBUqVJCXl5e8vb3VtGlT7dmzx3rM+vXrVaNGDUlS165drdNUbr/OsLAwlS9fXjt37lT9+vWVJ08e6/ty55zu8PBweXh4pHj9TZo0UYECBXTq1Kk0v9a0OnjwoJ599ln5+vrKw8ND1atX17Jlyxz2Puzdu1cNGjRQnjx5FBwcrG+++UaStGHDBtWsWVOenp4KCQnR6tWrbWL4888/9eqrryokJESenp7y8/PTc889p+PHj9scd3sazcaNG9WrVy/5+fnJ29tbnTt31oULF+z87gHA/yHpBrKA7777Tg8//LDq1KmTpuN79Oihd999V1WrVtXHH3+sBg0aKDIyUh06dEhx7NGjR/Xss8/qiSee0Lhx41SgQAF16dJFv/32mySpbdu2+vjjjyVJHTt21Ny5czVhwoR0xf/bb7+pefPmSkxM1MiRIzVu3Di1bNlSv/zyyz2ft3r1ajVp0kSnT5/WiBEjNHDgQG3evFl169ZNkUxJUrt27XT58mVFRkaqXbt2ioqKUkRERJrjbNu2rSwWixYvXmxt++qrr1SmTBlVrVo1xfF//PGHli5dqubNm2v8+PF6/fXXtW/fPjVo0MCaAIeGhmrkyJGSpJdeeklz587V3LlzVb9+fet5zp07p6ZNm6py5cqaMGGCGjZsmGp8EydOVKFChRQeHq6kpCRJ0qeffqqVK1dq8uTJCggIuO9rvH79us6ePZtiS0hISHHsb7/9plq1aunAgQN68803NW7cOOXNm1etW7fWkiVL7P4+XLhwQc2bN1fNmjU1ZswYubu7q0OHDlq4cKE6dOigp59+Wh9++KGuXLmiZ599VpcvX7Y+d/v27dq8ebM6dOigSZMm6eWXX9aaNWsUFhaW6hevPn366MCBAxoxYoQ6d+6sefPmqXXr1jIM477vIQA8EAOAU7t48aIhyWjVqlWajo+OjjYkGT169LBpHzx4sCHJWLt2rbUtMDDQkGRs3LjR2nb69GnD3d3dGDRokLUtJibGkGR89NFHNucMDw83AgMDU8QwfPhw47//vHz88ceGJOPMmTN3jft2H7NmzbK2Va5c2ShcuLBx7tw5a9uePXsMFxcXo3Pnzin669atm80527RpY/j5+d21z/++jrx58xqGYRjPPvus0ahRI8MwDCMpKckoWrSoERERkep7cP36dSMpKSnF63B3dzdGjhxpbdu+fXuK13ZbgwYNDEnG9OnTU93XoEEDm7affvrJkGS8//77xh9//GF4eXkZrVu3vu9rNAzDkHTfbfv27dbjGzVqZFSoUMG4fv26tS05OdmoU6eOUbp0aYe8D1999ZW17eDBg4Ykw8XFxdi6dWuK9+C/57l69WqKc27ZssWQZMyZM8faNmvWLEOSUa1aNePGjRvW9jFjxhiSjG+//fZubx8AZAiVbsDJXbp0SZKUL1++NB3//fffS5IGDhxo0z5o0CBJSjH3u2zZsnrsscesjwsVKqSQkBD98ccfDxzznW7PBf/222+VnJycpufExsYqOjpaXbp0ka+vr7W9YsWKeuKJJ6yv879efvllm8ePPfaYzp07Z30P0+L555/X+vXrFRcXp7Vr1youLi7VqSXSv/PAXVz+/Wc0KSlJ586ds06d2bVrV5r7dHd3V9euXdN07JNPPqlevXpp5MiRatu2rTw8PPTpp5+mua9WrVpp1apVKbbXX3/d5rjz589r7dq11l8PblfEz507pyZNmujIkSP6+++/rfHb433w8vKy+TUmJCRE+fPnV2hoqGrWrGltv/3n/45RT09P659v3rypc+fOKTg4WPnz5081hpdeesnmot1XXnlFuXPnTnVcAYA9kHQDTs7b21uSbH5Kv5c///xTLi4uCg4OtmkvWrSo8ufPrz///NOmvUSJEinOUaBAAbvOb23fvr3q1q2rHj16qEiRIurQoYP+97//3TMBvx1nSEhIin2hoaE6e/asrly5YtN+52spUKCAJKXrtTz99NPKly+fFi5cqHnz5qlGjRop3svbkpOT9fHHH6t06dJyd3dXwYIFVahQIe3du1cXL15Mc58PPfRQui6aHDt2rHx9fRUdHa1JkyapcOHCaX5usWLF1Lhx4xRb2bJlbY47evSoDMPQsGHDVKhQIZtt+PDhkqTTp09Lst/7UKxYsRTXAvj4+Kh48eIp2iTbz/XatWt69913Vbx4cZsY4uPjU42hdOnSNo+9vLzk7++f6rQlALAHVi8BnJy3t7cCAgK0f//+dD3vzuTlbnLlypVqu5GGua136+P2fOPbPD09tXHjRq1bt04rVqzQjz/+qIULF+rxxx/XypUr7xpDemXktdzm7u6utm3bavbs2frjjz80YsSIux47atQoDRs2TN26ddN7770nX19fubi4aMCAAWmu6Eu2Vdq02L17tzXh3bdvnzp27Jiu56fF7fgHDx6sJk2apHrM7S8j9nof7vb5peVz7du3r2bNmqUBAwaodu3a1ps4dejQIV0xAICjkHQDWUDz5s312WefacuWLapdu/Y9jw0MDFRycrKOHDmi0NBQa/s///yj+Ph460ok9lCgQAGblT5uu7OaLkkuLi5q1KiRGjVqpPHjx2vUqFF6++23tW7dOjVu3DjV1yFJhw4dSrHv4MGDKliwoPLmzZvxF5GK559/Xl988YVcXFxSvfj0tm+++UYNGzbUzJkzbdrj4+NVsGBB6+O0fgFKiytXrqhr164qW7as6tSpozFjxqhNmzbWlUHs5eGHH5Ykubq6pvr5/JcZ70NqMYSHh2vcuHHWtuvXr6c6PqV/b3j03wtWExISFBsbq6efftphMQLI2ZheAmQBb7zxhvLmzasePXron3/+SbH/2LFjmjhxoiRZk4Y7VxgZP368JKlZs2Z2i6tUqVK6ePGi9u7da22LjY21WdlC+nd+8J1u3xzlzmUMb/P391flypU1e/Zsm8Rp//79WrlypUOTo4YNG+q9997TlClTVLRo0bselytXrhRV9K+//to61/m2218O7pYApseQIUN04sQJzZ49W+PHj1dQUJDCw8Pv+j4+qMKFCyssLEyffvqpYmNjU+y/vXa7ZM77cKfUYpg8eXKKX11u++yzz3Tz5k3r42nTpunWrVtq2rSp3WMDAIlKN5AllCpVSl999ZXat2+v0NBQmztSbt68WV9//bW6dOkiSapUqZLCw8P12WefKT4+Xg0aNNCvv/6q2bNnq3Xr1nddju5BdOjQQUOGDFGbNm3Ur18/Xb16VdOmTdMjjzxic/HayJEjtXHjRjVr1kyBgYE6ffq0PvnkExUrVkz16tW76/k/+ugjNW3aVLVr11b37t117do1TZ48WT4+Pvec9pFRLi4ueuedd+57XPPmzTVy5Eh17dpVderU0b59+zRv3jxrlfi2UqVKKX/+/Jo+fbry5cunvHnzqmbNmipZsmS64lq7dq0++eQTDR8+3LqE4axZsxQWFqZhw4ZpzJgx6Trf/UydOlX16tVThQoV1LNnTz388MP6559/tGXLFp08edK6Dndmvw+pad68uebOnSsfHx+VLVtWW7Zs0erVq+Xn55fq8Tdu3FCjRo3Url07HTp0SJ988onq1aunli1bZjgWAEiViSunAEinw4cPGz179jSCgoIMNzc3I1++fEbdunWNyZMn2yzrdvPmTSMiIsIoWbKk4erqahQvXtwYOnSozTGG8e+Sgc2aNUvRz51L1d1tyUDDMIyVK1ca5cuXN9zc3IyQkBDjyy+/TLFk4Jo1a4xWrVoZAQEBhpubmxEQEGB07NjROHz4cIo+7lxObvXq1UbdunUNT09Pw9vb22jRooXx+++/2xxzu787lyS8vTxcTEzMXd9Tw7BdMvBu7rZk4KBBgwx/f3/D09PTqFu3rrFly5ZUl/r79ttvjbJlyxq5c+e2eZ0NGjQwypUrl2qf/z3PpUuXjMDAQKNq1arGzZs3bY577bXXDBcXF2PLli33fA2SjN69e6e67/Z79d8lAw3DMI4dO2Z07tzZKFq0qOHq6mo89NBDRvPmzY1vvvkmU96Hu43RO1/LhQsXjK5duxoFCxY0vLy8jCZNmhgHDx40AgMDjfDw8BSvc8OGDcZLL71kFChQwPDy8jI6depkszQlANibxTC4EwAAIGeIiopS165dtX37dlWvXt3scADkIMzpBgAAAByMpBsAAABwMJJuAAAAwMFIugEAOUaXLl1kGAbzuQFYbdy4US1atFBAQIAsFouWLl1qsz8hIUF9+vRRsWLF5OnpqbJly2r69Onp7oekGwAAADnWlStXVKlSJU2dOjXV/QMHDtSPP/6oL7/8UgcOHNCAAQPUp08fLVu2LF39sHoJAAAAoH/vnLtkyRK1bt3a2la+fHm1b99ew4YNs7ZVq1ZNTZs21fvvv5/mc1PpBgAAQLaSmJioS5cu2WwPeufeOnXqaNmyZfr7779lGIbWrVunw4cP68knn0zXebLlHSk9q/QxOwRkAxe2TzE7BAAAMszDybK9zMjThrQqqIiICJu24cOHP9DdjCdPnqyXXnpJxYoVU+7cueXi4qIZM2aofv366TqPk30MAAAAQMYMHTpUAwcOtGlzd3d/oHNNnjxZW7du1bJlyxQYGKiNGzeqd+/eCggIUOPGjdN8HpJuAAAAZB6L42c3u7u7P3CS/V/Xrl3TW2+9pSVLlqhZs2aSpIoVKyo6Olpjx45NV9LNnG4AAAAgFTdv3tTNmzfl4mKbMufKlUvJycnpOheVbgAAAGQei8XsCGwkJCTo6NGj1scxMTGKjo6Wr6+vSpQooQYNGuj111+Xp6enAgMDtWHDBs2ZM0fjx49PVz8k3QAAAMixduzYoYYNG1of354LHh4erqioKC1YsEBDhw5Vp06ddP78eQUGBuqDDz7Qyy+/nK5+SLoBAACQeTJhTnd6hIWF6V63rSlatKhmzZqV4X6c61UDAAAA2RCVbgAAAGQeJ5vTnVmodAMAAAAORqUbAAAAmcfJ5nRnlpz5qgEAAIBMRKUbAAAAmYc53QAAAAAcgUo3AAAAMg9zugEAAAA4ApVuAAAAZB7mdAMAAABwBCrdAAAAyDzM6QYAAADgCFS6AQAAkHmY0w0AAADAEah0AwAAIPMwpxsAAACAI1DpBgAAQOZhTjcAAAAAR6DSDQAAgMzDnG4AAAAAjkClGwAAAJmHSre54uPj9fnnn2vo0KE6f/68JGnXrl36+++/TY4MAAAAyBinqHTv3btXjRs3lo+Pj44fP66ePXvK19dXixcv1okTJzRnzhyzQwQAAIA9uLB6iWkGDhyoLl266MiRI/Lw8LC2P/3009q4caOJkQEAAAAZ5xSV7u3bt+vTTz9N0f7QQw8pLi7OhIgAAADgEMzpNo+7u7suXbqUov3w4cMqVKiQCREBAAAA9uMUSXfLli01cuRI3bx5U5JksVh04sQJDRkyRM8884zJ0QEAAMBuLBbHb07IKZLucePGKSEhQYULF9a1a9fUoEEDBQcHK1++fPrggw/MDg8AAADIEKeY0+3j46NVq1Zp06ZN2rt3rxISElS1alU1btzY7NAAAABgTzl0TrdTJN231atXT/Xq1TM7DAAAAMCunCLpnjRpUqrtFotFHh4eCg4OVv369ZUrV65MjgwAAAB25aRzrh3NKZLujz/+WGfOnNHVq1dVoEABSdKFCxeUJ08eeXl56fTp03r44Ye1bt06FS9e3ORoAQAAgPRxikk1o0aNUo0aNXTkyBGdO3dO586d0+HDh1WzZk1NnDhRJ06cUNGiRfXaa6+ZHSoAAAAywuLi+M0JOUWl+5133tGiRYtUqlQpa1twcLDGjh2rZ555Rn/88YfGjBnD8oEAAADIkpwi6Y6NjdWtW7dStN+6dct6R8qAgABdvnw5s0MDAACAPeXQOd1OUX9v2LChevXqpd27d1vbdu/erVdeeUWPP/64JGnfvn0qWbKkWSECAAAAD8wpku6ZM2fK19dX1apVk7u7u9zd3VW9enX5+vpq5syZkiQvLy+NGzfO5EgBAACQIczpNk/RokW1atUqHTx4UIcPH5YkhYSEKCQkxHpMw4YNzQoPAAAAyBCnSLpvK1OmjMqUKWN2GAAAAHCUHDqn27Ske+DAgWk+dvz48Q6MBAAAAHAs05Lu/140KUm7du3SrVu3rFNKDh8+rFy5cqlatWpmhAcAAABHcNI5145mWtK9bt0665/Hjx+vfPnyafbs2TZ3pOzatasee+wxs0IEAAAA7MIpvmqMGzdOkZGR1oRbkgoUKKD333+fFUsAAACyE4vF8ZsTcoqk+9KlSzpz5kyK9jNnznBDHAAAAGR5TpF0t2nTRl27dtXixYt18uRJnTx5UosWLVL37t3Vtm1bs8MDAACAvTjZOt0bN25UixYtFBAQIIvFoqVLl6Y45sCBA2rZsqV8fHyUN29e1ahRQydOnEhXP06RdE+fPl1NmzbV888/r8DAQAUGBur555/XU089pU8++cTs8AAAAJBNXblyRZUqVdLUqVNT3X/s2DHVq1dPZcqU0fr167V3714NGzZMHh4e6erHYhiGYY+A7eHKlSs6duyYJKlUqVLKmzfvA53Hs0ofe4aFHOrC9ilmhwAAQIZ5ONVdWSTPFo4vqF777tUHep7FYtGSJUvUunVra1uHDh3k6uqquXPnZigmp6h03xYbG6vY2FiVLl1aefPmlRN9HwAAAEAWkZiYqEuXLtlsiYmJ6T5PcnKyVqxYoUceeURNmjRR4cKFVbNmzVSnoNyPUyTd586dU6NGjfTII4/o6aefVmxsrCSpe/fuGjRokMnRAQAAwG4yYfWSyMhI+fj42GyRkZHpDvX06dNKSEjQhx9+qKeeekorV65UmzZt1LZtW23YsCFd53KKpPu1116Tq6urTpw4oTx58ljb27dvrx9//NHEyLK2ulVL6ZsJvfTHyg90bfcUtQiraLM/r6ebPh7ynI7++J7ObxmvXYveVo9n65kULbKSBV/NU9MnHleNKhXUqcNz2rd3r9khIYthDCGjGENZWCZcSDl06FBdvHjRZhs6dGi6Q01OTpYktWrVSq+99poqV66sN998U82bN9f06dPTdS6nSLpXrlyp0aNHq1ixYjbtpUuX1p9//mlSVFlfXk937Tv8twZELkx1/+hBz+iJOmXV9e05qtz2fU2Zt14fD3lOzRpUyORIkZX8+MP3GjsmUr1e7a0FXy9RSEgZvdKru86dO2d2aMgiGEPIKMYQ7sfd3V3e3t42m7u7e7rPU7BgQeXOnVtly5a1aQ8NDc2aq5dcuXLFpsJ92/nz5x/oDcK/Vv7yuyI+Wa5l61L/9l+rUkl9uXybft55RCdiz+uLxb9o7+G/Vb1cYCZHiqxk7uxZavtsO7Vu84xKBQfrneER8vDw0NLFi8wODVkEYwgZxRjK4rLQzXHc3NxUo0YNHTp0yKb98OHDCgxMX77kFEn3Y489pjlz5lgfWywWJScna8yYMWrYsKGJkWVvW/fEqHmDCgoo5CNJql+9tEoHFtbqrQdMjgzO6uaNGzrw+2+qVbuOtc3FxUW1atXR3j27TYwMWQVjCBnFGIK9JSQkKDo6WtHR0ZKkmJgYRUdHWyvZr7/+uhYuXKgZM2bo6NGjmjJlir777ju9+mr6VkhxikVkxowZo0aNGmnHjh26ceOG3njjDf322286f/68fvnlF7PDy7YGjv5aU4d11LGVH+jmzSQlG8l69b35+mXXMbNDg5O6EH9BSUlJ8vPzs2n38/NTTMwfJkWFrIQxhIxiDGUD6bx5jaPt2LHDpsg7cOBASVJ4eLiioqLUpk0bTZ8+XZGRkerXr59CQkK0aNEi1auXvuvgnCLpLl++vA4fPqwpU6YoX758SkhIUNu2bdW7d2/5+/vf87mJiYkploAxkpNkccnlyJCzhVc7NNCjFYL0TP/pOhF7XvWqBmvCm+0Ue+ai1m07dP8TAAAAZHFhYWH3Xaa6W7du6tatW4b6cYqkW5J8fHz09ttvp/t5kZGRioiIsGnLVaSGXP0ftVdo2ZKHu6si+rZQ+4Ez9OOm3yRJ+4+cUsWQYhrwYiOSbqSqQP4CypUrV4qLlc6dO6eCBQuaFBWyEsYQMooxlA3Ycc51VmJafX/v3r1p3u4ltSVhcheplkmvIutyzZ1Lbq65lXzHN7ukpGS5uOTMvwy4P1c3N4WWLadtW7dY25KTk7Vt2xZVrFTFxMiQVTCGkFGMIWRVplW6K1euLIvFct9yvsViUVJS0l33u7u7p1jhhKkl/8rr6aZSxQtZHwc95KeKjzykC5eu6q+4C9q444hGDWita9dv6kTseT1WLVidmj+qIeMXmxg1nN2L4V017K0hKleuvMpXqKgv587WtWvX1LpNW7NDQxbBGEJGMYayNksOrXSblnTHxMSY1XWOUbVsoFZ+3t/6eMzgZyRJc5dt1UvDv1TnN7/QyL6tFDUqXAW88+hE7HmNmLpcM77eZFbIyAKeavq0Lpw/r0+mTNLZs2cUUiZUn3z6ufz4WRdpxBhCRjGGkBVZjPuVmrMgzyp9zA4B2cCF7VPMDgEAgAzzcJor+P6V99lZDu/jyjddHd5HejnFx1CiRAmFhYWpQYMGCgsLU6lSpcwOCQAAALAbp1gocdSoUfLw8NDo0aNVunRpFS9eXC+88IJmzJihI0eOmB0eAAAA7MWSCZsTcopK9wsvvKAXXnhBkhQbG6sNGzZo+fLlevXVV5WcnHzPCykBAAAAZ+cUSbckXb16VZs2bdL69eu1bt067d69W+XLl1dYWJjZoQEAAMBOWL3ERHXq1NHu3bsVGhqqsLAwvfnmm6pfv74KFChgdmgAAABAhjlF0n3w4EHlzZtXZcqUUZkyZRQaGkrCDQAAkA3l1Eq3U1xIee7cOa1du1a1atXSTz/9pLp16+qhhx7S888/rxkzZpgdHgAAAJAhTrdOt2EY2rlzp6ZMmaJ58+Y90IWUrNMNe2CdbgBAduBs63R7d5jj8D4uLejs8D7Syyk+hl27dmn9+vVav369Nm3apMuXL6tChQrq27evGjRoYHZ4AAAAQIY4RdL96KOPqkqVKmrQoIF69uyp+vXry8fHx+ywAAAAYGc5dU63UyTd58+fl7e3t9lhAAAAAA7hFEn37YR7586dOnDggCSpbNmyqlq1qplhAQAAwN5yZqHbOZLu06dPq3379tqwYYPy588vSYqPj1fDhg21YMECFSpUyNwAAQAAgAxwiiUD+/btq4SEBP322286f/68zp8/r/379+vSpUvq16+f2eEBAADATiwWi8M3Z+QUle4ff/xRq1evVmhoqLWtbNmymjp1qp588kkTIwMAAAAyzimS7uTkZLm6uqZod3V1VXJysgkRAQAAwBGctRLtaE4xveTxxx9X//79derUKWvb33//rddee02NGjUyMTIAAAAg45wi6Z4yZYouXbqkoKAglSpVSqVKlVLJkiV16dIlTZ482ezwAAAAYCfM6TZR8eLFtWvXLq1evVoHDx6UJIWGhqpx48YmRwYAAABknFMk3dK/33qeeOIJPfHEE2aHAgAAAAdx1kq0ozlN0r1mzRqtWbNGp0+fTnHx5BdffGFSVAAAAEDGOUXSHRERoZEjR6p69ery9/fPsd+AAAAAsr0cmuY5RdI9ffp0RUVF6cUXXzQ7FAAAAMDunCLpvnHjhurUqWN2GAAAAHCwnDqjwSmWDOzRo4e++uors8MAAAAAHMIpKt3Xr1/XZ599ptWrV6tixYop7k45fvx4kyIDAACAPeXUSrdTJN179+5V5cqVJUn79++32Xf58mUTIgIAAADsx9Sk++OPP9Zrr72mdevWpbr/8uXLeuqppzI5KgAAADhKTq10mzqn+6233tKcOXNS3XflyhU1bdpU586dy+SoAAAAAPsytdI9d+5cvfjii8qfP79atmxpbU9ISNBTTz2l06dPa/369eYFCAAAAPvKmYVuc5PuZ599VvHx8erYsaNWrFihsLAwa4X7n3/+0YYNGxQQEGBmiAAAAECGmX4hZY8ePXT+/Hm1atVK3377rd59912dOnWKhBsAACAbyqlzuk1PuiXpjTfe0Pnz59WoUSMFBQVp/fr1KlasmNlhAQAAAHZhatLdtm1bm8eurq4qWLCg+vfvb9O+ePHizAwLAAAADkKl2wQ+Pj42jzt27GhSJAAAAIDjmJp0z5o1y8zuAQAAkMlyaqXb1HW6AQAAgJzAKS6kBAAAQM5ApRsAAACAQ1DpBgAAQObJmYVuKt0AAADIuTZu3KgWLVooICBAFotFS5cuveuxL7/8siwWiyZMmJDufki6AQAAkGksFovDt/S4cuWKKlWqpKlTp97zuCVLlmjr1q0PfMd0ppcAAAAgx2ratKmaNm16z2P+/vtv9e3bVz/99JOaNWv2QP2QdAMAACDTZMbqJYmJiUpMTLRpc3d3l7u7e7rPlZycrBdffFGvv/66ypUr98AxMb0EAAAA2UpkZKR8fHxstsjIyAc61+jRo5U7d27169cvQzFR6QYAAECmyYxK99ChQzVw4ECbtgepcu/cuVMTJ07Url27Mhw3lW4AAABkK+7u7vL29rbZHiTp/vnnn3X69GmVKFFCuXPnVu7cufXnn39q0KBBCgoKSte5qHQDAAAg82ShdbpffPFFNW7c2KatSZMmevHFF9W1a9d0nYukGwAAADlWQkKCjh49an0cExOj6Oho+fr6qkSJEvLz87M53tXVVUWLFlVISEi6+iHpBgAAQKbJjDnd6bFjxw41bNjQ+vj2XPDw8HBFRUXZrR+SbgAAAORYYWFhMgwjzccfP378gfoh6QYAAECmcbZKd2Zh9RIAAADAwah0AwAAINPk1Eo3STcAAAAyTU5NupleAgAAADgYlW4AAABknpxZ6KbSDQAAADhatqx0b1oyyuwQAAAAkArmdAMAAABwiGxZ6QYAAIBzotINAAAAwCGodAMAACDT5NBCN5VuAAAAwNGodAMAACDTMKcbAAAAgENQ6QYAAECmyaGFbirdAAAAgKNR6QYAAECmYU43AAAAAIcwvdKdlJSkqKgorVmzRqdPn1ZycrLN/rVr15oUGQAAAOwthxa6zU+6+/fvr6ioKDVr1kzly5fPsT85AAAAIPsyPelesGCB/ve//+npp582OxQAAAA4mItLziywmj6n283NTcHBwWaHAQAAADiM6Un3oEGDNHHiRBmGYXYoAAAAcDCLxfGbMzJ9esmmTZu0bt06/fDDDypXrpxcXV1t9i9evNikyAAAAAD7MD3pzp8/v9q0aWN2GAAAAMgEOXXRDNOT7lmzZpkdAgAAAOBQpifdt505c0aHDh2SJIWEhKhQoUImRwQAAAB7y6GFbvMvpLxy5Yq6desmf39/1a9fX/Xr11dAQIC6d++uq1evmh0eAAAAkGGmJ90DBw7Uhg0b9N133yk+Pl7x8fH69ttvtWHDBg0aNMjs8AAAAGBHFovF4ZszMn16yaJFi/TNN98oLCzM2vb000/L09NT7dq107Rp08wLDgAAALAD05Puq1evqkiRIinaCxcuzPQSAACAbMZZK9GOZvr0ktq1a2v48OG6fv26te3atWuKiIhQ7dq1TYwMAAAAsA/TK90TJ05UkyZNVKxYMVWqVEmStGfPHnl4eOinn34yOToAAADYUw4tdJufdJcvX15HjhzRvHnzdPDgQUlSx44d1alTJ3l6epocHQAAAJBxpifdkpQnTx717NnT7DAAAADgYDl1TrcpSfeyZcvUtGlTubq6atmyZfc8tmXLlpkUFQAAAOAYpiTdrVu3VlxcnAoXLqzWrVvf9TiLxaKkpKTMCwwAAAAOlUML3eYk3cnJyan+GQAAAMiOnGJO953i4+OVP39+s8MAAACAneXUOd2mr9M9evRoLVy40Pr4ueeek6+vrx566CHt2bPHxMgAAAAA+zA96Z4+fbqKFy8uSVq1apVWr16tH3/8UU2bNtXrr79ucnQAAACwJ4vF8ZszMn16SVxcnDXpXr58udq1a6cnn3xSQUFBqlmzpsnRAQAAABlneqW7QIEC+uuvvyRJP/74oxo3bixJMgyDlUsAAACyGYvF4vDNGZle6W7btq2ef/55lS5dWufOnVPTpk0lSbt371ZwcLDJ0QEAAAAZZ3ql++OPP1afPn1UtmxZrVq1Sl5eXpKk2NhYvfrqqyZHBwAAAHtytjndGzduVIsWLRQQECCLxaKlS5da9928eVNDhgxRhQoVlDdvXgUEBKhz5846depUul+36ZVuV1dXDR48OEX7a6+9ZkI0AAAAyEmuXLmiSpUqqVu3bmrbtq3NvqtXr2rXrl0aNmyYKlWqpAsXLqh///5q2bKlduzYka5+TE+6JenIkSNat26dTp8+neJmOe+++65JUQEAAMDenG3OddOmTa3Tm+/k4+OjVatW2bRNmTJFjz76qE6cOKESJUqkuR/Tk+4ZM2bolVdeUcGCBVW0aFGbD8JisZB0AwAAIF0SExOVmJho0+bu7i53d/cMn/vixYuyWCzpvpGj6XO633//fX3wwQeKi4tTdHS0du/ebd127dpldngAAACwo8yY0x0ZGSkfHx+bLTIyMsOxX79+XUOGDFHHjh3l7e2drueaXum+cOGCnnvuObPDAAAAQDYxdOhQDRw40KYto1Xumzdvql27djIMQ9OmTUv3802vdD/33HNauXKl2WEAAAAgE2TGOt3u7u7y9va22TKSdN9OuP/880+tWrUq3VVuyQkq3cHBwRo2bJi2bt2qChUqyNXV1WZ/v379TIoMAAAAOd3thPv2wh9+fn4PdB7Tk+7PPvtMXl5e2rBhgzZs2GCzz2KxkHQDAABkI062eIkSEhJ09OhR6+OYmBhFR0fL19dX/v7+evbZZ7Vr1y4tX75cSUlJiouLkyT5+vrKzc0tzf1YDMMw7B69yXYev2R2CMgGyhVL/09HAAA4Gw/TS6y26ozZ6PA+Nr9RP83Hrl+/Xg0bNkzRHh4erhEjRqhkyZKpPm/dunUKCwtLcz9O8zHcuHFDMTExKlWqlHLndpqwAAAAYEfOtk53WFiY7lWDtld92vQLKa9evaru3bsrT548KleunE6cOCFJ6tu3rz788EOTowMAAAAyzvSke+jQodqzZ4/Wr18vDw8Pa3vjxo21cOFCEyMDAACAvWXGOt3OyPR5HEuXLtXChQtVq1Ytm58bypUrp2PHjpkYGQAAAGAfpifdZ86cUeHChVO0X7lyxenm/AAAACBjcmp+Z/r0kurVq2vFihXWx7c/iM8//1y1a9c2KywAAADAbkyvdI8aNUpNmzbV77//rlu3bmnixIn6/ffftXnz5hTrdgMAACBro9Jtknr16ik6Olq3bt1ShQoVtHLlShUuXFhbtmxRtWrVzA4PAAAAyDDTK92SVKpUKc2YMcPsMAAAAOBgObTQbX6lW5KSk5N1+PBhbdq0SRs3brTZ4BjLFkbp+SY1NGfaOLNDQRa04Kt5avrE46pRpYI6dXhO+/buNTskZDGMIWQUYwhZjelJ99atWxUcHKzQ0FDVr19fYWFh1i21W3Ii444d+k1rVixRiZKlzQ4FWdCPP3yvsWMi1evV3lrw9RKFhJTRK72669y5c2aHhiyCMYSMYgxlbRaLxeGbMzI96X755ZdVvXp17d+/X+fPn9eFCxes2/nz580OL9u5fu2qpo5+Vz0GvKW8+fKZHQ6yoLmzZ6nts+3Uus0zKhUcrHeGR8jDw0NLFy8yOzRkEYwhZBRjCFmR6Un3kSNHNGrUKIWGhip//vzy8fGx2WBfs6aMUZVH66pC1Zpmh4Is6OaNGzrw+2+qVbuOtc3FxUW1atXR3j27TYwMWQVjCBnFGMr6cuodKU1PumvWrKmjR4+aHUaOsHn9Sh0/elDtu/U2OxRkURfiLygpKUl+fn427X5+fjp79qxJUSErYQwhoxhDyKpMWb1k738udujbt68GDRqkuLg4VahQQa6urjbHVqxY8Z7nSkxMVGJiok3bjcREubm72y/gbODc6TjNmTZOb0VOkZsb7w0AADCHs865djRTku7KlSvLYrHIMAxrW7du3ax/vr3PYrEoKSnpnueKjIxURESETVvP/m+q14Ch9g06i/vj6EFdij+vt3q/aG1LTk7SwX27tXLZ15qz/Be55MplYoTICgrkL6BcuXKluFjp3LlzKliwoElRISthDCGjGENZXw7Nuc1JumNiYux2rqFDh2rgwIE2bb/FJt7l6JyrfOUaGv3pfJu2T8eNVEDxILVo15mEG2ni6uam0LLltG3rFj3eqLGkf5f83LZtizp0fMHk6JAVMIaQUYwhZFWmJN2BgYF2O5e7u7vc75hK4nb+kt3On1145smr4kHBNm3uHp7yyueToh24lxfDu2rYW0NUrlx5la9QUV/Ona1r166pdZu2ZoeGLIIxhIxiDGVtLjm01O0Ud6ScO3eupk+frpiYGG3ZskWBgYGaMGGCSpYsqVatWpkdHoD/eKrp07pw/rw+mTJJZ8+eUUiZUH3y6efy42ddpBFjCBnFGEJWZDH+O7HaBNOmTdO7776rAQMG6IMPPtD+/fv18MMPKyoqSrNnz9a6devSfc6dx6l0I+PKFfM2OwQAADLMwylKrP/nyalbHd7Hyt61HN5Hepm+ZODkyZM1Y8YMvf3228r1n3nF1atX1759+0yMDAAAALAP07/7xMTEqEqVKina3d3ddeXKFRMiAgAAgKPk1CUDTa90lyxZUtHR0Snaf/zxR4WGhmZ+QAAAAICdmV7pHjhwoHr37q3r16/LMAz9+uuvmj9/viIjI/X555+bHR4AAADsyCVnFrrNT7p79OghT09PvfPOO7p69aqef/55BQQEaOLEierQoYPZ4QEAAAAZZmrSfevWLX311Vdq0qSJOnXqpKtXryohIUGFCxc2MywAAAA4CHO6TZA7d269/PLLun79uiQpT548JNwAAADIdky/kPLRRx/V7t27zQ4DAAAAmcBicfzmjEyf0/3qq69q0KBBOnnypKpVq6a8efPa7K9YsaJJkQEAAAD2YXrSfftiyX79+lnbLBaLDMOQxWJRUlKSWaEBAADAzixy0lK0g5medMfExJgdAgAAAOBQpifdgYGBZocAAACATMI63SY6dOiQJk+erAMHDkiSQkND1bdvX4WEhJgcGQAAAJBxpq9esmjRIpUvX147d+5UpUqVVKlSJe3atUvly5fXokWLzA4PAAAAdmSxWBy+OSPTK91vvPGGhg4dqpEjR9q0Dx8+XG+88YaeeeYZkyIDAAAA7MP0SndsbKw6d+6cov2FF15QbGysCREBAADAUXLqOt2mJ91hYWH6+eefU7Rv2rRJjz32mAkRAQAAAPZl+vSSli1basiQIdq5c6dq1aolSdq6dau+/vprRUREaNmyZTbHAgAAIOtycdZStINZDMMwzAzAxSVtxfb03Chn5/FLGQkJkCSVK+ZtdggAAGSYh+klVlttZ+50eB+Lu1dzeB/pZfrHkJycbHYIAAAAyCQ5tNBt/pxuAAAAILszvdItSdu3b9e6det0+vTpFJXv8ePHmxQVAAAA7M1Z19F2NNOT7lGjRumdd95RSEiIihQpYvNB5NQPBQAAANmL6Un3xIkT9cUXX6hLly5mhwIAAAAHy6k11TQl3Xv37k3zCStWrJiuAFxcXFS3bt10PQcAAADIStKUdFeuXFkWi0V3W13w9r70LOt322uvvaapU6dqwoQJ6XoeAAAAsp6cuk53mpLumJgYhwUwePBgNWvWTKVKlVLZsmXl6upqs3/x4sUO6xsAAAA528aNG/XRRx9p586dio2N1ZIlS9S6dWvrfsMwNHz4cM2YMUPx8fGqW7eupk2bptKlS6ernzQl3YGBgek6aXr069dP69atU8OGDeXn58fFkwAAANmYs2V6V65cUaVKldStWze1bds2xf4xY8Zo0qRJmj17tkqWLKlhw4apSZMm+v333+Xh4ZHmfh7oQsq5c+dq+vTpiomJ0ZYtWxQYGKgJEyaoZMmSatWqVbrONXv2bC1atEjNmjV7kFAAAACAB9a0aVM1bdo01X2GYWjChAl65513rDnunDlzVKRIES1dulQdOnRIcz/pvjnOtGnTNHDgQD399NOKj4+3zuHOnz//A83L9vX1ValSpdL9PAAAAGQ9FovF4Zu9xMTEKC4uTo0bN7a2+fj4qGbNmtqyZUu6zpXupHvy5MmaMWOG3n77beXKlcvaXr16de3bty+9p9OIESM0fPhwXb16Nd3PBQAAAO6UmJioS5cu2WyJiYnpPk9cXJwkqUiRIjbtRYoUse5Lq3RPL4mJiVGVKlVStLu7u+vKlSvpPZ0mTZqkY8eOqUiRIgoKCkpxIeWuXbvSfU4AAAA4J5dMmNQdGRmpiIgIm7bhw4drxIgRju/8LtKddJcsWVLR0dEpLq788ccfFRoamu4A/nt1KAAAAJBRQ4cO1cCBA23a3N3d032eokWLSpL++ecf+fv7W9v/+ecfVa5cOV3nSnfSPXDgQPXu3VvXr1+XYRj69ddfNX/+fEVGRurzzz9P7+k0fPjwdD8HAAAAWVNmrFTn7u7+QEn2nUqWLKmiRYtqzZo11iT70qVL2rZtm1555ZV0nSvdSXePHj3k6empd955R1evXtXzzz+vgIAATZw4MV1XcN5p586dOnDggCSpXLlyqU5hAQAAAOwpISFBR48etT6OiYlRdHS0fH19VaJECQ0YMEDvv/++SpcubV0yMCAgIN2zNSzG3W4zmQZXr15VQkKCChcu/KCn0OnTp9WhQwetX79e+fPnlyTFx8erYcOGWrBggQoVKpTuc+48fumB4wFuK1fM2+wQAADIMI8HWiDacV6ct8fhfcztVCnNx65fv14NGzZM0R4eHq6oqCjrzXE+++wzxcfHq169evrkk0/0yCOPpCumB066T58+rUOHDkmSypQp80DJsSS1b99ef/zxh+bMmWOdE/77778rPDxcwcHBmj9/frrPSdINeyDpBgBkByTdziHdH8Ply5f16quvav78+UpOTpYk5cqVS+3bt9fUqVPl4+OTrvP9+OOPWr16tc1FmGXLltXUqVP15JNPpjc8AAAAOLGcevfxdK/T3aNHD23btk0rVqxQfHy84uPjtXz5cu3YsUO9evVKdwDJyckplgmUJFdXV2tSDwAAAGRl6Z5ekjdvXv3000+qV6+eTfvPP/+sp556Kt1rdbdq1Urx8fGaP3++AgICJEl///23OnXqpAIFCmjJkiXpOp/E9BLYB9NLAADZgbNNL+kyf6/D+4jqWNHhfaRXuivdfn5+qU4h8fHxUYECBdIdwJQpU3Tp0iUFBQWpVKlSKlWqlEqWLKlLly5p8uTJ6T4fAAAA4GzS/d3nnXfe0cCBAzV37lzrguFxcXF6/fXXNWzYsHQHULx4ce3atUurV6/WwYMHJUmhoaE297gHAABA9pBT53SnKemuUqWKzRt05MgRlShRQiVKlJAknThxQu7u7jpz5kya53WvXbtWffr00datW+Xt7a0nnnhCTzzxhCTp4sWLKleunKZPn67HHnssva8JAAAAcCppSrodcav2CRMmqGfPnvL2Tjlv1sfHR7169dL48eNJugEAALKRnFnnTmPS7Yhbte/Zs0ejR4++6/4nn3xSY8eOtXu/AAAAQGYz7XrWf/75J9WlAm/LnTu3zpw5k4kRAQAAwNFccuic7nSvXpKUlKSxY8fq0UcfVdGiReXr62uzpdVDDz2k/fv333X/3r175e/vn97wAAAAAKeT7qQ7IiJC48ePV/v27XXx4kUNHDhQbdu2lYuLi0aMGJHm8zz99NMaNmyYrl+/nmLftWvXNHz4cDVv3jy94QEAAMCJWSyO35xRum+OU6pUKU2aNEnNmjVTvnz5FB0dbW3bunWrvvrqqzSd559//lHVqlWVK1cu9enTRyEhIZKkgwcPaurUqUpKStKuXbtUpEiRdL8obo4De+DmOACA7MDZbo7T8393n+lgLzPalXd4H+mV7o8hLi5OFSpUkCR5eXnp4sWLkqTmzZuna53uIkWKaPPmzXrllVc0dOhQ3c79LRaLmjRpoqlTpz5Qwg0AAADnxTrdaVSsWDHFxsaqRIkSKlWqlFauXKmqVatq+/btcnd3T9e5AgMD9f333+vChQs6evSoDMNQ6dKlH+jOlgAAAICzSnfS3aZNG61Zs0Y1a9ZU37599cILL2jmzJk6ceKEXnvttQcKokCBAqpRo8YDPRcAAABZRw4tdKc/6f7www+tf27fvr0CAwO1efNmlS5dWi1atLBrcAAAAEB2kOGp9bVq1VKtWrV0+vRpjRo1Sm+99ZY94gIAAEA2xDrdGRQbG5uuCykBAACAnMLJFpEBAABAdpZDC932q3QDAAAASB2VbgAAAGQa1um+j4EDB95z/5kzZzIcDAAAAJAdpTnp3r17932PqV+/foaCsZfvj542OwRkA9wGHgAA+8upc5vTnHSvW7fOkXEAAAAgB8ip00ty6pcNAAAAINNwISUAAAAyjUvOLHRT6QYAAAAcjUo3AAAAMg2VbgAAAAAO8UBJ988//6wXXnhBtWvX1t9//y1Jmjt3rjZt2mTX4AAAAJC9WCwWh2/OKN1J96JFi9SkSRN5enpq9+7dSkxMlCRdvHhRo0aNsnuAAAAAQFaX7qT7/fff1/Tp0zVjxgy5urpa2+vWratdu3bZNTgAAABkLy4Wx2/OKN1J96FDh1K986SPj4/i4+PtERMAAACQraQ76S5atKiOHj2aon3Tpk16+OGH7RIUAAAAsieLxfGbM0p30t2zZ0/1799f27Ztk8Vi0alTpzRv3jwNHjxYr7zyiiNiBAAAALK0dK/T/eabbyo5OVmNGjXS1atXVb9+fbm7u2vw4MHq27evI2IEAABANuHirKVoB0t30m2xWPT222/r9ddf19GjR5WQkKCyZcvKy8vLEfEBAAAAWd4D35HSzc1NZcuWtWcsAAAAyOZy6p0Z0510N2zY8J6Ljq9duzZDAQEAAADZTbqT7sqVK9s8vnnzpqKjo7V//36Fh4fbKy4AAABkQzl0Snf6k+6PP/441fYRI0YoISEhwwEBAAAA2Y3dptW88MIL+uKLL+x1OgAAAGRDLhaLwzdnZLeke8uWLfLw8LDX6QAAAIBsI93TS9q2bWvz2DAMxcbGaseOHRo2bJjdAgMAAED246SFaIdLd9Lt4+Nj89jFxUUhISEaOXKknnzySbsFBgAAAGQX6Uq6k5KS1LVrV1WoUEEFChRwVEwAAADIplycrNKdlJSkESNG6Msvv1RcXJwCAgLUpUsXvfPOO/dcJju90pV058qVS08++aQOHDhA0g0AAIAsb/To0Zo2bZpmz56tcuXKaceOHeratat8fHzUr18/u/WT7ukl5cuX1x9//KGSJUvaLQgAAADkDM62usjmzZvVqlUrNWvWTJIUFBSk+fPn69dff7VrP+leveT999/X4MGDtXz5csXGxurSpUs2GwAAAJBV1KlTR2vWrNHhw4clSXv27NGmTZvUtGlTu/aT5kr3yJEjNWjQID399NOSpJYtW9rMczEMQxaLRUlJSekKICkpSVFRUVqzZo1Onz6t5ORkm/3cVh4AACD7yIxCd2JiohITE23a3N3d5e7unuLYN998U5cuXVKZMmWUK1cuJSUl6YMPPlCnTp3sGlOak+6IiAi9/PLLWrdunV0D6N+/v6KiotSsWTOVL1/erhPWAQAAkPNERkYqIiLCpm348OEaMWJEimP/97//ad68efrqq69Urlw5RUdHa8CAAQoICFB4eLjdYrIYhmGk5UAXFxfFxcWpcOHCdutckgoWLKg5c+ZYK+j28N7qo3Y7F3Ku18OCzQ4BAIAM80j3FXyO9cEax+dpg+sVT3Olu3jx4nrzzTfVu3dva9v777+vL7/8UgcPHrRbTOn6GBxRhXZzc1NwMMkNAAAA7ONuCXZqrl69KhcX28scc+XKlWLKc0alK+l+5JFH7pt4nz9/Pl0BDBo0SBMnTtSUKVOYWgIAAJDNWeRc+V6LFi30wQcfqESJEipXrpx2796t8ePHq1u3bnbtJ11Jd0RERIo7UmbUpk2btG7dOv3www8qV66cXF1dbfYvXrzYrv0BAAAAt02ePFnDhg3Tq6++qtOnTysgIEC9evXSu+++a9d+0pV0d+jQwe5zuvPnz682bdrY9ZwAAABwTs52R8p8+fJpwoQJmjBhgkP7SXPS7aipH7NmzXLIeQEAAABnkeakO42LnDywM2fO6NChQ5KkkJAQFSpUyKH9AQAAIPM5W6U7s6T5jpTJycl2n1oiSVeuXFG3bt3k7++v+vXrq379+goICFD37t119epVu/cHAAAAZLZ03wbe3gYOHKgNGzbou+++U3x8vOLj4/Xtt99qw4YNGjRokNnhAQAAwI4sFovDN2dk+nLpixYt0jfffKOwsDBr29NPPy1PT0+1a9dO06ZNMy84AAAAwA5MT7qvXr2qIkWKpGgvXLgw00sAAACyGeZ0m6R27doaPny4rl+/bm27du2aIiIiVLt2bRMjAwAAAOzD9Er3xIkT1aRJExUrVkyVKlWSJO3Zs0ceHh766aefTI4OAAAA9uSkU64dzvSku3z58jpy5IjmzZungwcPSpI6duyoTp06ydPT0+ToAAAAgIwzPemWpDx58qhnz55mhwEAAAAHc8mhpW5Tku5ly5apadOmcnV11bJly+55bMuWLTMpKgAAAMAxTEm6W7durbi4OBUuXFitW7e+63EWi0VJSUmZFxgAAAAcKqeuXmJK0p2cnJzqnwEAAIDsyPQlA+fMmaPExMQU7Tdu3NCcOXNMiAgAAACOYrE4fnNGpifdXbt21cWLF1O0X758WV27djUhIgAAAMC+TF+9xDAMWVL5SnLy5En5+PiYEBEAAAAcxUVOWop2MNOS7ipVqshischisahRo0bKnfv/QklKSlJMTIyeeuops8IDAAAA7Ma0pPv2qiXR0dFq0qSJvLy8rPvc3NwUFBSkZ555xqToAAAA4AjOOufa0UxLuocPHy5JCgoKUvv27eXh4WFWKAAAAIBDmT6nOzw83OwQAAAAkElYp9skSUlJ+vjjj/W///1PJ06c0I0bN2z2nz9/3qTIAAAAAPswfcnAiIgIjR8/Xu3bt9fFixc1cOBAtW3bVi4uLhoxYoTZ4QEAAMCOXCwWh2/OyPSke968eZoxY4YGDRqk3Llzq2PHjvr888/17rvvauvWrWaHBwAAAGSY6Ul3XFycKlSoIEny8vKy3iinefPmWrFihZmhZTvJyUmK/m6ulrzbTfMHtNHS4d2194f5MgzD7NCQxSz4ap6aPvG4alSpoE4dntO+vXvNDglZDGMIGcUYyrq4I6VJihUrptjYWElSqVKltHLlSknS9u3b5e7ubmZo2c7vK7/RkZ+/V412L6vFsOmq0qqrfl+1SIfWf2d2aMhCfvzhe40dE6ler/bWgq+XKCSkjF7p1V3nzp0zOzRkEYwhZBRjCFmR6Ul3mzZttGbNGklS3759NWzYMJUuXVqdO3dWt27dTI4uezkTc0DFKtZUsfKPysuviAKr1pN/aBWd/fOQ2aEhC5k7e5baPttOrds8o1LBwXpneIQ8PDy0dPEis0NDFsEYQkYxhrK2nDqn2/TVSz788EPrn9u3b6/AwEBt3rxZpUuXVosWLUyMLPspVDJUR375UZf++VveRR7ShZN/6Myx31WtbQ+zQ0MWcfPGDR34/Td179nL2ubi4qJatepo757dJkaGrIIxhIxiDCGrMj3pvlOtWrVUq1Yts8PIlso9+ZxuXr+qZe/1ksXiIsNIVuUWnVXy0YZmh4Ys4kL8BSUlJcnPz8+m3c/PTzExf5gUFbISxhAyijGU9TlpIdrhTE+6IyMjVaRIkRRTSb744gudOXNGQ4YMuefzExMTlZiYaNN260aicrsxH/xOf+76WTHb16tel9fl4x+oCyf/0I5Fn8nTx1elajU2OzwAAIBsy/Q53Z9++qnKlCmTor1cuXKaPn36fZ8fGRkpHx8fm23jgk8dEWqWt2vJFyr35HMKqt5ABR4K0sM1H1dow9b6beXXZoeGLKJA/gLKlStXiouVzp07p4IFC5oUFbISxhAyijGU9blkwuaMTI8rLi5O/v7+KdoLFSpkXdXkXoYOHaqLFy/abPU79Lrv83KiWzcTZbnjNx2Ly7/TTIC0cHVzU2jZctq2dYu1LTk5Wdu2bVHFSlVMjAxZBWMIGcUYQlZl+vSS4sWL65dfflHJkiVt2n/55RcFBATc9/nu7u4plhZkaknqipV/VPt/Wqg8voWU3z9Q5/86pgNrl6hU7SfMDg1ZyIvhXTXsrSEqV668yleoqC/nzta1a9fUuk1bs0NDFsEYQkYxhrK2OwuAOYXpSXfPnj01YMAA3bx5U48//rgkac2aNXrjjTc0aNAgk6PLXmq0e1l7ln+p7Qs+0fWEi/L08VXpek1VoWlHs0NDFvJU06d14fx5fTJlks6ePaOQMqH65NPP5cfPukgjxhAyijGErMhimHw7QsMw9Oabb2rSpEm6ceOGJMnDw0NDhgzRu++++0DnfG/1UXuGiBzq9bBgs0MAACDDPEwvsdqas+Mvh/fRuXpxh/eRXqZ/DBaLRaNHj9awYcN04MABeXp6qnTp0tyNEgAAIBty1pvXOJrpSfdtXl5eqlGjhtlhAAAAAHZnStLdtm1bRUVFydvbW23b3vuih8WLF2dSVAAAAHC0nFnnNinp9vHxsV656uPjY0YIAAAAQKYxJemeNWtWqn8GAABA9pZDp3Sbf3McAAAAILszpdJdpUqVNC+MvmvXLgdHAwAAgMzCzXEyUevWrc3oFgAAADCFKUn38OHDzegWAAAAJsupc5udZp3uHTt26MCBA5KksmXLqlq1aiZHBAAAANiH6Un3yZMn1bFjR/3yyy/Knz+/JCk+Pl516tTRggULVKxYMXMDBAAAgN3k1Dndplf4e/TooZs3b+rAgQM6f/68zp8/rwMHDig5OVk9evQwOzwAAABkc3///bdeeOEF+fn5ydPTUxUqVNCOHTvs2ofple4NGzZo8+bNCgkJsbaFhIRo8uTJeuyxx0yMDAAAAPbmbHXuCxcuqG7dumrYsKF++OEHFSpUSEeOHFGBAgXs2o/pSXfx4sV18+bNFO1JSUkKCAgwISIAAADkFKNHj1bx4sVtbthYsmRJu/dj+vSSjz76SH379rUp4e/YsUP9+/fX2LFjTYwMAAAA9maxWBy+pceyZctUvXp1PffccypcuLCqVKmiGTNm2P91G4Zh2P2s6VCgQAFdvXpVt27dUu7c/xbeb/85b968NseeP38+Ted8b/VRu8eJnOf1sGCzQwAAIMM8TJ/XYOubPbEO76NFGV8lJibatLm7u8vd3T3FsR4eHpKkgQMH6rnnntP27dvVv39/TZ8+XeHh4XaLyfSPYcKECWaHAAAAgEySGdMsIiMjFRERYdM2fPhwjRgxIsWxycnJql69ukaNGiXp3zun79+/P/sl3fZ8MQAAAMDQoUM1cOBAm7bUqtyS5O/vr7Jly9q0hYaGatGiRXaNyfSkW/r3osklS5bY3BynVatW1ukmAAAAyB4yY53uu00lSU3dunV16NAhm7bDhw8rMDDQrjGZntX+9ttvatmypeLi4qzLBo4ePVqFChXSd999p/Lly5scIQAAALKr1157TXXq1NGoUaPUrl07/frrr/rss8/02Wef2bUf01cv6dGjh8qVK6eTJ09q165d2rVrl/766y9VrFhRL730ktnhAQAAwI4smbClR40aNbRkyRLNnz9f5cuX13vvvacJEyaoU6dOGXqddzK90h0dHa0dO3bYLEBeoEABffDBB6pRo4aJkQEAACAnaN68uZo3b+7QPkyvdD/yyCP6559/UrSfPn1awcEs2QYAAJCdWCyO35yR6Ul3ZGSk+vXrp2+++UYnT57UyZMn9c0332jAgAEaPXq0Ll26ZN0AAACArMj06SW3S/nt2rWzXs16+349LVq0sD62WCxKSkoyJ0gAAADYhUu6Z11nD6Yn3evWrbvrvr1796pixYqZGA0AAABgf6Yn3Q0aNLB5fPnyZc2fP1+ff/65du7cSXUbAAAgG3HWOdeOZvqc7ts2btyo8PBw+fv7a+zYsXr88ce1detWs8MCAAAAMszUSndcXJyioqI0c+ZMXbp0Se3atVNiYqKWLl2a4nacAAAAyPosOXROt2mV7hYtWigkJER79+7VhAkTdOrUKU2ePNmscAAAAACHMa3S/cMPP6hfv3565ZVXVLp0abPCAAAAQCZiTncm27Rpky5fvqxq1aqpZs2amjJlis6ePWtWOAAAAIDDmJZ016pVSzNmzFBsbKx69eqlBQsWKCAgQMnJyVq1apUuX75sVmgAAABwEBdZHL45I9NXL8mbN6+6deumTZs2ad++fRo0aJA+/PBDFS5cWC1btjQ7PAAAACDDTE+6/yskJERjxozRyZMnNX/+fLPDAQAAgJ1ZLI7fnJFTJd235cqVS61bt9ayZcvMDgUAAADIMNPvSAkAAICcw1kr0Y7mlJVuAAAAIDuh0g0AAIBMwx0pAQAAADgElW4AAABkGpecWeim0g0AAAA4GpVuAAAAZBrmdAMAAABwCCrdAAAAyDSs0w0AAADAIah0AwAAINMwpxsAAACAQ1DpBgAAQKZhnW4AAAAADkGlGwAAAJmGOd0AAAAAHIJKNwAAADIN63QDAAAAcAgq3QAAAMg0ObTQTaUbAAAAcDQq3QAAAMg0Ljl0UjeVbgAAAMDBsmWlu26xAmaHAAAAgFTkzDo3lW4AAADA4bJlpRsAAABOKoeWuql0AwAAAA5GpRsAAACZxpJDS91UugEAAAAHo9INAACATJNDl+mm0g0AAAA4GpVuAAAAZJocWuim0g0AAIBMZMmELQM+/PBDWSwWDRgwIGMnugNJNwAAACBp+/bt+vTTT1WxYkW7n5ukGwAAAJnGkgn/PYiEhAR16tRJM2bMUIECBez8qkm6AQAAAPXu3VvNmjVT48aNHXJ+LqQEAABApsmMJQMTExOVmJho0+bu7i53d/dUj1+wYIF27dql7du3OywmKt0AAADIViIjI+Xj42OzRUZGpnrsX3/9pf79+2vevHny8PBwWEwWwzAMh53dJGsPnjM7BGQDdYL9zA4BAIAM83CyeQ27jl9yeB/l/N3TXOleunSp2rRpo1y5clnbkpKSZLFY5OLiosTERJt9D8rJPgYAAAAgY+41leROjRo10r59+2zaunbtqjJlymjIkCF2Sbglkm4AAABkJie7O06+fPlUvnx5m7a8efPKz88vRXtGMKcbAAAAcDAq3QAAAMg0D7qOdmZav3693c9JpRsAAABwMCrdAAAAyDSZsU63M6LSDQAAADgYlW4AAABkmhxa6KbSDQAAADgalW4AAABknhxa6qbSDQAAADgYlW4AAABkmqywTrcjUOkGAAAAHIxKNwAAADIN63QDAAAAcAgq3QAAAMg0ObTQTaUbAAAAcDQq3QAAAMg8ObTUTaUbAAAAcDAq3QAAAMg0rNNtkmvXrunq1avWx3/++acmTJiglStXmhgVAAAAYD+mJ92tWrXSnDlzJEnx8fGqWbOmxo0bp1atWmnatGkmRwcAAAB7slgcvzkj05PuXbt26bHHHpMkffPNNypSpIj+/PNPzZkzR5MmTTI5OgAAACDjTJ/TffXqVeXLl0+StHLlSrVt21YuLi6qVauW/vzzT5OjAwAAgD05aSHa4UyvdAcHB2vp0qX666+/9NNPP+nJJ5+UJJ0+fVre3t4mRwcAAABknOlJ97vvvqvBgwcrKChINWvWVO3atSX9W/WuUqWKydEBAADAriyZsDkhi2EYhtlBxMXFKTY2VpUqVZKLy7/fA3799Vd5e3urTJky6T7f2oPn7B0icqA6wX5mhwAAQIZ5mD6Z2NaB2CsO7yPUP6/D+0gvp/gYihYtqqJFi9q0PfrooyZFAwAAAEfJqet0m5J0t23bVlFRUfL29lbbtm3veezixYszKSoAAADAMUxJun18fGT5/4so+vj4mBECAAAATOCs62g7mlPM6bY35nTDHpjTDQDIDpxtTvehuKv3PyiDQormcXgf6WX66iXcBh4AACDnyKGLl5ifdN95G/hHH32U28ADAAAgWzE96b7zNvBFixblNvAAAADZVQ4tdZuedHMbeAAAAGR3pifd3AYeAAAg57Bkwn/OyPSkm9vAAwAAILtziiUDuQ08nBFLBgIAsgNnWzLw6OlrDu8juLCnw/tIL9Mr3bNmzZKPj4+qVKliTbilf28D/yAJNwAAAOBsTE+633zzTRUpUkTdu3fX5s2bzQ4HAAAADpRDFy8xP+n++++/NXv2bJ09e1ZhYWEqU6aMRo8erbi4OLNDAwAAAOzC9KQ7d+7catOmjb799lv99ddf6tmzp+bNm6cSJUqoZcuW+vbbb5WcnGx2mNnC8vmf65VWdWy2Ea92MDssZEELvpqnpk88rhpVKqhTh+e0b+9es0NCFsMYQkYxhrKwHFrqNj3p/q8iRYqoXr16ql27tlxcXLRv3z6Fh4erVKlSWr9+vdnhZQv+JUrqw6jvrNvgD6ebHRKymB9/+F5jx0Sq16u9teDrJQoJKaNXenXXuXNcwIy0YQwhoxhDyIqcIun+559/NHbsWJUrV05hYWG6dOmSli9frpiYGP39999q166dwsPDzQ4zW8iVK7d8CvhZNy/v/GaHhCxm7uxZavtsO7Vu84xKBQfrneER8vDw0NLFi8wODVkEYwgZxRjK2lin2yQtWrRQ8eLFFRUVpZ49e+rvv//W/Pnz1bhxY0lS3rx5NWjQIP31118mR5o9nD71l97s0lLvvPSsvhg3QufPMHceaXfzxg0d+P031apdx9r27x1k62jvnt0mRoasgjGEjGIMIasyfeXGwoULa8OGDdab4qSmUKFCiomJycSosqegR8qpc/93VOShErp0/qxWLPhC44a+omGTvpRHnrxmh4cs4EL8BSUlJcnPz3YNcz8/P8XE/GFSVMhKGEPIKMZQ1mdxzkK0w5medM+cOfO+x1gsFgUGBqa6LzExUYmJiTZtN24kys3N3S7xZSflq/3ni01QsIIeKae3e7bVzl/Wqu4TLcwLDAAAIJszJemeNGlSmo/t16/fPfdHRkYqIiLCpq1z79cV3mfIA8WWk+TxyqciAcV1Jvak2aEgiyiQv4By5cqV4mKlc+fOqWDBgiZFhayEMYSMYgxlfTm00G1O0v3xxx+n6TiLxXLfpHvo0KEaOHCgTdvm4wkPHFtOcv3aVZ2J+1uPhj1ldijIIlzd3BRatpy2bd2ixxv9e91FcnKytm3bog4dXzA5OmQFjCFkFGMIWZUpSbc952e7u7vL3d12Komb2027nT87WTRrsirUqCe/QkUVf/6sls//XC4uuVSj/hNmh4Ys5MXwrhr21hCVK1de5StU1JdzZ+vatWtq3aat2aEhi2AMIaMYQ1mck5W6IyMjtXjxYh08eFCenp6qU6eORo8erZCQELv2Y/qcbmSeC2dP64uxw3Xl8kV5+eRXqdCKemPMZ8rnU8Ds0JCFPNX0aV04f16fTJmks2fPKKRMqD759HP58bMu0ogxhIxiDMGeNmzYoN69e6tGjRq6deuW3nrrLT355JP6/ffflTev/RaasBiGYdjtbA/o5MmTWrZsmU6cOKEbN27Y7Bs/fny6z7f2IIvjI+PqBPvd/yAAAJych5OVWP88l3j/gzIo0O/BF9Q4c+aMdXW9+vXr2y0m0z+GNWvWqGXLlnr44Yd18OBBlS9fXsePH5dhGKpatarZ4QEAACAHuXjxoiTJ19fXruc1/eY4Q4cO1eDBg7Vv3z55eHho0aJF+uuvv9SgQQM999xzZocHAAAAO7JYHL8lJibq0qVLNtudS0ynJjk5WQMGDFDdunVVvnx5u75u05PuAwcOqHPnzpKk3Llz69q1a/Ly8tLIkSM1evRok6MDAABAVhMZGSkfHx+bLTIy8r7P6927t/bv368FCxbYPSbTp5fkzZvXOo/b399fx44dU7ly5SRJZ8+eNTM0AAAA2FlmLF6S2pLSd652d6c+ffpo+fLl2rhxo4oVK2b3mExPumvVqqVNmzYpNDRUTz/9tAYNGqR9+/Zp8eLFqlWrltnhAQAAIItJbUnpuzEMQ3379tWSJUu0fv16lSxZ0iExmZ50jx8/XgkJ/97MJiIiQgkJCVq4cKFKly79QCuXAAAAwHlZnGyd7t69e+urr77St99+q3z58ikuLk6S5OPjI09PT7v14xRLBtobSwbCHlgyEACQHTjbkoEnL9y4/0EZVKyAW5qPtdzlW8CsWbPUpUsXO0XkBJXu227cuKHTp08rOTnZpr1EiRImRQQAAIDsLrPqz6Yn3YcPH1b37t21efNmm3bDMGSxWJSUlGRSZAAAALA3Z5tekllMT7q7du2q3Llza/ny5fL3979riR8AAADIqkxPuqOjo7Vz506VKVPG7FAAAADgYDm1vGr6zXHKli3LetwAAADI1kxPukePHq033nhD69ev17lz51LcshMAAADZR2bcBt4Zmb5koIvLv3n/nXO5M3IhJUsGwh5YMhAAkB0425KBsRcdv2Sgv0/alwzMLKZ/DOvWrbvrvn379mViJAAAAHA0Sw6d1W16pftOly9f1vz58/X5559r586dVLphGirdAIDswNkq3XEXbzq8j6I+rg7vI71Mn9N928aNGxUeHi5/f3+NHTtWjz/+uLZu3Wp2WAAAALAnSyZsTsjU7z5xcXGKiorSzJkzdenSJbVr106JiYlaunSpypYta2ZoAAAAgN2YVulu0aKFQkJCtHfvXk2YMEGnTp3S5MmTzQoHAAAAmSCHFrrNq3T/8MMP6tevn1555RWVLl3arDAAAAAAhzOt0r1p0yZdvnxZ1apVU82aNTVlyhRukgMAAJDN5dR1uk1LumvVqqUZM2YoNjZWvXr10oIFCxQQEKDk5GStWrVKly9fNis0AAAAwK6casnAQ4cOaebMmZo7d67i4+P1xBNPaNmyZek+D0sGwh5YMhAAkB0425KBZy7fcngfhfI52YuWEy0ZKEkhISEaM2aMTp48qfnz55sdDgAAAGAXTlXpthcq3bAHKt0AgOzA6SrdCZlQ6fZyshctJ6t0AwAAANmR830NAAAAQLblpIuLOByVbgAAAMDBqHQDAAAg0zjrOtqORqUbAAAAcDAq3QAAAMg0lhw6q5tKNwAAAOBgVLoBAACQaZjTDQAAAMAhSLoBAAAAByPpBgAAAByMOd0AAADINMzpBgAAAOAQVLoBAACQaVinGwAAAIBDUOkGAABApmFONwAAAACHoNINAACATJNDC91UugEAAABHo9INAACAzJNDS91UugEAAAAHo9INAACATMM63QAAAAAcgko3AAAAMg3rdAMAAABwCCrdAAAAyDQ5tNBNpRsAAABwNCrdAAAAyDw5tNRNpRsAAAA53tSpUxUUFCQPDw/VrFlTv/76q13PT9INAACATGPJhP/Sa+HChRo4cKCGDx+uXbt2qVKlSmrSpIlOnz5tt9dN0g0AAIAcbfz48erZs6e6du2qsmXLavr06cqTJ4+++OILu/VB0g0AAIBMY7E4fkuPGzduaOfOnWrcuLG1zcXFRY0bN9aWLVvs9rq5kBIAAADZSmJiohITE23a3N3d5e7unuLYs2fPKikpSUWKFLFpL1KkiA4ePGi3mLJl0v14GT+zQ3BqiYmJioyM1NChQ1MdfMD9MIZgD4wjZBRjKGvyyITsc8T7kYqIiLBpGz58uEaMGOH4zu/CYhiGYVrvMMWlS5fk4+Ojixcvytvb2+xwkAUxhmAPjCNkFGMId5OeSveNGzeUJ08effPNN2rdurW1PTw8XPHx8fr222/tEhNzugEAAJCtuLu7y9vb22a7268hbm5uqlatmtasWWNtS05O1po1a1S7dm27xZQtp5cAAAAAaTVw4ECFh4erevXqevTRRzVhwgRduXJFXbt2tVsfJN0AAADI0dq3b68zZ87o3XffVVxcnCpXrqwff/wxxcWVGUHSnQO5u7tr+PDhXHSCB8YYgj0wjpBRjCHYU58+fdSnTx+HnZ8LKQEAAAAH40JKAAAAwMFIugEAAAAHI+nOgY4fPy6LxaLo6OgMnScsLEwDBgywS0zImuw1ljLKYrFo6dKlpsaAf40YMUKVK1e2Pu7SpYvNureOwhjImYKCgjRhwgS7nCuzxipyLpLuTJDaX+RvvvlGHh4eGjdunDlBwRRxcXHq27evHn74Ybm7u6t48eJq0aKFzdqgSL/Y2Fg1bdrU7DCyhC1btihXrlxq1qxZpvQ3ceJERUVF2e18dyb1tzEGnFNmj7eMsPdYBe5E0m2Czz//XJ06ddK0adM0aNAgs8NBJjl+/LiqVaumtWvX6qOPPtK+ffv0448/qmHDhurdu7fZ4aVw8+ZNs0NIs6JFi7J6QRrNnDlTffv21caNG3Xq1CmH9+fj46P8+fM7vB/GgHPK7PGWEZk1VpFzkXRnsjFjxqhv375asGCBdcH1sLAw9evXT2+88YZ8fX1VtGhRjRgxwuZ5J06cUKtWreTl5SVvb2+1a9dO//zzjyTp4sWLypUrl3bs2CHp37so+fr6qlatWtbnf/nllypevPhd49q/f7+aNm0qLy8vFSlSRC+++KLOnj1r3X/lyhV17txZXl5e8vf3T7VCHxsbq2bNmsnT01MlS5bUV199leKnv/j4ePXo0UOFChWSt7e3Hn/8ce3Zsyfd72NW9Oqrr8pisejXX3/VM888o0ceeUTlypXTwIEDtXXrVkn3/pyl/6vyffHFFypRooS8vLz06quvKikpSWPGjFHRokVVuHBhffDBBzZ9WywWTZs2TU2bNpWnp6cefvhhffPNN9b9t6eJLFy4UA0aNJCHh4fmzZsn6d8viaGhofLw8FCZMmX0ySefpHhtf/zxhxo2bKg8efKoUqVK2rJli83+TZs26bHHHpOnp6eKFy+ufv366cqVK9b9QUFBGjVqlLp166Z8+fKpRIkS+uyzz6z7b9y4oT59+sjf318eHh4KDAxUZGSkzev779SCffv26fHHH5enp6f8/Pz00ksvKSEhwbr/9q9PY8eOlb+/v/z8/NS7d+8s9UXjQSQkJGjhwoV65ZVX1KxZM5uq3vr162WxWLRixQpVrFhRHh4eqlWrlvbv3289JioqSvnz59fSpUtVunRpeXh4qEmTJvrrr7/u2uedv/QlJydrzJgxCg4Olru7u0qUKGEzXocMGaJHHnlEefLk0cMPP6xhw4ZZP5eoqChFRERoz549slgsslgs1tfAGHA+aRlva9asUfXq1ZUnTx7VqVNHhw4dsh5z7NgxtWrVSkWKFJGXl5dq1Kih1atX37W/bt26qXnz5jZtN2/eVOHChTVz5kxJ//7KXKFCBeu4aNy4sfXfojvH6r2OBR6IAYcLDw83WrVqZbzxxhuGl5eXsXr1apv9DRo0MLy9vY0RI0YYhw8fNmbPnm1YLBZj5cqVhmEYRlJSklG5cmWjXr16xo4dO4ytW7ca1apVMxo0aGA9R9WqVY2PPvrIMAzDiI6ONnx9fQ03Nzfj8uXLhmEYRo8ePYxOnToZhmEYMTExhiRj9+7dhmEYxoULF4xChQoZQ4cONQ4cOGDs2rXLeOKJJ4yGDRtaz//KK68YJUqUMFavXm3s3bvXaN68uZEvXz6jf//+1mMaN25sVK5c2di6dauxc+dOo0GDBoanp6fx8ccf2xzTokULY/v27cbhw4eNQYMGGX5+fsa5c+fs9XY7pXPnzhkWi8UYNWrUXY9Jy+c8fPhww8vLy3j22WeN3377zVi2bJnh5uZmNGnSxOjbt69x8OBB44svvjAkGVu3brU+T5Lh5+dnzJgxwzh06JDxzjvvGLly5TJ+//13wzD+b0wEBQUZixYtMv744w/j1KlTxpdffmn4+/tb2xYtWmT4+voaUVFRNs8rU6aMsXz5cuPQoUPGs88+awQGBho3b940DMMwjh49auTNm9f4+OOPjcOHDxu//PKLUaVKFaNLly7W+AIDAw1fX19j6tSpxpEjR4zIyEjDxcXFOHjwoGEYhvHRRx8ZxYsXNzZu3GgcP37c+Pnnn42vvvrK5vUtWbLEMAzDSEhIMPz9/Y22bdsa+/btM9asWWOULFnSCA8Ptx4fHh5ueHt7Gy+//LJx4MAB47vvvjPy5MljfPbZZw/2AWcRM2fONKpXr24YhmF89913RqlSpYzk5GTDMAxj3bp1hiQjNDTUWLlypfXveVBQkHHjxg3DMAxj1qxZhqurq1G9enVj8+bNxo4dO4xHH33UqFOnjrWP4cOHG5UqVbI+vv3v321vvPGGUaBAASMqKso4evSo8fPPPxszZsyw7n/vvfeMX375xYiJiTGWLVtmFClSxBg9erRhGIZx9epVY9CgQUa5cuWM2NhYIzY21rh69aphGIwBZ5SW8VazZk1j/fr1xm+//WY89thjNmMpOjramD59urFv3z7j8OHDxjvvvGN4eHgYf/75p/WYwMBA6/9jfvnlFyNXrlzGqVOnrPsXL15s5M2b17h8+bJx6tQpI3fu3Mb48eONmJgYY+/evcbUqVOt/5/871i937HAgyDpzgTh4eGGm5ubIclYs2ZNiv0NGjQw6tWrZ9NWo0YNY8iQIYZhGMbKlSuNXLlyGSdOnLDu/+233wxJxq+//moYhmEMHDjQaNasmWEYhjFhwgSjffv2RqVKlYwffvjBMAzDCA4Otv7P5M6k+7333jOefPJJm/7/+usvQ5Jx6NAh4/Lly4abm5vxv//9z7r/3LlzhqenpzXpPnDggCHJ2L59u/WYI0eOGJKs/yD+/PPPhre3t3H9+nWbvkqVKmV8+umn938js7Bt27YZkozFixff9Zi0fM7Dhw838uTJY1y6dMl6TJMmTYygoCAjKSnJ2hYSEmJERkZaH0syXn75ZZv+atasabzyyiuGYfzfmJgwYYLNMaVKlbJJbg3j3/FSu3Ztm+d9/vnnKWI+cOCAYRiG0b17d+Oll16yOcfPP/9suLi4GNeuXTMM49//cb7wwgvW/cnJyUbhwoWNadOmGYZhGH379jUef/xx6/+w7/TfhOuzzz4zChQoYCQkJFj3r1ixwnBxcTHi4uIMw/j372RgYKBx69Yt6zHPPfec0b59+1TPn13UqVPH+hnfvHnTKFiwoLFu3TrDMP4vCVqwYIH1+Nt/zxcuXGgYxr9J951f6G7/3d+2bZthGPdOui9dumS4u7vbJNn389FHHxnVqlWzPr7z/LcxBpxPWsbbf4tQK1asMCRZ/11ITbly5YzJkydbH/836TYMwyhbtqz1S5phGEaLFi2sX/B37txpSDKOHz+e6rn/O1bvdyzwIJhekkkqVqyooKAgDR8+3OYnzv/u/y9/f3+dPn1aknTgwAEVL17cZnpI2bJllT9/fh04cECS1KBBA23atElJSUnasGGDwsLCFBYWpvXr1+vUqVM6evSowsLCUo1tz549Wrdunby8vKxbmTJlJP37896xY8d048YN1axZ0/ocX19fhYSEWB8fOnRIuXPnVtWqVa1twcHBKlCggE0/CQkJ8vPzs+krJiZGx44dS+tbmSUZabgHVVo+Z+nfqRj58uWzPi5SpIjKli0rFxcXm7bb4+e22rVrp3j83/NKUvXq1a1/vnLlio4dO6bu3bvbfF7vv/9+is/rv+PX399fkqz979mzR1FRUTbnaNKkiZKTkxUTE5PqOSwWi4oWLWo9R5cuXRQdHa2QkBD169dPK1euTPU9lP59HytVqqS8efNa2+rWravk5GSbn67LlSunXLly2cR953uWnRw6dEi//vqrOnbsKEnKnTu32rdvb/3Z/bb/jpPbf8//O05y586tGjVqWB+XKVMmxRi9mwMHDigxMVGNGjW66zELFy5U3bp1VbRoUXl5eemdd97RiRMn0vw6b/fDGDBXWsfbvf7tSEhI0ODBgxUaGqr8+fPLy8tLBw4cuOd46NGjh2bNmiVJ+ueff/TDDz+oW7dukqRKlSqpUaNGqlChgp577jnNmDFDFy5cSPU86TkWSCtuA59JHnroIX3zzTdq2LChnnrqKf3www82iZOrq6vN8RaLRcnJyWk+f/369XX58mXt2rVLGzdu1KhRo1S0aFF9+OGHqlSpkgICAlS6dOlUn5uQkKAWLVpo9OjRKfb5+/vr6NGjaY7jXhISEuTv76/169en2JfdL14pXbq0LBaLDh48mOFzpTZWMjp+bvtvknL7y+GMGTNsvnBJsklU7ozJYrFIkrX/hIQE9erVS/369UvRX4kSJVI9x52voWrVqoqJidEPP/yg1atXq127dmrcuLHNvPT0std7llXMnDlTt27dUkBAgLXNMAy5u7trypQpmRKDp6fnPfdv2bJFnTp1UkREhJo0aSIfHx8tWLDAYas85bQxkJnSOt7u9W/H4MGDtWrVKo0dO1bBwcHy9PTUs88+qxs3bty1386dO+vNN9/Uli1btHnzZpUsWVKPPfaYpH//3Vq1apU2b96slStXavLkyXr77be1bds2lSxZ0uY86TkWSCsq3ZkoMDBQGzZsUFxcnJ566ildvnw5Tc8LDQ3VX3/9ZXOx0u+//674+HiVLVtW0r9Ja8WKFTVlyhS5urqqTJkyql+/vnbv3q3ly5erQYMGdz1/1apV9dtvvykoKEjBwcE2W968eVWqVCm5urpq27Zt1udcuHBBhw8ftj4OCQnRrVu3tHv3bmvb0aNHbSoDVatWVVxcnHLnzp2in4IFC6bpvciqfH191aRJE02dOjXVC3Hi4+PT9DlnxO2LNf/7ODQ09K7HFylSRAEBAfrjjz9SfF7p+Z9O1apV9fvvv6c4R3BwsNzc3NJ8Hm9vb7Vv314zZszQwoULtWjRIp0/fz7FcaGhodqzZ4/N+/zLL7/IxcXF5teZnOTWrVuaM2eOxo0bp+joaOu2Z88eBQQEaP78+dZj/ztObv89/+84uXXrlvWibenfiubt8Xs/pUuXlqen512XyNy8ebMCAwP19ttvq3r16ipdurT+/PNPm2Pc3NyUlJR0z34YA+ZKz3i7l19++UVdunRRmzZtVKFCBRUtWlTHjx+/53P8/PzUunVrzZo1S1FRUdYFC26zWCyqW7euIiIitHv3brm5uWnJkiWpnis9xwJpQdKdyYoXL67169fr9OnTatKkiS5dunTf5zRu3FgVKlRQp06dtGvXLv3666/q3LmzGjRoYDMdICwsTPPmzbMm2L6+vgoNDbWuSHE3vXv31vnz59WxY0dt375dx44d008//aSuXbsqKSlJXl5e6t69u15//XWtXbtW+/fvV5cuXWymM5QpU0aNGzfWSy+9pF9//VW7d+/WSy+9JE9PT2v1onHjxqpdu7Zat26tlStX6vjx49q8ebPefvttm/+JZ1dTp05VUlKSHn30US1atEhHjhzRgQMHNGnSJNWuXTvNn/OD+vrrr/XFF1/o8OHDGj58uH799Vf16dPnns+JiIhQZGSkJk2apMOHD2vfvn2aNWuWxo8fn+Z+hwwZos2bN6tPnz6Kjo7WkSNH9O2339637/8aP3685s+fr4MHD+rw4cP6+uuvVbRo0VR/IenUqZM8PDwUHh6u/fv3a926derbt69efPFFFSlSJM19ZifLly/XhQsX1L17d5UvX95me+aZZ2x+8h85cqTWrFlj/XtesGBBmxUdXF1d1bdvX23btk07d+5Uly5dVKtWLT366KP3jcPDw0NDhgzRG2+8oTlz5ujYsWPaunWrtf/SpUvrxIkTWrBggY4dO6ZJkyalSHKCgoIUExOj6OhonT17VomJiSn6YQyYKz3j7V5Kly6txYsXWxP2559/Pk2/RPTo0UOzZ8/WgQMHFB4ebm3ftm2bRo0apR07dujEiRNavHixzpw5k+oXxvQcC6QVSbcJihUrpvXr1+vs2bNpSrwtFou+/fZbFShQQPXr11fjxo318MMPa+HChTbHNWjQQElJSTZzt8PCwlK03SkgIEC//PKLkpKS9OSTT6pChQoaMGCA8ufPb02sP/roIz322GNq0aKFGjdurHr16qlatWo255kzZ46KFCmi+vXrq02bNurZs6fy5csnDw8P6+v4/vvvVb9+fXXt2lWPPPKIOnTooD///DNH/I/w4Ycf1q5du9SwYUMNGjRI5cuX1xNPPKE1a9Zo2rRpaf6cH1RERIQWLFigihUras6cOZo/f/59K+g9evTQ559/rlmzZqlChQpq0KCBoqKi0lXprlixojZs2KDDhw/rscceU5UqVfTuu+/a/Ox8P/ny5dOYMWNUvXp11ahRQ8ePH9f3339v88Xvtjx58uinn37S+fPnVaNGDT377LNq1KhRpk2hcEYzZ85U48aN5ePjk2LfM888ox07dmjv3r2SpA8//FD9+/dXtWrVFBcXp++++87mF4k8efJoyJAhev7551W3bl15eXmla4wOGzZMgwYN0rvvvqvQ0FC1b9/eOoe3ZcuWeu2119SnTx9VrlxZmzdv1rBhw1LE+9RTT6lhw4YqVKhQqlVTxoC50jPe7mX8+PEqUKCA6tSpoxYtWqhJkyY21w3dTePGjeXv768mTZrY/Dvj7e2tjRs36umnn9Yjjzyid955R+PGjUv1pkrpORZIK4uRliu8gAdw8uRJFS9eXKtXr77nhVNwPIvFoiVLlnCLY9zV+vXr1bBhQ124cOGu11hERUVpwIABio+Pz9TYgPRISEjQQw89pFmzZqlt27ZmhwNYcSEl7Gbt2rVKSEhQhQoVFBsbqzfeeENBQUGqX7++2aEBALK55ORknT17VuPGjVP+/PnVsmVLs0MCbJB0w25u3rypt956S3/88Yfy5cunOnXqaN68eSlWCAAAwN5OnDihkiVLqlixYoqKilLu3KQ4cC5MLwEAAAAcjAspAQAAAAcj6QYAAAAcjKQbAAAAcDCSbgAAAMDBSLoBAAAAByPpBpDjdOnSxeZGQWFhYRowYECmx7F+/XpZLBaH3mzmztf6IDIjTgDI7ki6ATiFLl26yGKxyGKxyM3NTcHBwRo5cqRu3brl8L4XL16s9957L03HZnYCGhQUpAkTJmRKXwAAx2HleABO46mnntKsWbOUmJio77//Xr1795arq6uGDh2a4tgbN27Izc3NLv36+vra5TwAANwNlW4ATsPd3V1FixZVYGCgXnnlFTVu3FjLli2T9H/TJD744AMFBAQoJCREkvTXX3+pXbt2yp8/v3x9fdWqVSsdP37ces6kpCQNHDhQ+fPnl5+fn9544w3deU+wO6eXJCYmasiQISpevLjc3d0VHBysmTNn6vjx42rYsKEkqUCBArJYLOrSpYukf29BHRkZqZIlS8rT01OVKlXSN998Y9PP999/r0ceeUSenp5q2LChTZwPIikpSd27d7f2GRISookTJ6Z6bEREhAoVKiRvb2+9/PLLunHjhnVfWmIHAGQMlW4ATsvT01Pnzp2zPl6zZo28vb21atUqSdLNmzfVpEkT1a5dWz///LNy586t999/X0899ZT27t0rNzc3jRs3TlFRUfriiy8UGhqqcePGacmSJXr88cfv2m/nzp21ZcsWTZo0SZUqVVJMTIzOnj2r4sWLa9GiRXrmmWd06NAheXt7y9PTU5IUGRmpL7/8UtOnT1fp0qW1ceNGvfDCCypUqJAaNGigv/76S23btlXv3r310ksvaceOHRo0aFCG3p/k5GQVK1ZMX3/9tfz8/LR582a99NJL8vf3V7t27WzeNw8PD61fv17Hjx9X165d5efnpw8++CBNsQMA7MAAACcQHh5utGrVyjAMw0hOTjZWrVpluLu7G4MHD7buL1KkiJGYmGh9zty5c42QkBAjOTnZ2paYmGh4enoaP/30k2EYhuHv72+MGTPGuv/mzZtGsWLFrH0ZhmE0aNDA6N+/v2EYhnHo0CFDkrFq1apU41y3bp0hybhw4YK17fr160aePHmMzZs32xzbvXt3o2PHjoZhGMbQoUONsmXL2uwfMmRIinPdKTAw0Pj444/vuv9OvXv3Np555hnr4/DwcMPX19e4cuWKtW3atGmGl5eXkZSUlKbYU3vNAID0odINwGksX75cXl5eunnzppKTk/X8889rxIgR1v0VKlSwmce9Z88eHT16VPny5bM5z/Xr13Xs2DFdvHhRsbGxqlmzpnVf7ty5Vb169RRTTG6Ljo5Wrly50lXhPXr0qK5evaonnnjCpv3GjRuqUqWKJOnAgQM2cUhS7dq109zH3UydOlVffPGFTpw4oWvXrunGjRuqXLmyzTGVKlVSnjx5bPpNSEjQX3/9pYSEhPvGDgDIOJJuAE6jYcOGmjZtmtzc3BQQEKDcuW3/icqbN6/N44SEBFWrVk3z5s1Lca5ChQo9UAy3p4ukR0JCgiRpxYoVeuihh2z2ubu7P1AcabFgwQINHjxY48aNU+3atZUvXz599NFH2rZtW5rPYVbsAJDTkHQDcBp58+ZVcHBwmo+vWrWqFi5cqMKFC8vb2zvVY/z9/bVt2zbVr19fknTr1i3t3LlTVatWTfX4ChUqKDk5WRs2bFDjxo1T7L9daU9KSrK2lS1bVu7u7jpx4sRdK+ShoaHWi0Jv27p16/1f5D388ssvqlOnjl599VVr27Fjx1Ict2fPHl27ds36hWLr1q3y8vJS8eLF5evre9/YAQAZx+olALKsTp06qWDBgmrVqpV+/vlnxcTEaP369erXr59OnjwpSerfv78+/PBDLV26VAcPHtSrr756zzW2g4KCFB4erm7dumnp0qXWc/7vf/+TJAUGBspisWj58uU6c+aMEhISlC9fPg0ePFivvfaaZs+erWPHjmnXrl2aPHmyZs+eLUl6+eWXdeTIEb3++us6dOiQvvrqK0VFRaXpdf7999+Kjo622S5cuKDSpUtrx44d+umnn3T48GENGzZM27dvT/H8GzduqHv37vr999/1/fffa/jw4erTp49cXFzSFDsAIONIugFkWXny5NHGjRtVokQJtW3bVqGhoerevbuuX79urXwPGjRIL774osLDw61TMNq0aXPP806bNk3PPvusXn31VZUpU0Y9e/bUlStXJEkPPfSQIiIi9Oabb6pIkSLq06ePJOm9997TsGHDFBkZqdDQUD311FNasWKFSpYsKUkqUaKEFi1apKVLl6pSpUqaPn26Ro0alabXOXbsWFWpUsVmW7FihXr16qW2bduqffv2qlmzps6dO2dT9b6tUaNGKl26tOrXr6/27durZcuWNnPl7xc7ACDjLMbdriYCAAAAYBdUugEAAAAHI+kGAAAAHIykGwAAAHAwkm4AAADAwUi6AQAAAAcj6QYAAAAcjKQbAAAAcDCSbgAAAMDBSLoBAAAAByPpBgAAAByMpBsAAABwMJJuAAAAwMH+H27gAna2tT0zAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_labels in data_loader:\n",
        "            # Move batch_data to the same device as the model\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            outputs, _ = model(batch_data) # Get logits from model output\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.tolist())  # Use .tolist() instead of .numpy()\n",
        "            all_labels.extend(batch_labels.tolist())  # Use .tolist() instead of .numpy()\n",
        "    return all_preds, all_labels\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions, true_labels = evaluate(model, test_loader)\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "print(f\"Test Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Save faulty predictions\n",
        "faulty_predictions = []\n",
        "for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
        "    predicted_bloom = bloom_categories[predictions[i]]\n",
        "    actual_bloom = bloom_categories[true_label]\n",
        "\n",
        "    if predicted_bloom != actual_bloom:\n",
        "        faulty_predictions.append({\n",
        "            \"question\": text,\n",
        "            \"actual_bloom\": actual_bloom,\n",
        "            \"predicted_bloom\": predicted_bloom\n",
        "        })\n",
        "\n",
        "with open(faulty_predictions_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(faulty_predictions, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Faulty predictions saved to {faulty_predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFB8DGqsOn3K",
        "outputId": "3b2b1db9-94db-4a12-b8ff-ff684cc26a8e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.0527\n",
            "Epoch 2/5, Loss: 0.0493\n",
            "Epoch 3/5, Loss: 0.0325\n",
            "Epoch 4/5, Loss: 0.0049\n",
            "Epoch 5/5, Loss: 0.0029\n",
            "Test Accuracy: 0.4571, F1 Score: 0.3708\n",
            "Faulty predictions saved to faulty_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_heatmap(true_labels, predictions, class_names):\n",
        "    # Generate the confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "    # Normalize the confusion matrix (optional)\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Create the heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(\"Normalized Confusion Matrix Heatmap\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate the model and plot the heatmap\n",
        "def evaluate_and_plot(model, test_loader, class_names):\n",
        "    predictions, true_labels = evaluate(model, test_loader)\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "    plot_heatmap(true_labels, predictions, class_names)\n",
        "\n",
        "# Define class names (example: Bloom taxonomy categories)\n",
        "class_names = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Call the evaluation and heatmap function\n",
        "evaluate_and_plot(model, test_loader, class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "uYJBrkI1PorF",
        "outputId": "425934d7-ae56-4438-ae4e-09e55f220d38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4571, F1 Score: 0.3708\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtHRsJ9mNbee",
        "outputId": "f6ec10c7-1d39-4e89-c051-655142b40e90"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "train_dataset_path = r\"eduqg_evaluation_bloom_cleaned.json\"\n",
        "test_dataset_path = r\"eduqg_few_shot_bloom_cleaned.json\"\n",
        "\n",
        "# Bloom taxonomy categories\n",
        "bloom_categories = [\"Knowledge\", \"Comprehension\", \"Application\", \"Analysis\"]\n",
        "\n",
        "# Load data\n",
        "def load_data(dataset_path, bloom_categories):\n",
        "    texts, labels = [], []\n",
        "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "        dataset = json.load(f)\n",
        "        for chapter in dataset:\n",
        "            for question_item in chapter.get('questions', []):\n",
        "                question = question_item.get(\"question\", {}).get(\"normal_format\", \"\")\n",
        "                actual_bloom = question_item.get(\"actual_bloom\", \"\")\n",
        "                if question and actual_bloom:\n",
        "                    texts.append(question)\n",
        "                    labels.append(bloom_categories.index(actual_bloom))\n",
        "    return texts, labels\n",
        "\n",
        "train_texts, train_labels = load_data(train_dataset_path, bloom_categories)\n",
        "test_texts, test_labels = load_data(test_dataset_path, bloom_categories)\n",
        "\n",
        "# Text vectorization\n",
        "vectorizer = CountVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_train = vectorizer.fit_transform(train_texts).toarray()\n",
        "X_test = vectorizer.transform(test_texts).toarray()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_labels)\n",
        "y_test = label_encoder.transform(test_labels)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Dataset and DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Define the GRU model\n",
        "class GRUClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.5):\n",
        "        super(GRUClassifier, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # Add sequence dimension\n",
        "        gru_out, _ = self.gru(x)\n",
        "        last_hidden_state = gru_out[:, -1, :]  # Use the last hidden state\n",
        "        out = self.fc(last_hidden_state)\n",
        "        return self.softmax(out)\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = 128\n",
        "output_size = len(bloom_categories)\n",
        "num_layers = 2\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 10\n",
        "\n",
        "# Initialize the model, loss, and optimizer\n",
        "model = GRUClassifier(input_size, hidden_size, output_size, num_layers)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch_data, batch_labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_data)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_labels in test_loader:\n",
        "            outputs = model(batch_data)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.numpy())\n",
        "            all_labels.extend(batch_labels.numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "    print(f\"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Train and evaluate\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "ZmF6CgXqNSEx",
        "outputId": "4672e5c5-3eca-4e9d-f7ec-dacbc01f0740"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 28/28 [00:00<00:00, 94.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 36.9167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 28/28 [00:00<00:00, 113.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 29.7005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 28/28 [00:00<00:00, 122.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 28.0631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 28/28 [00:00<00:00, 133.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 28.1475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 28/28 [00:00<00:00, 147.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 27.9084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 28/28 [00:00<00:00, 150.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 27.1210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 28/28 [00:00<00:00, 141.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 26.3257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 28/28 [00:00<00:00, 146.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 26.0348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 28/28 [00:00<00:00, 137.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 25.3324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 28/28 [00:00<00:00, 138.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 24.6941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fce618c7525a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-fce618c7525a>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.15.1\n",
        "!pip install torch==2.0.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4UV7HUS9LbIp",
        "outputId": "b359d0e2-9e28-42e4-81c7-95927ef761c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.15.1\n",
            "  Downloading torchtext-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.32.3)\n",
            "Collecting torch==2.0.0 (from torchtext==0.15.1)\n",
            "  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.2.2)\n",
            "Collecting torchdata==0.6.0 (from torchtext==0.15.1)\n",
            "  Downloading torchdata-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (892 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.9.0.58)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.31.2)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n",
            "Downloading torchtext-0.15.1-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: nvidia-nvtx-cu11\n",
            "    Found existing installation: nvidia-nvtx-cu11 11.8.86\n",
            "    Uninstalling nvidia-nvtx-cu11-11.8.86:\n",
            "      Successfully uninstalled nvidia-nvtx-cu11-11.8.86\n",
            "  Attempting uninstall: nvidia-nccl-cu11\n",
            "    Found existing installation: nvidia-nccl-cu11 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu11-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu11-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu11\n",
            "    Found existing installation: nvidia-cusparse-cu11 11.7.5.86\n",
            "    Uninstalling nvidia-cusparse-cu11-11.7.5.86:\n",
            "      Successfully uninstalled nvidia-cusparse-cu11-11.7.5.86\n",
            "  Attempting uninstall: nvidia-curand-cu11\n",
            "    Found existing installation: nvidia-curand-cu11 10.3.0.86\n",
            "    Uninstalling nvidia-curand-cu11-10.3.0.86:\n",
            "      Successfully uninstalled nvidia-curand-cu11-10.3.0.86\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
            "    Found existing installation: nvidia-cuda-runtime-cu11 11.8.89\n",
            "    Uninstalling nvidia-cuda-runtime-cu11-11.8.89:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu11-11.8.89\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu11 11.8.89\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu11-11.8.89:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.8.89\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu11\n",
            "    Found existing installation: nvidia-cuda-cupti-cu11 11.8.87\n",
            "    Uninstalling nvidia-cuda-cupti-cu11-11.8.87:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu11-11.8.87\n",
            "  Attempting uninstall: nvidia-cublas-cu11\n",
            "    Found existing installation: nvidia-cublas-cu11 11.11.3.6\n",
            "    Uninstalling nvidia-cublas-cu11-11.11.3.6:\n",
            "      Successfully uninstalled nvidia-cublas-cu11-11.11.3.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu11\n",
            "    Found existing installation: nvidia-cusolver-cu11 11.4.1.48\n",
            "    Uninstalling nvidia-cusolver-cu11-11.4.1.48:\n",
            "      Successfully uninstalled nvidia-cusolver-cu11-11.4.1.48\n",
            "  Attempting uninstall: nvidia-cudnn-cu11\n",
            "    Found existing installation: nvidia-cudnn-cu11 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu11-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu11-9.1.0.70\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1\n",
            "    Uninstalling torch-2.5.1:\n",
            "      Successfully uninstalled torch-2.5.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu118 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu118 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "d0bd9c575f1c4efd937dc06cce60f2b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 397, in resolve\n",
            "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n",
            "    return any(self)\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 53, in _iter_built\n",
            "    candidate = func()\n",
            "                ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 185, in _make_candidate_from_link\n",
            "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 598, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 170, in unpack_url\n",
            "    file = get_http_url(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 111, in get_http_url\n",
            "    from_path, content_type = download(link, temp_dir.path)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/download.py\", line 149, in __call__\n",
            "    content_file.write(chunk)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1742, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "           ~~~~~~~~~~~^^^^^^^\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1535, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1744, in isEnabledFor\n",
            "    _acquireLock()\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 228, in _acquireLock\n",
            "    def _acquireLock():\n",
            "    \n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}